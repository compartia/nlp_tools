{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UI-Demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/compartia/nlp_tools/blob/vadim/UI_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "raaJNhjYXuoW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#.init"
      ]
    },
    {
      "metadata": {
        "id": "DmfQVYoSXqf8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##utils"
      ]
    },
    {
      "metadata": {
        "id": "YYCa_a2lXjxP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import uuid\n",
        "from google.colab import output\n",
        "from google.colab import files\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from google.colab import widgets\n",
        "from google.colab import output\n",
        "\n",
        "\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "def interactive_upload(filetype):\n",
        "  \n",
        "  import docx2txt\n",
        "  \n",
        "  print(f'Please select \"{filetype}\" .docx file:')\n",
        "  uploaded = files.upload()\n",
        "  docs=[]\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "    with open(fn, \"wb\") as df:\n",
        "      df.write(uploaded[fn])\n",
        "      df.close()\n",
        "\n",
        "    # extract text\n",
        "  \n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "    print(\"–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ:\", len(text))\n",
        "    docs.append(text)\n",
        "    return docs\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "class InvokeButton(object):\n",
        "  def __init__(self, title, callback = None):\n",
        "    self.title = title\n",
        "    self.callback = callback\n",
        "\n",
        "  # def _repr_html_(self):\n",
        "  def render(self):\n",
        "    self.callback_id = 'button-' + str(uuid.uuid4())\n",
        "    if self.callback:\n",
        "      output.register_callback(self.callback_id, self.callback)\n",
        "\n",
        "    template =f'''<button style=\"padding:5px; font-size:16px; margin:15px\"  id=\"{self.callback_id}\">{self.title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{self.callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction(\"{self.callback_id}\", [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>'''\n",
        "    display(IPython.display.HTML(template))\n",
        "  \n",
        "  \n",
        "  def render_to(self, tb, tab, cleartab = False):\n",
        "    with tb.output_to(tab):\n",
        "      if cleartab:\n",
        "        tb.clear_tab()\n",
        "      self.render()\n",
        "      \n",
        "  def render_to_element(self, id):\n",
        "    with output.redirect_to_element(f'#{id}'):    \n",
        "      self.render()\n",
        "  \n",
        "\n",
        "      \n",
        "\n",
        "def clear_div(elementID):\n",
        "  display(IPython.display.Javascript(f'document.getElementById(\"{elementID}\").innerHTML = \"\";'))\n",
        "\n",
        "def replace_self_elem(elementID, text):\n",
        "  #print(f'Replace: {elementID}')\n",
        "  display(IPython.display.Javascript(f'document.getElementById(\"{elementID}\").parentElement.innerHTML = \"{text}\";'))\n",
        "\n",
        "def toggle_element(elementId):\n",
        "  display(IPython.display.Javascript(f''' \n",
        "    var x = document.getElementById(\"{elementId}\");\n",
        "    if (x.style.display === \"none\")\n",
        "      x.style.display = \"block\";\n",
        "    else\n",
        "      x.style.display = \"none\";\n",
        "    '''))\n",
        "\n",
        "  \n",
        "  \n",
        "GLOBALS__ = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TTYEFnsrX_LL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#–î–µ–º–æ"
      ]
    },
    {
      "metadata": {
        "id": "st1uyXGyR1WN",
        "colab_type": "code",
        "outputId": "927499c8-679d-466c-d6d2-85365d129b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title –ù–∞—Å—Ç—Ä–æ–π–∫–∏ { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "USD_to_RUB = 264.02 #@param {type:\"number\"}\n",
        "RUB_to_USD = 1.0/USD_to_RUB\n",
        "\n",
        "# print('USD_to_RUB=',USD_to_RUB)\n",
        "# print('RUB_to_USD=',RUB_to_USD)\n",
        "\n",
        "\n",
        "\n",
        "currency_converter = {\n",
        "  'USD': USD_to_RUB,\n",
        "  'RUB': 1.0\n",
        "}\n",
        "\n",
        "print(currency_converter)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'USD': 264.02, 'RUB': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CPxjslnsM6Y2",
        "colab_type": "code",
        "outputId": "f79e3d6a-8cf2-4133-d5ab-bf35c9cd5e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        }
      },
      "cell_type": "code",
      "source": [
        "# @title –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ { output-height: 800, form-width: \"300px\", display-mode: \"form\" }\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def interactive_upload(filetype):\n",
        "  from google.colab import files\n",
        "  import docx2txt\n",
        "\n",
        "  print(f'Please select \"{filetype}\" .docx file:')\n",
        "  uploaded = files.upload()\n",
        "  docs = []\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "    with open(fn, \"wb\") as df:\n",
        "      df.write(uploaded[fn])\n",
        "      df.close()\n",
        "\n",
        "    # extract text\n",
        "\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "    print(\"–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ:\", len(text))\n",
        "    docs.append(text)\n",
        "    return docs\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# ====================================\n",
        "_git_branch = \"vadim\"  # @param {type:\"string\"}\n",
        "# ====================================\n",
        "# ====================================\n",
        "\n",
        "\n",
        "# ''' AZ:-IMPORT CODE GITHUB----------------------------------------------üò∫------ '''\n",
        "import sys\n",
        "\n",
        "\n",
        "def _init_import_code_from_gh():\n",
        "  if 'GLOBALS__' not in globals():\n",
        "    print('adding global GLOBALS__')\n",
        "    global GLOBALS__\n",
        "    GLOBALS__ = {}\n",
        "\n",
        "  if '_init_import_code_from_gh' in GLOBALS__:\n",
        "    print('üëå code already imported from GitHub!')\n",
        "    return\n",
        "\n",
        "  import subprocess\n",
        "  def exec(x):\n",
        "    r = subprocess.check_output(x, shell=True)\n",
        "    r = r.decode('unicode-escape').encode('latin1').decode('utf8')\n",
        "    print(r)\n",
        "\n",
        "  print(f\"fetching code from GitHub.....{_git_branch}\")\n",
        "  try:\n",
        "    exec('rm -r nlp_tools')\n",
        "  except:\n",
        "    pass\n",
        "  exec(f'git clone --single-branch --branch {_git_branch} https://github.com/compartia/nlp_tools.git nlp_tools')\n",
        "\n",
        "  print('ü¶ä GIT revision:')\n",
        "  exec('cd nlp_tools\\ngit rev-list --reverse HEAD | awk \"{ print NR }\" | tail -n 1\\ngit branch\\ngit log -3 --pretty=%B')\n",
        "\n",
        "  sys.path.insert(0, 'nlp_tools')\n",
        "\n",
        "  # self-test\n",
        "  from text_tools import untokenize\n",
        "  print(untokenize(['code', 'imported', 'OK üëç']))\n",
        "\n",
        "  print('installing antiword...')\n",
        "  exec('sudo apt-get install antiword')\n",
        "\n",
        "  print('installing docx2txt...')\n",
        "  exec(\"pip install docx2txt\")\n",
        "\n",
        "  GLOBALS__['_init_import_code_from_gh'] = True\n",
        "\n",
        "  ''' AZ:-------------------------------------------------IMPORT CODE GITHUB-üò∫---'''\n",
        "  print('‚ù§Ô∏è DONE importing Code fro GitHub')\n",
        "\n",
        "\n",
        "# AZ:-INIT ELMO-----------------------------------------------------------------------------------\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "def _import_elmo():\n",
        "  \"\"\"\n",
        "  ACHTUNG!! this method is called later by ElmoEmbedder\n",
        "  \"\"\"\n",
        "\n",
        "  elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz',\n",
        "                    trainable=False)  # news\n",
        "  #   elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-twitter_2013-01_2018-04_600k_steps.tar.gz',\n",
        "  #                     trainable=False)  # twitter\n",
        "  print('‚ù§Ô∏è ‚ù§Ô∏è ‚ù§Ô∏è DONE (re)importing Tensorflow hub.Module ')\n",
        "  print('Tensorflow version is', tf.__version__)\n",
        "\n",
        "  return elmo\n",
        "\n",
        "\n",
        "# AZ:-INIT EMBEDDER-----------------------------------------------------------------------------------\n",
        "\n",
        "def _init_embedder():\n",
        "  if 'elmo_embedder' in GLOBALS__:\n",
        "    print('üëå Embedder is already created! ')\n",
        "    return\n",
        "\n",
        "  from embedding_tools import ElmoEmbedder\n",
        "  GLOBALS__['elmo_embedder'] = ElmoEmbedder(_import_elmo(), tf, 'elmo', _import_elmo)\n",
        "\n",
        "  print('‚ù§Ô∏è DONE creating words embedding model')\n",
        "  return GLOBALS__['elmo_embedder']\n",
        "\n",
        "\n",
        "# AZ:-Init chartes context-----------------------------------------------------------------------------------\n",
        "def _init_charters():\n",
        "  if 'CharterAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Charters-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  _init_embedder()  # PRECONDITION\n",
        "  from charter_patterns import CharterPatternFactory\n",
        "  from charter_parser import CharterDocumentParser\n",
        "  CPF = CharterPatternFactory(GLOBALS__['elmo_embedder'])\n",
        "  GLOBALS__['CharterAnlysingContext'] = CharterDocumentParser(CPF)\n",
        "  print('‚ù§Ô∏è DONE initing Charters-related tools and models ')\n",
        "\n",
        "\n",
        "def _init_contracts():\n",
        "  if 'ContractAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Contracts-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  from contract_parser import ContractAnlysingContext\n",
        "  GLOBALS__['ContractAnlysingContext'] = ContractAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['renderer'])\n",
        "  print('‚ù§Ô∏è DONE initing Contracts-related tools and models ')\n",
        "\n",
        "\n",
        "# AZ:- THE CODE----------------------------------------------------------------------------------\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def _init_the_code(reset=False):\n",
        "  if '_init_the_code' in GLOBALS__ and not reset:\n",
        "    print('üëå Code is alredy imported!')\n",
        "    return\n",
        "\n",
        "  from transaction_values import ValueConstraint\n",
        "\n",
        "  import matplotlib as mpl\n",
        "  from IPython.core.display import display, HTML\n",
        "  import matplotlib.pyplot as plt\n",
        "  \n",
        "  from renderer import AbstractRenderer, HtmlRenderer, head_types_colors\n",
        "  from renderer import to_multicolor_text, as_headline_3, as_offset\n",
        "  from renderer import as_msg, as_quote, as_c_quote\n",
        "  from renderer import as_error_html, known_subjects_dict, v_color_map\n",
        "  from transaction_values import ValueConstraint\n",
        "  from parsing import head_types_dict, head_types\n",
        "  from legal_docs import PatternSearchResults, ConstraintsSearchResult, PatternSearchResult, CharterDocument\n",
        "  \n",
        "  import numpy as np\n",
        "  \n",
        "  from charter_patterns import known_subjects\n",
        "  from patterns import AV_SOFT, AV_PREFIX\n",
        "  from structures import ContractSubject\n",
        "  from contract_parser import ContractDocument3\n",
        "\n",
        "  def _as_smaller(txt):\n",
        "    return f'<div font-size:12px\">{txt}</div>'\n",
        " \n",
        "  \n",
        "      \n",
        "  class DemoRenderer(HtmlRenderer):\n",
        "\n",
        "    def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      print('render_color_text')\n",
        "      html = self.to_color_text(tokens, weights, colormap, print_debug, _range)\n",
        "      display(HTML(html))\n",
        "                \n",
        "\n",
        "    def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      if len(tokens) == 0:\n",
        "        return \" - empty -\"\n",
        "      if len(weights) != len(tokens):\n",
        "        raise ValueError(\"number of weights differs weights={} tokens={}\".format(len(weights), len(tokens)))\n",
        "\n",
        "      #   if()\n",
        "      vmin = min(weights)\n",
        "      vmax = max(weights)\n",
        "\n",
        "      if _range is not None:\n",
        "        vmin = _range[0]\n",
        "        vmax = _range[1]\n",
        "\n",
        "      if print_debug:\n",
        "        print(vmin, vmax)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmin=vmin - 0.5, vmax=vmax)\n",
        "      html = \"\"\n",
        "      cmap = mpl.cm.get_cmap(colormap)\n",
        "\n",
        "      for d in range(0, len(weights)):\n",
        "        word = tokens[d]\n",
        "        if word == ' ':\n",
        "          word = '&nbsp;_ '\n",
        "\n",
        "        html += '<span title=\"{} {:.4f}\" style=\"background-color:{}\">{} </span>'.format(\n",
        "          d,\n",
        "          weights[d],\n",
        "          mpl.colors.to_hex(cmap(norm(weights[d]))),\n",
        "          word)\n",
        "\n",
        "        #     html+='<span style=\"background-color:' +mpl.colors.to_hex(cmap(norm(weights[d]) ))+ '\">' + str(tokens[d]) + \" </span>\"\n",
        "        if tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "\n",
        "    ''' AZ:-Rendering CHARITYüî•-----üí∏------üí∏-------üí∏------------------------------'''\n",
        "    def render_multicolor_text(self, tokens, vectors, colormap, min_color=None, _slice=None):\n",
        "      display(HTML(to_multicolor_text(tokens, vectors, colormap, min_color=min_color, _slice=_slice)))\n",
        "\n",
        "    \n",
        "\n",
        "    ''' AZ:------üí∏------üí∏-------üí∏----------------------END--Rendering CHARITYüî•------'''\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    def render_subj(self, contract: ContractDocument3):\n",
        "      subjects: List[ProbableValue] = contract.subjects\n",
        "\n",
        "      if len(subjects) > 0:\n",
        "        sorted_ = [y for y in sorted(subjects, key=lambda x: -x.confidence)]\n",
        "        subject_kind = sorted_[0].value\n",
        "        confidence = sorted_[0].confidence\n",
        "      else:\n",
        "        subject_kind = ContractSubject.Other\n",
        "\n",
        "      if subject_kind in known_subjects_dict:\n",
        "        rendering_name = known_subjects_dict[subject_kind]\n",
        "      else:\n",
        "        rendering_name = '–ø—Ä–æ—á–µ–µ'\n",
        "\n",
        "      display(\n",
        "        HTML(f'–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:'\n",
        "             f'<h3 style=\"margin:0\">{rendering_name}<sup> {subject_kind}</sup> </h3> '\n",
        "             f'confidence:{confidence:20,.2f}'))\n",
        "\n",
        "\n",
        "\n",
        "    def sign_to_text(self, sign: int):\n",
        "      if sign < 0: return \" &lt; \"\n",
        "      if sign > 0: return \" &gt; \"\n",
        "      return ' = '\n",
        "\n",
        "    def probable_value_to_html(self, pv):\n",
        "      vc = pv.value\n",
        "      color = '#333333'\n",
        "      if vc.sign > 0:\n",
        "        color = '#993300'\n",
        "      elif vc.sign < 0:\n",
        "        color = '#009933'\n",
        "\n",
        "      return f'<b style=\"color:{color}\">{self.sign_to_text(vc.sign)} {vc.currency} {vc.value:20,.2f} confidence={pv.confidence:20,.2f}</b> '\n",
        "\n",
        "    def render_contents(self, doc):\n",
        "      html = as_headline_3('–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞')\n",
        "      html += \"<ul>\"\n",
        "      for i in doc.structure.headline_indexes:\n",
        "        line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li> {line} <sup>line {i}</sup></li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_sections(self, sections):\n",
        "      from legal_docs import HeadlineMeta\n",
        "      html = as_headline_3('–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞')\n",
        "      html += \"<ul>\"\n",
        "      for section_type in sections:\n",
        "        section: HeadlineMeta = sections[section_type]\n",
        "        body = section.body.untokenize_cc()[:1000]\n",
        "        headline = section.subdoc.untokenize_cc()[:500]\n",
        "        #     line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li><h3> {headline} <sup>type: {section_type}</sup> </h3> <p>{body}</p> </li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_values(self, values):\n",
        "      if len(values) > 0:\n",
        "        for pv in values:\n",
        "          h = self.probable_value_to_html(pv)\n",
        "          display(HTML(h))\n",
        "      else:\n",
        "        display(HTML('—Å—É–º–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'))\n",
        "\n",
        "    def render_value_section_details(self, value_section_info):\n",
        "      value_section = value_section_info.body\n",
        "      headline_doc = value_section_info.subdoc\n",
        "\n",
        "      headline = headline_doc.untokenize_cc()\n",
        "\n",
        "      v_names = {\n",
        "        'value_attention_vector',\n",
        "        'novalue_attention_vector',\n",
        "\n",
        "        'novalue_attention_vector_local_contrast',\n",
        "        'value_attention_vector_tuned'}\n",
        "\n",
        "      fig = plt.figure(figsize=(20, 6))\n",
        "      ax = plt.axes()\n",
        "      for vector_name in v_names:\n",
        "        ax.plot(value_section.distances_per_pattern_dict[vector_name], label=vector_name, alpha=0.4)\n",
        "\n",
        "      ax.plot(value_section.distances_per_pattern_dict['value_attention_vector_tuned'], label='value_attention result',\n",
        "              alpha=0.9, color='black')\n",
        "      plt.legend(loc='upper right')\n",
        "\n",
        "      text = self.to_color_text(value_section.tokens_cc,\n",
        "                                value_section.distances_per_pattern_dict['value_attention_vector_tuned'], _range=(0, 1))\n",
        "      html = f'{ as_headline_3(headline)} <div style=\"margin-left:4em; font-size=90%\">{text}</div>'\n",
        "      display(HTML(html))\n",
        "\n",
        "     \n",
        "    def render_charter_parsing_results_2(self, charter):\n",
        "      display(HTML(self.charter_parsing_results_to_html(charter)))\n",
        "      \n",
        "    def render_charter_parsing_results(self, doc, org, rz, charity_constraints):\n",
        "      WARN = '\\033[1;31m======== Dear Artem, ACHTUNG! üîû '\n",
        "      print (WARN+f\"use {self.render_charter_parsing_results} is deprecated\")\n",
        "      txt_html = self.to_color_text(org['tokens'], org['attention_vector'], _range=[0, 1])\n",
        "\n",
        "      html = '<div style=\"background:#eeeeff; padding:0.5em\"> recognized NE(s): <br><br> org type:<h3 style=\"margin:0\">  {} </h3>org full name:<h2 style=\"margin:0\">  {} </h2> <br>quote: <div style=\"font-size:90%; background:white\">{}</div> </div>'.format(\n",
        "        org['type_name'], org['name'], txt_html)\n",
        "      # html+=txt_html\n",
        "      html += self.render_constraint_values(doc, rz, charity_constraints)\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        " \n",
        "\n",
        "     \n",
        "\n",
        "    \n",
        " \n",
        "\n",
        "  GLOBALS__['renderer'] = DemoRenderer()\n",
        "\n",
        "  # AZ:----------PROTOCOLS RENDERER-------------------------\n",
        "\n",
        "  from legal_docs import LegalDocument\n",
        "\n",
        "  import matplotlib as mpl\n",
        "  from IPython.core.display import display, HTML\n",
        "  from renderer import as_headline_3, as_headline_4\n",
        "  \n",
        "  class ProtocolRenderer(DemoRenderer):\n",
        "\n",
        "    def winning_patterns_to_html(self, _tokens, ranges, winning_patterns, _range,\n",
        "                                 colormaps=['Reds', 'Purples', 'Blues', 'Greens', 'Greys']):\n",
        "      vmin = -ranges[1]\n",
        "      vmax = -ranges[0]\n",
        "\n",
        "      #     print(\"winning_patterns_to_html _range\", _range, \"min max=\", ranges)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmax=vmax, vmin=vmin)\n",
        "\n",
        "      cmaps = []\n",
        "\n",
        "      #     print (colormaps)\n",
        "      for n in colormaps:\n",
        "        cmap = mpl.cm.get_cmap(n)\n",
        "        cmaps.append(cmap)\n",
        "\n",
        "      html = \"\"\n",
        "\n",
        "      for d in _range:\n",
        "        winning_pattern_i = winning_patterns[d][0]\n",
        "        colormap = cmaps[winning_pattern_i % len(colormaps)]\n",
        "        normed = norm(-winning_patterns[d][1])\n",
        "        color = mpl.colors.to_hex(colormap(normed))\n",
        "        html += '<span title=\"' + '{} {:.2f}'.format(d, winning_patterns[d][\n",
        "          1]) + '\" style=\"background-color:' + color + '\">' + str(\n",
        "          _tokens[d]) + \" </span>\"\n",
        "        if _tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "\n",
        "    def _render_doc_subject_fragments(self, doc):\n",
        "      #     print(doc.per_subject_distances)\n",
        "\n",
        "      _html = \"\"\n",
        "      if doc.per_subject_distances is not None:\n",
        "\n",
        "        type = \"–î–æ–≥–æ–≤–æ—Ä  –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è\"\n",
        "        if doc.per_subject_distances[0] > doc.per_subject_distances[1]:\n",
        "          type = \"–î–æ–≥–æ–≤–æ—Ä –≤–æ–∑–º–µ–∑–¥–Ω–æ–≥–æ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥\"\n",
        "\n",
        "        _html += \"<h3>\" + type + \"</h3>\"\n",
        "\n",
        "        colormaps = ['PuRd'] * 5 + ['Blues'] * 7 + ['Greys']\n",
        "\n",
        "        _html += as_headline_4('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞')\n",
        "\n",
        "        for region in [doc.subj_range]:\n",
        "          _html += self.winning_patterns_to_html(_tokens=doc.tokens, ranges=doc.subj_ranges,\n",
        "                                                 winning_patterns=doc.winning_subj_patterns, _range=region,\n",
        "                                                 colormaps=colormaps)\n",
        "\n",
        "      return _html\n",
        "\n",
        "    def render_subject(self, counter):\n",
        "      html = as_headline_3('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (X):') + self.subject_type_weights_to_html(counter)\n",
        "      display(HTML(html))\n",
        "\n",
        "    def print_results(self, _doc: LegalDocument, results=None):\n",
        "\n",
        "      if results is None:\n",
        "        results = _doc.found_sum\n",
        "\n",
        "      result, (start, end), sentence, meta = results\n",
        "\n",
        "      html = \"<hr>\"\n",
        "\n",
        "      html += self._render_doc_subject_fragments(_doc)\n",
        "\n",
        "      if result is None:\n",
        "        html += '<h2 style=\"color:red\">–°–£–ú–ú–ê –ù–ï –ù–ê–ô–î–ï–ù–ê</h2>'\n",
        "      else:\n",
        "        html += '<h2>' + str(result[0]) + ' ' + str(result[1]) + '</h2>'\n",
        "\n",
        "      for key in meta.keys():\n",
        "        html += '<div style=\"font-size:9px\">' + str(key) + \" = \" + str(meta[key]) + \"</div>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "      self.render_color_text(_doc.tokens[start:end], _doc.sums[start:end])\n",
        "\n",
        "    def subject_type_weights_to_html(self, counter):\n",
        "      dict = {\n",
        "        't_dea': '–°–¥–µ–ª–∫–∞',\n",
        "        't_cha': '–ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å',\n",
        "        't_org': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è'\n",
        "      }\n",
        "\n",
        "      maxkey = \"None\"\n",
        "      for key in dict:\n",
        "        if counter[key] > counter[maxkey]:\n",
        "          maxkey = key\n",
        "\n",
        "      html = \"\"\n",
        "      for key in dict:\n",
        "        templ = \"<div>{}: {}</div>\"\n",
        "        if key == maxkey:\n",
        "          templ = '<b style=\"font-size:135%; color:maroon\">{}: {}</b>'\n",
        "        html += templ.format(counter[key], dict[key])\n",
        "\n",
        "      return html\n",
        "\n",
        "  GLOBALS__['ProtocolRenderer'] = ProtocolRenderer()\n",
        "\n",
        "  from demo_protocols import ProtocolAnlysingContext\n",
        "  GLOBALS__['ProtocolAnlysingContext'] = ProtocolAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['ProtocolRenderer'])\n",
        "  GLOBALS__['_init_the_code'] = True\n",
        "\n",
        "  # AZ:-------------------------------------------------Init Protocols context===\n",
        "\n",
        "  # AZ:-------------------------------------------------Init Charters context====\n",
        "\n",
        "  def read_doc(fn):\n",
        "    import docx2txt, sys, os\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    return text\n",
        "\n",
        "  GLOBALS__['read_doc'] = read_doc\n",
        "\n",
        "  print(\"‚ù§Ô∏è DONE initializing the code\")\n",
        "\n",
        "\n",
        "# AZ:-FINDING_VIOLATIONS--------------------------------------------------------\n",
        "def find_and_show_violations():\n",
        "  from IPython.core.display import display, HTML\n",
        "\n",
        "  from contract_parser import ContractAnlysingContext\n",
        "  from renderer import as_headline_2, as_error_html\n",
        "\n",
        "  print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')\n",
        "\n",
        "  charterAnlysingContext: CharterAnlysingContext = GLOBALS__['CharterAnlysingContext']\n",
        "  contractAnlysingContext: ContractAnlysingContext = GLOBALS__['ContractAnlysingContext']\n",
        "\n",
        "  contract = contractAnlysingContext.contract\n",
        "  charter = charterAnlysingContext.doc\n",
        "  charter_constraints = charterAnlysingContext.constraints  # XXX: move to doc\n",
        "\n",
        "  renderer = GLOBALS__['renderer']\n",
        "  renderer.render_subj(contract)\n",
        "\n",
        "  import copy\n",
        "\n",
        "  def convert(v):\n",
        "    v_converted = copy.copy(v)\n",
        "    if v.currency in currency_converter:\n",
        "      v_converted.value = currency_converter[v.currency] * v.value\n",
        "      v_converted.currency = 'RUB'\n",
        "      return v_converted\n",
        "    else:\n",
        "      display(HTML(as_error_html(\n",
        "        f\"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?\")))\n",
        "      return v\n",
        "\n",
        "  best_value = contractAnlysingContext.find_contract_best_value(convert)\n",
        "\n",
        "  # rendering:----------------------------\n",
        "\n",
        "  def _render_violations(ranges_by_group, best_value):\n",
        "    for group_key in ranges_by_group:\n",
        "      group = ranges_by_group[group_key]\n",
        "      display(HTML(as_headline_2(group['name'])))\n",
        "\n",
        "      for rk in group['ranges']:\n",
        "        r = group['ranges'][rk]\n",
        "        display(HTML(r.check_contract_value(best_value, convert, renderer)))\n",
        "\n",
        "  print(\"–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:\")\n",
        "  renderer.render_values([best_value])\n",
        "  renderer.render_color_text(best_value.value.context.tokens, best_value.value.context.attention, _range=[0, 1])\n",
        "\n",
        "  _render_violations(\n",
        "    charterAnlysingContext.find_ranges_by_group(charter_constraints, convert, verbose=False),\n",
        "    best_value)\n",
        "\n",
        "#   display(HTML(renderer.render_constraint_values(charter_constraints)))\n",
        "\n",
        "\n",
        "# AZ:--------------------------------------------------------FINDING_VIOLATIONS-\n",
        "\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0425 00:41:08.293641 140385638020992 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "QDIDCaXmVuB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ { vertical-output: true, output-height: 800, display-mode: \"form\" }\n",
        "\n",
        "# VI: @artifex from here:\n",
        "import traceback\n",
        "\n",
        "def init_all():\n",
        "  ## do preparation here   \n",
        "  # 1.\n",
        "  _init_import_code_from_gh()\n",
        "  # 2.\n",
        "  _init_embedder()\n",
        "  # 3.\n",
        "  _init_the_code()\n",
        "  # 4.\n",
        "  _init_charters()\n",
        "  # 5.\n",
        "  _init_contracts()\n",
        "\n",
        "\n",
        "def process_charter(tb):\n",
        "  uploaded = interactive_upload('–£—Å—Ç–∞–≤, –æ–Ω –ª–µ–≥ —Å–ø–∞—Ç—å')\n",
        "  try:\n",
        "\n",
        "    _CTX = GLOBALS__['CharterAnlysingContext']\n",
        "    _CTX.verbosity_level=2\n",
        "    _CTX.analyze_charter(uploaded[0], True)\n",
        "\n",
        "    tb.clear_tab()\n",
        "\n",
        "    GLOBALS__['renderer'].render_charter_parsing_results_2(_CTX.charter)\n",
        "    GLOBALS__['renderer'].render_contents(_CTX.doc)\n",
        "  except Exception as e:\n",
        "    print(f\"üí•\\033[1;31m–û—à–∏–±–∫–∞:{e}\\033[1;0m\")\n",
        "    print(traceback.format_exc())\n",
        "\n",
        "def process_contract(tb):\n",
        "  uploaded = interactive_upload('–î–æ–≥–æ–≤–æ—Ä')\n",
        "  tb.clear_tab()\n",
        "\n",
        "  try:\n",
        "    GLOBALS__['ContractAnlysingContext'].analyze_contract(uploaded[0])\n",
        "    doc = GLOBALS__['ContractAnlysingContext'].contract\n",
        "\n",
        "    # tb.clear_tab()\n",
        "\n",
        "    GLOBALS__['renderer'].render_subj(doc)\n",
        "    GLOBALS__['renderer'].render_contents(doc)\n",
        "  except Exception as e:\n",
        "    print(f\"üí•\\033[1;31m–û—à–∏–±–∫–∞:{e}\\033[1;0m\")\n",
        "    print(traceback.format_exc())\n",
        "\n",
        "def compare_with_charter(tb):\n",
        "  tb.clear_tab() \n",
        "  try:\n",
        "    _CTX = GLOBALS__['CharterAnlysingContext']\n",
        "    GLOBALS__['renderer'].render_contents(_CTX.doc)\n",
        "    find_and_show_violations()\n",
        "\n",
        "  except:\n",
        "    print(f\"üí•\\033[1;31m–û—à–∏–±–∫–∞:{sys.exc_info()}\\033[1;0m\")\n",
        "    print(traceback.format_exc())\n",
        "  \n",
        "  \n",
        "def start_wizard(tb):\n",
        "  def step1():\n",
        "    with tb.output_to(0):\n",
        "      print(f\"\\033[1;32m–°–º. —Å–ª–µ–¥—É—é—â–∏–µ —Ç–∞–±—ã\\u2713\")\n",
        "    \n",
        "    b2.render_to(tb, 1, cleartab=True)\n",
        "\n",
        "  def step2():\n",
        "    with tb.output_to(1):      \n",
        "      tb.clear_tab()\n",
        "      process_charter(tb) \n",
        "      \n",
        "      print(f\"\\033[1;32m–£—Å—Ç–∞–≤: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ \\u2713\")  \n",
        "      b2.render()\n",
        "    \n",
        "    b3.render_to(tb, 2, cleartab=True)\n",
        "\n",
        "  def step3():    \n",
        "    with tb.output_to(2):\n",
        "      tb.clear_tab()\n",
        "      process_contract(tb)\n",
        "      \n",
        "      print(f\"\\033[1;32m–î–æ–≥–æ–≤–æ—Ä: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ \\u2713\")  \n",
        "      b3.render()\n",
        "    \n",
        "    b4.render_to(tb, 3, cleartab=True)\n",
        "\n",
        "  def step4():\n",
        "    with tb.output_to(3):\n",
        "\n",
        "      compare_with_charter(tb)\n",
        "      \n",
        "      print(f\"\\033[1;32m–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–π: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ \\u2713\")  \n",
        "      b4.render()\n",
        "    \n",
        "    with tb.output_to(4):\n",
        "      tb.clear_tab()\n",
        "      b5.render()\n",
        "      b6.render()\n",
        "      \n",
        "  def step5():\n",
        "    with tb.output_to(4):\n",
        "      tb.clear_tab()\n",
        "      uploaded = interactive_upload('–ü—Ä–æ—Ç–æ–∫–æ–ª')\n",
        "      try:\n",
        "        GLOBALS__['ProtocolAnlysingContext'].process(uploaded[0])        \n",
        "      except:\n",
        "        print(f\"üí•\\033[1;31m–û—à–∏–±–∫–∞:{sys.exc_info()}\\033[1;0m\")\n",
        "        print(traceback.format_exc())\n",
        "        \n",
        "      print(f\"\\033[1;32m–ü—Ä–æ—Ç–æ–∫–æ–ª: —Å–¥–µ–ª–∞–Ω–æ\\u2713\")  \n",
        "      b5.render()\n",
        "      b6.render()\n",
        "      \n",
        "      \n",
        "  def without_protocol_step5():\n",
        "    with tb.output_to(4):\n",
        "      tb.clear_tab()\n",
        "      print(\"‚ùå\\033[1;31m–ù–∞—Ä—É—à–µ–Ω–∏–µ: –ø—Ä–æ—Ç–æ–∫–æ–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç!\\033[1;0m\")\n",
        "      b5.render()\n",
        "      b6.render()\n",
        "    \n",
        "    \n",
        "                                     \n",
        "  b1 = InvokeButton('–ù–∞—á–Ω—ë–º', step1)\n",
        "  b2 = InvokeButton('–£—Å—Ç–∞–≤...', step2)\n",
        "  b3 = InvokeButton('–î–æ–≥–æ–≤–æ—Ä...', step3)\n",
        "  b4 = InvokeButton('–°—Ä–∞–≤–Ω–∏—Ç—å —Å —É—Å—Ç–∞–≤–æ–º...', step4)\n",
        "  b5 = InvokeButton('–ü—Ä–æ—Ç–æ–∫–æ–ª...', step5)\n",
        "\n",
        "  b6 = InvokeButton('–ü—Ä–æ—Ç–æ–∫–æ–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç', without_protocol_step5)\n",
        "    \n",
        "  \n",
        "  with tb.output_to(0): \n",
        "    try:     \n",
        "      \n",
        "      init_all()\n",
        "      \n",
        "      b1.render()\n",
        "    except:\n",
        "      print(f\"üí•\\033[1;31m–û—à–∏–±–∫–∞:{sys.exc_info()}\\033[1;0m\")\n",
        "      print(traceback.format_exc())\n",
        "\n",
        "\n",
        "\n",
        "tb2 = widgets.TabBar(['–ù–∞—á–∞–ª–æ', '–£—Å—Ç–∞–≤', '–î–æ–≥–æ–≤–æ—Ä', '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —É—Å—Ç–∞–≤–æ–º', '–ü—Ä–æ—Ç–æ–∫–æ–ª', '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–º'], location='top')    \n",
        "start_wizard(tb2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-cWJ3cFRHw6V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded = interactive_upload('–î–æ–≥–æ–≤–æ—Ä –≤ –∑–∞–∫–æ–Ω–µ')\n",
        "\n",
        "GLOBALS__['ContractAnlysingContext'].analyze_contract(uploaded[0])\n",
        "doc = GLOBALS__['ContractAnlysingContext'].contract\n",
        "\n",
        "GLOBALS__['renderer'].render_subj(doc)\n",
        "GLOBALS__['renderer'].render_contents(doc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_5plTF-i9gbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "8578c56e-0ed0-4f33-c36b-8fd8a935e90f"
      },
      "cell_type": "code",
      "source": [
        "#### compare with charter\n",
        "def f0_compare_with_charter():\n",
        "\n",
        "  _CTX = GLOBALS__['CharterAnlysingContext']\n",
        "  # GLOBALS__['renderer'].render_contents(_CTX.doc)\n",
        "  # find_and_show_violations()\n",
        "\n",
        "  contract = GLOBALS__['ContractAnlysingContext'].contract\n",
        "  x = max(contract.subjects, key = lambda p: p.confidence)\n",
        "  print(f'max value: {x.value} {x.value.display_string} prob: {x.confidence} ')\n",
        "  print(f'contract subj: {x.value}')\n",
        "  contract_subj = x.value\n",
        "  #print(f'{contract.contract_values}')\n",
        "  #for cs in contract.contract_values:\n",
        "  #  print(f'value: {cs.value.value} {cs.value.currency} prob: {cs.confidence}')\n",
        "  cv = max(contract.contract_values, key = lambda k: k.value.value)  \n",
        "  print(f'Max contract sum: {cv.value.value} {cv.value.currency} prob: {cs.confidence}')\n",
        "  contract_sum = cv.value.value\n",
        "\n",
        "  from structures import ContractSubject, OrgStructuralLevel\n",
        "  import sys\n",
        "\n",
        "  print('–£—Å—Ç–∞–≤, —è —Å–µ–ª:')\n",
        "  ### TEST ###############################\n",
        "  #contract_subj = ContractSubject.Charity\n",
        "  ########################################\n",
        "\n",
        "  ch = GLOBALS__['CharterAnlysingContext'].charter\n",
        "\n",
        "  DEALS = {ContractSubject.Deal, ContractSubject.Other, ContractSubject.RealEstate}\n",
        "\n",
        "  def in_range(r, v):\n",
        "    if r[1]<0:\n",
        "      return v >= r[0]\n",
        "    else:\n",
        "      return r[0]<=v<=r[1]\n",
        "\n",
        "  ccs = []\n",
        "  for c in ch._constraints:\n",
        "    subj = c.subject_mapping['subj']\n",
        "    if subj == ContractSubject.Lawsuit:\n",
        "      continue\n",
        "\n",
        "    if subj == contract_subj or (contract_subj in DEALS and  subj in DEALS):\n",
        "      print(f'\\t{c.org_level.display_string} {c.subject_mapping[\"subj\"].display_string}')\n",
        "      c_max = -1\n",
        "      c_min = sys.float_info.max\n",
        "      for cc in c.constraints:\n",
        "        print(f'\\t\\tconf:{cc.confidence} val:{cc.value.value} {cc.value.sign} {cc.value.currency}')\n",
        "        if cc.value.sign < 0:\n",
        "          c_max = max(c_max, cc.value.value)\n",
        "        else:\n",
        "          c_min = min(c_min, cc.value.value)\n",
        "\n",
        "      ccs.append((c.org_level, (c_min, c_max)))\n",
        "\n",
        "  ccs = sorted(ccs, key = lambda x: x[0].value, reverse = True)\n",
        "  print(ccs)\n",
        "\n",
        "  need_protocol = False\n",
        "  phrase = ''\n",
        "  if contract_subj == ContractSubject.Charity:\n",
        "    if len(ccs)>0:\n",
        "      phrase = '–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞'\n",
        "      need_protocol = True\n",
        "    else:\n",
        "      phrase = '–í –£—Å—Ç–∞–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–∞ –æ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏'\n",
        "  else:  \n",
        "    ###contract_sum = 500000000\n",
        "    last_org_level = -1\n",
        "    for (org_level, r) in ccs:\n",
        "      if in_range(r, contract_sum):\n",
        "        last_org_level = org_level.value\n",
        "\n",
        "    if last_org_level != -1:\n",
        "      print(f'last level: {OrgStructuralLevel(last_org_level).display_string}')\n",
        "\n",
        "    if last_org_level == OrgStructuralLevel.CEO.value or last_org_level == -1:\n",
        "      phrase = '–û–¥–æ–±—Ä–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è'\n",
        "    else:\n",
        "      phrase = f'–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ: {OrgStructuralLevel(last_org_level).display_string}'\n",
        "      need_protocol = True\n",
        "  \n",
        "  return (phrase, need_protocol)    \n",
        "      \n",
        "print(f_compare_with_charter())"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max value: ContractSubject.Deal –°–¥–µ–ª–∫–∞ prob: 0.7013866702715555 \n",
            "contract subj: ContractSubject.Deal\n",
            "Max contract sum: 156000000.0 RUB prob: 0.6354426155103445\n",
            "–£—Å—Ç–∞–≤, —è —Å–µ–ª:\n",
            "\t–ì–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–µ —Å–æ–±—Ä–∞–Ω–∏–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å\n",
            "\t\tconf:0.0 val:100000000.0 1 RUB\n",
            "\t\tconf:0.0 val:100000000.0 1 RUB\n",
            "\t–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å\n",
            "\t\tconf:0.0 val:50000000.0 1 RUB\n",
            "\t\tconf:0.0 val:100000000.0 -1 RUB\n",
            "\t\tconf:0.0 val:50000000.0 1 RUB\n",
            "\t\tconf:0.0 val:100000000.0 -1 RUB\n",
            "[(<OrgStructuralLevel.ShareholdersGeneralMeeting: 3>, (100000000.0, -1)), (<OrgStructuralLevel.BoardOfDirectors: 2>, (50000000.0, 100000000.0))]\n",
            "last level: –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–µ —Å–æ–±—Ä–∞–Ω–∏–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤\n",
            "('–¢—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ: –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–µ —Å–æ–±—Ä–∞–Ω–∏–µ –∞–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤', True)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}