{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Batch test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "NgEuLsK4kVHX"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vXHjbkIfc8Ws",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Config\n",
        "_git_branch = \"contracts-subj\" #@param {type:\"string\"}\n",
        "GLOBALS__={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSb3bCJFxVp_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Select sections to run: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "#@markdown 1. ### Charters\n",
        "batch_charters = False #@param {type:\"boolean\"}\n",
        "batch_charters_contents = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown 2. ### Protocols\n",
        "batch_protocols = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown 3. ### Contracts\n",
        "\n",
        "batch_contract_contents = False #@param {type:\"boolean\"}\n",
        "batch_contract_find_sections = False #@param {type:\"boolean\"}\n",
        "batch_contracts = True #@param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MN9nfwicwxBJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "''' AZ:-IMPORT CODE GITHUB----------------------------------------------üò∫------ '''\n",
        "import sys\n",
        "\n",
        "\n",
        "def _init_import_code_from_gh():\n",
        "  if 'GLOBALS__' not in globals():\n",
        "    print('adding global GLOBALS__')\n",
        "    global GLOBALS__\n",
        "    GLOBALS__ = {}\n",
        "\n",
        "  if '_init_import_code_from_gh' in GLOBALS__:\n",
        "    print('üëå code already imported from GitHub!')\n",
        "    return\n",
        "\n",
        "  import subprocess\n",
        "  def exec(x):\n",
        "    r = subprocess.check_output(x, shell=True)\n",
        "    r = r.decode('unicode-escape').encode('latin1').decode('utf8')\n",
        "    print(r)\n",
        "\n",
        "  print(f\"fetching code from GitHub.....{_git_branch}\")\n",
        "  try:\n",
        "    exec('rm -r nlp_tools')\n",
        "  except:\n",
        "    pass\n",
        "  exec(f'git clone --single-branch --branch {_git_branch} https://github.com/compartia/nlp_tools.git nlp_tools')\n",
        "\n",
        "  print('ü¶ä GIT revision:')\n",
        "  exec('cd nlp_tools\\ngit rev-list --reverse HEAD | awk \"{ print NR }\" | tail -n 1\\ngit branch\\ngit log -3 --pretty=%B')\n",
        "\n",
        "  sys.path.insert(0, 'nlp_tools')\n",
        "\n",
        "  # self-test\n",
        "  from text_tools import untokenize\n",
        "  print(untokenize(['code', 'imported', 'OK üëç']))\n",
        "\n",
        "  print('installing antiword...')\n",
        "  exec('sudo apt-get install antiword')\n",
        "\n",
        "  print('installing docx2txt...')\n",
        "  exec(\"pip install docx2txt\")\n",
        "\n",
        "  GLOBALS__['_init_import_code_from_gh'] = True\n",
        "\n",
        "  print('‚ù§Ô∏è DONE importing Code fro GitHub')\n",
        "\n",
        "''' AZ:-------------------------------------------------IMPORT CODE GITHUB-üò∫---'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-2Oe-BsTcCIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "\n",
        "# AZ:-INIT ELMO-----------------------------------------------------------------------------------\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "\n",
        "def _import_elmo():\n",
        "  \"\"\"\n",
        "  ACHTUNG!! this method is called later by ElmoEmbedder\n",
        "  \"\"\"\n",
        "  \n",
        "#   if 'elmo' in GLOBALS__:\n",
        "#     print('üëå Tensorflow hub.Module is already imported ')\n",
        "#     return GLOBALS__['elmo']\n",
        "\n",
        "  \n",
        "  elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz',\n",
        "                    trainable=False)  # twitter\n",
        "  print('‚ù§Ô∏è ‚ù§Ô∏è ‚ù§Ô∏è DONE (re)importing Tensorflow hub.Module ')\n",
        "  print('Tensorflow version is', tf.__version__)\n",
        "\n",
        "  return elmo\n",
        "#   GLOBALS__['elmo'] = elmo\n",
        "\n",
        "#   print(GLOBALS__['elmo'].__dict__)\n",
        "#   return GLOBALS__['elmo']\n",
        "\n",
        "\n",
        "# AZ:-INIT EMBEDDER-----------------------------------------------------------------------------------\n",
        "\n",
        "def _init_embedder():\n",
        "  if 'elmo_embedder' in GLOBALS__:\n",
        "    print('üëå Embedder is already created! ')\n",
        "    return\n",
        "\n",
        "\n",
        "  from embedding_tools import ElmoEmbedder\n",
        "  GLOBALS__['elmo_embedder'] = ElmoEmbedder(_import_elmo(), tf, 'elmo', _import_elmo)\n",
        "  \n",
        "  print('‚ù§Ô∏è DONE creating words embedding model')\n",
        "  return GLOBALS__['elmo_embedder']\n",
        "\n",
        "\n",
        "# AZ:-Init chartes context-----------------------------------------------------------------------------------\n",
        "def _init_charters():\n",
        "  if 'CharterAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Charters-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  from charter_parser import CharterDocumentParser\n",
        "  GLOBALS__['CharterAnlysingContext'] = CharterDocumentParser(None)\n",
        "  print('‚ù§Ô∏è DONE initing Charters-related tools and models ')\n",
        "\n",
        "\n",
        "def _init_contracts():\n",
        "  if 'ContractAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Contracts-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  from contract_parser import ContractAnlysingContext\n",
        "  GLOBALS__['ContractAnlysingContext'] = ContractAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['renderer'])\n",
        "  print('‚ù§Ô∏è DONE initing Contracts-related tools and models ')\n",
        "\n",
        "\n",
        "# AZ:- THE CODE----------------------------------------------------------------------------------\n",
        "def _init_the_code():\n",
        "  if '_init_the_code' in GLOBALS__:\n",
        "    print('üëå Code is alredy imported!')\n",
        "    return\n",
        "\n",
        "  from renderer import SilentRenderer\n",
        "\n",
        "  class RendererForBatch(SilentRenderer):\n",
        "    pass\n",
        "\n",
        "  GLOBALS__['renderer'] = RendererForBatch()\n",
        "  GLOBALS__['_init_the_code'] = True\n",
        "\n",
        "  def read_doc(fn):\n",
        "    import docx2txt, sys, os\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    return text\n",
        "\n",
        "  GLOBALS__['read_doc'] = read_doc\n",
        "\n",
        "  print(\"‚ù§Ô∏è DONE initializing the code\")\n",
        "\n",
        "# AZ:---------------------------------------------------------------------------END OF THE THE CODE, See you later\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TKaWFEoWcK_u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## do preparation here   \n",
        "    \n",
        "#1.\n",
        "_init_import_code_from_gh()\n",
        "#2.\n",
        "_init_embedder()\n",
        "#3.\n",
        "_init_the_code()\n",
        "#4. \n",
        "if batch_charters:\n",
        "  _init_charters()\n",
        "if batch_contracts:\n",
        "  _init_contracts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8XT83oIBLzuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sZTskr7JU2E5"
      },
      "cell_type": "markdown",
      "source": [
        "# BATCH\n",
        "–ø–∞–∫–µ—Ç–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —É—Å—Ç–∞–≤–æ–≤, –∑–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ google sheets"
      ]
    },
    {
      "metadata": {
        "id": "CKvUAZujWSPp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Authenticate on Google and mount Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "83ENUGvcVCrC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "google_spread = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ch4V2kirjnte",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "def read_documents(filename_prefix):\n",
        "  texts = {}\n",
        "  for file in glob.glob(filename_prefix+\"*.doc\"):\n",
        "    try:\n",
        "      text = GLOBALS__['read_doc'](file)\n",
        "      texts[file] = text\n",
        "      print(\"good:\", file)\n",
        "    except:\n",
        "      print('WRONG *.doc FILE!!', file)\n",
        "\n",
        "  for file in glob.glob(filename_prefix+\"*.docx\"):\n",
        "    try:\n",
        "      text = GLOBALS__['read_doc'](file)\n",
        "      texts[file] = text\n",
        "      print(\"good:\", file)\n",
        "    except:\n",
        "      print('WRONG *.docx FILE!!', file)\n",
        "      \n",
        "  return texts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MleDegzekAFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import traceback\n",
        "import gc\n",
        "    \n",
        "#-------------------------------------------------------------------------------\n",
        "  \n",
        "import time\n",
        "def run_batch(batch_method, worksheet, filename_prefix, documents) :\n",
        "  \n",
        "\n",
        "\n",
        "#   worksheet.update_cell(1, 1, \"used CONFIG: {}:\".format(str(hyperparameters)))\n",
        "  \n",
        "  \n",
        "  # _row=3\n",
        "\n",
        "  the_row = start_from_row\n",
        "  number_of_files = int(worksheet.cell(1, 1).value)\n",
        "\n",
        "  col = 1\n",
        "  for _row in range(start_from_row, 2 + number_of_files):\n",
        "    gc.collect()\n",
        "\n",
        "    def _clean():\n",
        "      _clean_row(worksheet, the_row, 3, 15)\n",
        "\n",
        "\n",
        "    print(\"=\" * 120)\n",
        "    print(\"=\" * 120)\n",
        "    short_fn = worksheet.cell(_row, 1).value\n",
        "\n",
        "    try:\n",
        "      the_row = int(worksheet.cell(_row, 2).value)\n",
        "    except:\n",
        "      worksheet.update_cell(_row, 2, the_row)\n",
        "      \n",
        "    worksheet.update_cell(the_row, 5, '-PENDING...-')\n",
        "      \n",
        "    _clean_row(worksheet, the_row, 3, 12)\n",
        "    _clean_row(worksheet, the_row+1, 3, 12)\n",
        "    _clean_row(worksheet, the_row+2, 3, 12)\n",
        " \n",
        "\n",
        "    filename = filename_prefix + short_fn\n",
        "    print(_row, '-', the_row, filename)    \n",
        "\n",
        "    \n",
        "    worksheet.update_cell(the_row, col + 2, \"{}: {}\".format(_row, short_fn))\n",
        "    worksheet.update_cell(the_row, col + 3, time.strftime(\"%Y-%m-%d %H:%M\"))\n",
        "    \n",
        "    try:      \n",
        "      #===========================================\n",
        "      the_row = 1 + batch_method(documents, worksheet, filename, the_row, col+4)\n",
        "      #===========================================\n",
        "    except Exception as e:\n",
        "      _, _, tb = sys.exc_info()\n",
        "      traceback.print_tb(tb) # Fixed format\n",
        "      tb_info = traceback.extract_tb(tb)\n",
        "      filename, line, func, text = tb_info[-1]\n",
        "\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      worksheet.update_cell(the_row, col + 11, f'-ERROR- {func} {line} {text} {sys.exc_info()}' )\n",
        "      raise(e)\n",
        "\n",
        "    the_row += 1\n",
        "    worksheet.update_cell(_row + 1, 2, the_row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PhUn2IWFjtCo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CHARTERS"
      ]
    },
    {
      "metadata": {
        "id": "eC8ETJDRQ7OC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if batch_charters: \n",
        "  from charter_patterns import CharterPatternFactory\n",
        "  \n",
        "  CPF = CharterPatternFactory( GLOBALS__[ 'elmo_embedder']  )\n",
        "  print( [ p.name for p in  CPF.patterns]  )\n",
        "  GLOBALS__['CharterAnlysingContext'].pattern_factory = CPF\n",
        "  \n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLK2poLAM7tP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LfLfXF13M80m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Microtest"
      ]
    },
    {
      "metadata": {
        "id": "_tTLwiVK5hMl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "microsample = \"\"\"\n",
        "–û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è\n",
        "\n",
        "1.1. –í —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –Ω–∞—Å—Ç–æ—è—â–∏–º –î–æ–≥–æ–≤–æ—Ä–æ–º –ñ–µ—Ä—Ç–≤–æ–≤–∞—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –ü–æ–ª—É—á–∞—Ç–µ–ª—é –¥–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –≤ —Ä–∞–∑–º–µ—Ä–µ 30 000 (–¢—Ä–∏–¥—Ü–∞—Ç—å —Ç—ã—Å—è—á) —Ä—É–±–ª–µ–π –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "if 'CharterAnlysingContext' in GLOBALS__:\n",
        "  GLOBALS__['CharterAnlysingContext'].analyze_charter(microsample)\n",
        "  print('ok')\n",
        "else:\n",
        "  print('üîû CharterAnlysingContext is NOT initialized, call _init_charters() before')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2NlzCFdnDSw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1"
      ]
    },
    {
      "metadata": {
        "id": "5arOcourob6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# raise error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "41ZYYovxU2E6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ XLS —Ç–∞–±–ª–∏—Ü—ã { run: \"auto\", vertical-output: true, form-width: \"650px\", display-mode: \"both\" }\n",
        "\n",
        "populate_names = False  #@param {type: \"boolean\"}\n",
        "#@markdown - —á–∏—Ç–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ –∏ –∑–∞–Ω–æ—Å–∏—Ç –∏—Ö –∏–º–µ–Ω–∞ –≤ –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü —Ç–∞–±–ª–∏—Ü—ã\n",
        "start_from_row = 2  # @param {type: \"integer\"}\n",
        "#@markdown - —á–∏—Ç–∞–µ—Ç –∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ —Å—Ç–æ–ª–±—Ü–∞ –Ω–∞—á–∏–Ω–∞—è —Å–æ —Å—Ç—Ä–æ–∫–∏  start_from_row (min=2)\n",
        "\n",
        "if start_from_row < 2:\n",
        "  raise Exception()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIXvFGj0t99n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _clean_row(worksheet, r, s, e, fill=''):\n",
        "  for col in range(s, e + 1):\n",
        "    worksheet.update_cell(r, col, fill)\n",
        "  worksheet.update_cell(r, e, '-EOF-')\n",
        "\n",
        "  \n",
        "\n",
        "def _populate_org(orginfo, the_row, col) -> int:\n",
        "  from text_tools import untokenize \n",
        "  worksheet.update_cell(the_row, col , orginfo['name'])\n",
        "  worksheet.update_cell(the_row, col + 1, orginfo['type_name'])\n",
        "#   worksheet.update_cell(the_row, col + 2, orginfo['type'])\n",
        "  worksheet.update_cell(the_row, col + 2, untokenize(orginfo['tokens'])[0:300] )\n",
        "\n",
        "  return the_row+1\n",
        "  \n",
        "  \n",
        " \n",
        "\n",
        "from legal_docs import LegalDocument\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "def render_contents(ws, doc: LegalDocument, _row, _col):\n",
        "  r = _row + 1\n",
        "  col = _col\n",
        "  ws.update_cell(r, col, '–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ')\n",
        "\n",
        "  for n in range(len(doc.structure.headline_indexes) - 1):\n",
        "    i = doc.structure.headline_indexes[n]\n",
        "    i_next = doc.structure.headline_indexes[n + 1]\n",
        "\n",
        "    sline = doc.structure.structure[i]\n",
        "    sline_next = doc.structure.structure[i_next]\n",
        "\n",
        "    line = [\n",
        "      '',#B erase\n",
        "      '',#C\n",
        "      '',#D\n",
        "      str(i),#E\n",
        "      sline.to_string(doc.tokens_cc),#F\n",
        "      sline_next.span[0]-sline.span[1],\n",
        "      sline.line_number,\n",
        "      sline.minor_number,\n",
        "      str(sline.number),\n",
        "      sline.level,\n",
        "      sline._possible_levels[0],\n",
        "      sline.span[1]\n",
        "      \n",
        "    ]\n",
        "    r+=1\n",
        "    \n",
        "    cell_list = ws.range(f'B{r}:N{r}')\n",
        "\n",
        "    i=0\n",
        "    for cell in cell_list:\n",
        "      if i<len(line):\n",
        "        cell.value = line[i]\n",
        "      i+=1\n",
        "\n",
        "    ws.update_cells(cell_list)\n",
        "  \n",
        "  return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hh_aTpC74st_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NgEuLsK4kVHX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Rread all chaters"
      ]
    },
    {
      "metadata": {
        "id": "iDj8yBOJ8qh3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if batch_charters or batch_charters_contents:\n",
        "\n",
        "  charters_filename_prefix='/content/gdrive/My Drive/GazpromOil/Charters/'\n",
        "  charters = read_documents(charters_filename_prefix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J6Uax-wv4_8f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Test population"
      ]
    },
    {
      "metadata": {
        "id": "s6qtgta-5DHH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TEST_POPULATION=False\n",
        "\n",
        "\n",
        "if TEST_POPULATION:\n",
        "  CTX=GLOBALS__['CharterAnlysingContext']\n",
        "  print(CTX.__dict__)\n",
        "  CTX.analyze_charter(charters[charters_filename_prefix + '–ì–ü–ù –£—Å—Ç–∞–≤.docx' ])\n",
        "print('OK')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DDvpVL7B6nQG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "worksheet = google_spread.open('Charter test results').sheet1  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dKdakIJA4-qY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# CTX.doc\n",
        "# CTX.org\n",
        "# CTX.constraints\n",
        "\n",
        "#-------------------------\n",
        "#todo: make renderer\n",
        "from parsing import head_types_dict\n",
        "\n",
        "\n",
        "def _clean(ws, r):\n",
        "    start='C'\n",
        "    end = 'Z'\n",
        "#     end = chr(ord(start) + len(line)-1)\n",
        "    cell_list = ws.range(f'{start}{r}:{end}{r}')\n",
        "    for cell in cell_list:\n",
        "      cell.value = ''\n",
        "    ws.update_cells(cell_list)\n",
        "\n",
        "\n",
        "def _populate_rz(charter, r, col, ws):\n",
        "  from structures import OrgStructuralLevel\n",
        "  from patterns import PatternSearchResult\n",
        "  from renderer import org_level_dict\n",
        "  \n",
        "  def _p(c, val):\n",
        "    try:\n",
        "      ws.update_cell(r, col + c, val)\n",
        "    except:\n",
        "      print(f'cannot update cell {r} {col+c} with value\"{val}\"')\n",
        "\n",
        "      \n",
        "      \n",
        "  for level in OrgStructuralLevel:\n",
        "    constraint_search_results: List[PatternSearchResult] = charter.constraints_by_org_level(level)\n",
        "      \n",
        "    _clean(ws, r)\n",
        "\n",
        "    cell_list = ws.range(f'F{r}:H{r}')\n",
        "    \n",
        "    cell_list[0].value = org_level_dict[level].upper()\n",
        "    cell_list[1].value = \" headline: TODO:\" #+ r_by_head_type['caption'][0:300]     \n",
        "    ws.update_cells(cell_list)\n",
        "     \n",
        "    renderered=0\n",
        "    for sentence in constraint_search_results:      \n",
        "      r = populate_constraints(sentence, r+1, ws)\n",
        "      renderered+=1\n",
        "    if renderered==0:\n",
        "      r+=1\n",
        "      _clean(ws, r)\n",
        "      ws.update_acell(f'G{r}', '–ø—É—Å—Ç–æ—Ç–∞ –ø—É—Å—Ç–æ—Ç—ã –ù–ê–ô–î–ï–ù–ê ‡•ê ‡§ì‡§ô‡•ç‡§ï‡§æ‡§∞ üêº –æ–º —à–∞–Ω—Ç–∏ —à–∞–Ω—Ç–∏  ‡•ê' )\n",
        "      \n",
        "      r+=1\n",
        "    _clean(ws, r)\n",
        "    _clean(ws, r+1)\n",
        "    _clean(ws, r+2)\n",
        "    _clean(ws, r+3)\n",
        "\n",
        "  return r+1\n",
        "\n",
        "\n",
        "from legal_docs import LegalDocument\n",
        "\n",
        "ggg={\n",
        "    'RealEstate':'üêå –ù–µ–ø–æ–¥–≤–∏–∂–Ω–æ—Å—Ç—å',\n",
        "    'Charity':'üôè –ë–ª–∞–≥-–æ—Å—Ç—å',\n",
        "    'Lawsuit':'üè¶ –ò—Å–∫–∏',\n",
        "    'Other':'üëΩ–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—è–∫ (other)'\n",
        "}\n",
        "  \n",
        "def populate_constraints(sentence , row, ws):\n",
        "  subj_type = sentence.subject_mapping[\"subj\"]\n",
        "  _clean(ws, row)\n",
        "        \n",
        "  constraints: List[ValueConstraint] = sentence.constraints\n",
        "  sname = ggg [subj_type.name]\n",
        "  \n",
        "  ws.update_acell(f'G{row}', \" \".join( sentence.tokens[0:200] ))\n",
        "  ws.update_acell(f'F{row}', sname )\n",
        "\n",
        "  \n",
        "  if len(constraints) > 0:\n",
        "    \n",
        "    for pv in constraints: \n",
        "      row+=1\n",
        "      _clean(ws, row)\n",
        "      c = pv.value\n",
        "      if c.value is not None and c.sign is not None:\n",
        "        col= 10 - c.sign * 2\n",
        "        ws.update_cell(row, col, c.value)       \n",
        "        ws.update_cell(row, col+1, c.currency)      \n",
        "  else:\n",
        "    row+=1\n",
        "    _clean(ws, row)\n",
        "\n",
        "    ws.update_acell(f'G{row}', '- —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã -' )\n",
        "    \n",
        "  row+=1\n",
        "  _clean(ws, row)\n",
        "  return row \n",
        "\n",
        "\n",
        "\n",
        "if TEST_POPULATION:\n",
        "  \n",
        "#   _populate_org(CTX.org, 2, 2)  \n",
        "  _populate_rz(CTX.charter, 2, 5, worksheet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0wBv-jvh4_Xc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Gsb4zq2d3nH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def charter_batch_method(documents, worksheet, filename, r, col) -> int:\n",
        "\n",
        "  text = documents[filename]\n",
        "  worksheet.update_acell(f'E{r}', 'Parsing üßö, .... be patient üôè ' )\n",
        "  GLOBALS__['CharterAnlysingContext'].analyze_charter(text)\n",
        "\n",
        "  _clean_row(worksheet, r, col, 20)\n",
        "  _clean_row(worksheet, r+1, col, 20)\n",
        "  _clean_row(worksheet, r+2, col, 20)\n",
        "  \n",
        "  r = _populate_org(GLOBALS__['CharterAnlysingContext'].charter.org, r, col)    \n",
        "  r = _populate_rz(GLOBALS__['CharterAnlysingContext'].charter, r, col+1, worksheet)\n",
        "  \n",
        "  return r + 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def charter_c_batch_method(documents, worksheet, filename, r, col) -> int:\n",
        "\n",
        "  text = documents[filename]\n",
        "  doc = CharterDocument(text)\n",
        "\n",
        "    # 1. find top level structure\n",
        "  doc.parse()\n",
        "\n",
        "\n",
        "  _clean_row(worksheet, r, col, 20)\n",
        "  _clean_row(worksheet, r+1, col, 20)\n",
        "  _clean_row(worksheet, r+2, col, 20)\n",
        "  \n",
        "  r=render_contents(worksheet, doc, r, col)\n",
        "  del doc\n",
        "  \n",
        "  _clean_row(worksheet, r+1, col, 20)\n",
        "  _clean_row(worksheet, r+2, col, 20)\n",
        "  worksheet.update_cell(r+1, 4, 'END of DOC') \n",
        "  worksheet.update_cell(r+3, 4, 'END of ALL') \n",
        "  \n",
        "  \n",
        "  return r + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RKCVjWgHTiJ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ü§¨ populate contents only"
      ]
    },
    {
      "metadata": {
        "id": "3ezRa9hdWrOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(f'batch_charters_contents={batch_charters_contents}')\n",
        "if batch_charters_contents:\n",
        "  for k in charters:\n",
        "    print(k)\n",
        "  \n",
        "  start_from_row=2\n",
        "  worksheet = google_spread.open('Charter test results').worksheet('_contents')\n",
        "\n",
        "  #TAKES TIME=====================================================================\n",
        "  if batch_charters_contents:\n",
        "    run_batch(charter_c_batch_method, worksheet, charters_filename_prefix, charters)\n",
        "  #===============================================================================\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AThqUfNmV2_7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## run batch loop"
      ]
    },
    {
      "metadata": {
        "id": "fBnCP1ffALSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if batch_charters:\n",
        "  worksheet = google_spread.open('Charter test results').sheet1  \n",
        "\n",
        "if populate_names:\n",
        "  import os, sys\n",
        "  _row=2  \n",
        "\n",
        "  # Populate document names\n",
        "  for filename in sorted(charters):\n",
        "    head, tail = os.path.split(filename)  \n",
        "    worksheet.update_cell( _row, 1, tail)\n",
        "\n",
        "    _row+=1\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "#TAKES TIME=====================================================================\n",
        "if batch_charters:\n",
        "  run_batch(charter_batch_method, worksheet, charters_filename_prefix, charters)\n",
        "#==============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XeSkOj16jF7O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CONTRACTS"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZEaU9oR_kk2r"
      },
      "cell_type": "markdown",
      "source": [
        "#### Rread all Contracts"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "m0prkxt5kk2s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "if batch_contracts or batch_contract_contents or batch_contract_find_sections:\n",
        "\n",
        "  contracts_filename_prefix='/content/gdrive/My Drive/GazpromOil/Contracts/'\n",
        "  contracts = read_documents(contracts_filename_prefix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jRKo-uhDkk2t",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "from text_tools import untokenize\n",
        "from renderer import known_subjects_dict\n",
        "from typing import List\n",
        "\n",
        "from contract_parser import ContractDocument3\n",
        "from ml_tools import ProbableValue\n",
        "from renderer import known_subjects_dict\n",
        "from structures import ContractSubject\n",
        "\n",
        "def render_subj(contract: ContractDocument3):\n",
        "  subjects: List[ProbableValue] = contract.subjects\n",
        "\n",
        "  if len(subjects) > 0:\n",
        "    sorted_ = [y for y in sorted(subjects, key=lambda x: -x.confidence)]\n",
        "    subject_kind = sorted_[0].value\n",
        "    confidence = sorted_[0].confidence\n",
        "  else:\n",
        "    subject_kind = ContractSubject.Other\n",
        "\n",
        "  if subject_kind in known_subjects_dict:\n",
        "    rendering_name = known_subjects_dict[subject_kind]\n",
        "  else:\n",
        "    rendering_name = '–ø—Ä–æ—á–µ–µ'\n",
        "\n",
        "  return rendering_name, subject_kind, confidence\n",
        "   \n",
        "  \n",
        "def contract_batch_method(docs, worksheet, filename, r, col) -> int:\n",
        "\n",
        "  text = docs[filename]\n",
        "  CTX = GLOBALS__['ContractAnlysingContext']\n",
        "  doc, values = CTX.analyze_contract(text)\n",
        "\n",
        "  _clean_row(worksheet, r, col, 20)\n",
        "  _clean_row(worksheet, r+1, 3, 20)\n",
        "  _clean_row(worksheet, r+2, 3, 20)\n",
        "  _clean_row(worksheet, r+3, 3, 20)\n",
        "  \n",
        "  quote_col = col\n",
        "  pricequote_col = quote_col+1\n",
        "  \n",
        "  if 'subj' in doc.sections:\n",
        "    section = doc.sections['subj']    \n",
        "    body = section.body.untokenize_cc()[:1000]\n",
        "    headline = section.subdoc.untokenize_cc()[:500]\n",
        "    \n",
        "    worksheet.update_cell(r, quote_col, headline+\"\\n\" +body)\n",
        "  else:\n",
        "    worksheet.update_cell(r, quote_col, '‚ö†Ô∏è —Ä–∞–∑–¥–µ–ª –æ –ø—Ä–µ–¥–º–µ—Ç–µ –ª—é–±–≤–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω')\n",
        "\n",
        "#   subj = doc.subject[0]\n",
        "#   subj_c = doc.subject[1]\n",
        "  \n",
        "  rendering_name, subject_kind, confidence = render_subj(doc)\n",
        "  \n",
        "  worksheet.update_cell(r, pricequote_col+1, confidence)\n",
        "  worksheet.update_cell(r, pricequote_col+2, rendering_name)\n",
        "  \n",
        " \n",
        "  \n",
        "  q=''\n",
        "  \n",
        "  if len(values)>0:\n",
        "    cnt = pricequote_col+2\n",
        "    \n",
        "    for pc in values:      \n",
        "      #saving quotes\n",
        "      c = pc.value\n",
        "      q += untokenize(c.context.tokens)+'\\n'\n",
        "      q = q[0:500]\n",
        "      \n",
        "      \n",
        "\n",
        "    for pc in values:      \n",
        "      c = pc.value\n",
        "      worksheet.update_cell(r+2, cnt+1, c.currency)\n",
        "     \n",
        "      worksheet.update_cell(r+1, cnt, c.sign)       \n",
        "      worksheet.update_cell(r+1, cnt+1, c.value)  \n",
        "      worksheet.update_cell(r+1, cnt+2, pc.confidence)  \n",
        "      \n",
        "      cnt+=3\n",
        "  else:\n",
        "    worksheet.update_cell(r+1, pricequote_col+1, \"‚ö†Ô∏è –Ω–∏—á–µ–≥–æ—à–µ–Ω—å–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!\")   \n",
        "  \n",
        "  q+='\\n\\n'+CTX.get_warings()\n",
        "  worksheet.update_cell(r, pricequote_col, q)  \n",
        "  \n",
        "  return r + 3\n",
        "      \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Vz8g2xivkk2x"
      },
      "cell_type": "markdown",
      "source": [
        "### run batch loop"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bPCaxZYKkk2y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Run Contracts batch { form-width: \"300px\" }\n",
        "\n",
        "start_from_row=14 #@param {type:\"integer\"}\n",
        "if batch_contracts:\n",
        "  worksheet = google_spread.open('Charter test results').worksheet('Contracts')\n",
        "import os\n",
        "  \n",
        "if populate_names or True:\n",
        "\n",
        "  _row=2  \n",
        "\n",
        "  # Populate document names\n",
        "  for filename in sorted(contracts):\n",
        "    head, tail = os.path.split(filename)  \n",
        "    worksheet.update_cell( _row, 1, tail)\n",
        "\n",
        "    _row+=1\n",
        "\n",
        "if batch_contracts:\n",
        "  run_batch(contract_batch_method, worksheet, contracts_filename_prefix, contracts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ICHRCE0mI1vr"
      },
      "cell_type": "markdown",
      "source": [
        "## ü§¨ populate Contract contents only"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tNdiQwqDI1vs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "start_from_row=2 #@param {type:\"integer\"} \n",
        "import os\n",
        "\n",
        "def contract_c_batch_method(docs, filename, r, col) -> int:\n",
        "\n",
        "  text = docs[filename]\n",
        "  doc = LegalDocument(text)\n",
        "  doc.parse()\n",
        "\n",
        "  _clean_row(worksheet, r, col, 20)\n",
        "  _clean_row(worksheet, r+1, col, 20)\n",
        "  _clean_row(worksheet, r+2, col, 20)\n",
        "  \n",
        "  r = render_contents(worksheet, doc, r, col)\n",
        "  del doc\n",
        "  \n",
        "  _clean_row(worksheet, r+1, col, 20)\n",
        "  _clean_row(worksheet, r+2, col, 20)\n",
        "  worksheet.update_cell(r+1, 4, 'END of DOC') \n",
        "  worksheet.update_cell(r+3, 4, 'END of ALL') \n",
        "  \n",
        "  return r + 1\n",
        "\n",
        "\n",
        "\n",
        "print(f'batch_contract_contents={batch_contract_contents}')\n",
        "if batch_contract_contents:\n",
        "  \n",
        "\n",
        "  worksheet = google_spread.open('Charter test results').worksheet('_contents_contracts')\n",
        "  \n",
        "  _row=2  \n",
        "  # Populate document names\n",
        "  for filename in sorted(contracts):\n",
        "    head, tail = os.path.split(filename)  \n",
        "    worksheet.update_cell( _row, 1, tail)\n",
        "    _row+=1\n",
        "\n",
        "  #----------\n",
        "#   batch_contract_find_sections\n",
        "  #----------\n",
        "  \n",
        "\n",
        "  #TAKES TIME=====================================================================\n",
        "  if batch_contract_contents:\n",
        "    run_batch(contract_c_batch_method, worksheet, contracts_filename_prefix, contracts)\n",
        "  #===============================================================================\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5U5LoDA6t7AX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "wxwacDNIt7qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qP6r3ziSt663",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IjAuehjmz6-B"
      },
      "cell_type": "markdown",
      "source": [
        "## ü§¨ populate Contract Sections info üèõ"
      ]
    },
    {
      "metadata": {
        "id": "c9mYPWM5uCjy",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " \n",
        "start_from_row=27 #@param {type:\"integer\"} \n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def populate_sections(ws, sections, _row, _col):\n",
        "  r = _row + 1\n",
        "  col = _col\n",
        "  ws.update_cell(r, col, '–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏')\n",
        "  \n",
        "  \n",
        "  for section_type in sections:\n",
        "    section:HeadlineMeta = sections[section_type]\n",
        "    line=[\n",
        "        section.index,\n",
        "        section.confidence,\n",
        "        section_type,        \n",
        "        section.subdoc.untokenize_cc()[:500],        \n",
        "        len(section.body.tokens),\n",
        "        section.body.untokenize_cc()[:700]\n",
        "        \n",
        "    ]\n",
        "    r+=1\n",
        "    start='E'\n",
        "    end = chr(ord(start) + len(line)-1)\n",
        "    cell_list = ws.range(f'{start}{r}:{end}{r}')\n",
        "\n",
        "    i=0\n",
        "    for cell in cell_list:\n",
        "      cell.value = line[i]\n",
        "      i+=1\n",
        "\n",
        "    ws.update_cells(cell_list)\n",
        "\n",
        "  \n",
        "\n",
        "  return r\n",
        "  \n",
        "  \n",
        "  \n",
        "def contract_sections_batch_method(docs, filename, r, col) -> int:\n",
        "\n",
        " \n",
        "  CTX = GLOBALS__['ContractAnlysingContext']\n",
        "  doc = LegalDocument( docs[filename] )\n",
        "  doc.parse()\n",
        "  CTX.contract = doc\n",
        "  print(\"1000 TOKENS:\",CTX.contract.untokenize()[0:1000])\n",
        "  CTX.contract.embedd(CTX.hadlines_factory)\n",
        "  CTX._logstep(\"parsing document and detecting document high-level structure\")\n",
        "\n",
        "  sections = CTX.sections_finder.find_sections(doc, \n",
        "                             CTX.hadlines_factory, \n",
        "                             CTX.hadlines_factory.headlines,\n",
        "                             headline_patterns_prefix='headline.')\n",
        "\n",
        "  \n",
        "\n",
        "  _clean_row(worksheet, r, col, 20)\n",
        "  _clean_row(worksheet, r+1, col, 20)\n",
        "  _clean_row(worksheet, r+2, col, 20)\n",
        "  \n",
        "  r = populate_sections(worksheet, sections, r, col)\n",
        "  CTX._reset_context()\n",
        "  del doc\n",
        "  \n",
        "  _clean_row(worksheet, r+1, 3, 20)\n",
        "  _clean_row(worksheet, r+2, 3, 20)\n",
        "  _clean_row(worksheet, r+3, 3, 20)\n",
        "  _clean_row(worksheet, r+4, 3, 20)\n",
        "  worksheet.update_cell(r+2, 4, 'END of DOC') \n",
        "  worksheet.update_cell(r+3, 4, 'END of ALL') \n",
        "  \n",
        "  return r + 1\n",
        "\n",
        "\n",
        "\n",
        "print(f'batch_contract_find_sections={batch_contract_find_sections}')\n",
        "if batch_contract_find_sections:\n",
        "  _init_contracts()\n",
        "  CTX = GLOBALS__['ContractAnlysingContext']\n",
        "  from sections_finder import FocusingSectionsFinder\n",
        "  assert CTX is not None\n",
        "  \n",
        "  sf = FocusingSectionsFinder(CTX)\n",
        "  CTX.sections_finder = sf\n",
        "\n",
        "  worksheet = google_spread.open('Charter test results').worksheet('_contracts_contents_focus')\n",
        "  \n",
        "  _row=2  \n",
        "  # Populate document names\n",
        "  for filename in sorted(contracts):\n",
        "    head, tail = os.path.split(filename)  \n",
        "    worksheet.update_cell( _row, 1, tail)\n",
        "    _row+=1\n",
        "\n",
        "  #----------\n",
        "#   batch_contract_find_sections\n",
        "  #----------\n",
        "  \n",
        "\n",
        "#TAKES TIME=====================================================================\n",
        "if batch_contract_find_sections:\n",
        "  run_batch(contract_sections_batch_method, worksheet, contracts_filename_prefix, contracts)\n",
        "#===============================================================================\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IYMgObyTKr5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CTX.__dict__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJFsh02OJXQF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nV0urWG3M9Vw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Experiments"
      ]
    },
    {
      "metadata": {
        "id": "M233TAfPTDhE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raise stop here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUhSeBcmNRGx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### rendering (copy)"
      ]
    },
    {
      "metadata": {
        "id": "eRT626ZcND0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "from IPython.core.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# //import\n",
        "def to_color_text(tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "  if len(tokens) == 0:\n",
        "    return \" - empty -\"\n",
        "  if len(weights) != len(tokens):\n",
        "    raise ValueError(\"number of weights differs weights={} tokens={}\".format(len(weights), len(tokens)))\n",
        "\n",
        "  #   if()\n",
        "  vmin = weights.min()\n",
        "  vmax = weights.max()\n",
        "\n",
        "  if _range is not None:\n",
        "    vmin = _range[0]\n",
        "    vmax = _range[1]\n",
        "\n",
        "  if print_debug:\n",
        "    print(vmin, vmax)\n",
        "\n",
        "  norm = mpl.colors.Normalize(vmin=vmin - 0.5, vmax=vmax)\n",
        "  html = \"\"\n",
        "  cmap = mpl.cm.get_cmap(colormap)\n",
        "\n",
        "  for d in range(0, len(weights)):\n",
        "    word = tokens[d]\n",
        "    if word == ' ':\n",
        "      word = '&nbsp;_ '\n",
        "\n",
        "    html += '<span title=\"{} {:.4f}\" style=\"background-color:{}\">{} </span>'.format(\n",
        "      d,\n",
        "      weights[d],\n",
        "      mpl.colors.to_hex(cmap(norm(weights[d]))),\n",
        "      word)\n",
        "\n",
        "    #     html+='<span style=\"background-color:' +mpl.colors.to_hex(cmap(norm(weights[d]) ))+ '\">' + str(tokens[d]) + \" </span>\"\n",
        "    if tokens[d] == '\\n':\n",
        "      html += \"<br>\"\n",
        "\n",
        "  return html\n",
        "\n",
        "\n",
        "\n",
        "def render_color_text(tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "  html = to_color_text(tokens, weights, colormap, print_debug, _range)\n",
        "  display(HTML(html))\n",
        "      \n",
        "      \n",
        "\n",
        "def render_contents(doc):\n",
        "  html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'\n",
        "  html += \"<ul>\"\n",
        "  for i in doc.structure.headline_indexes:\n",
        "    line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "    html += f'<li> {line} <sup>line {i}</sup></li>'\n",
        "  html += \"</ul>\"\n",
        "\n",
        "  display(HTML(html))\n",
        "\n",
        "\n",
        "def render_sections(sections):\n",
        "  html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'\n",
        "  html += \"<ul>\"\n",
        "  for section_type in sections:\n",
        "    section:HeadlineMeta = sections[section_type]\n",
        "    body = section.body.untokenize_cc()[:1000]\n",
        "    headline = section.subdoc.untokenize_cc()[:500]\n",
        "    #     line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "    html += f'<li><h3> {headline} <sup>type: {section_type}</sup> </h3> <p>{body}</p> </li>'\n",
        "  html += \"</ul>\"\n",
        "\n",
        "  display(HTML(html))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4fRP8ouUelD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## üê©make_headline_attention_vector "
      ]
    },
    {
      "metadata": {
        "id": "5IrhagFfTPt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "CTX = GLOBALS__['ContractAnlysingContext']\n",
        "doc = LegalDocument( contracts['/content/gdrive/My Drive/GazpromOil/Contracts/'+'–î–û–ì–û–í–û–†_–î–µ—Ç—Å–∫–∏–∏ÃÜ –¥–æ–º.docx'] )\n",
        "doc.parse()\n",
        "CTX.contract = doc\n",
        "print(\"1000 TOKENS:\", CTX.contract.untokenize()[0:1000])\n",
        "CTX.contract.embedd(CTX.hadlines_factory)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FY3XQHQBUCfi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "v = CTX.sections_finder.make_headline_attention_vector(doc)\n",
        "headlines_attention_vector = CTX.sections_finder.normalize_headline_attention_vector(v)\n",
        "render_color_text(doc.tokens, headlines_attention_vector)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8APTKjkoXEms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc.calculate_distances_per_pattern(CTX.hadlines_factory, pattern_prefix='headline.', merge=True)\n",
        "headlines_attention_vector_1 = np.ones(len(doc.tokens))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3ZPTS_db8Ze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "from IPython.core.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def mixclr(color_map, dictionary, min_color=None):\n",
        "  \n",
        "  reds = None\n",
        "  greens = None\n",
        "  blues = None\n",
        "  \n",
        "  for c in dictionary:\n",
        "    vector = np.array(dictionary[c])\n",
        "    if reds is None:\n",
        "      reds = np.zeros(len(vector))\n",
        "    if greens is None:\n",
        "      greens = np.zeros(len(vector))\n",
        "    if blues is None:\n",
        "      blues = np.zeros(len(vector))\n",
        "   \n",
        "\n",
        "    vector_color = color_map[c]\n",
        "\n",
        "      \n",
        "    reds += vector * vector_color[0]\n",
        "    greens += vector*vector_color[1]\n",
        "    blues += vector*vector_color[2]\n",
        "\n",
        "#   reds/=len(color_map) \n",
        "#   greens/=len(color_map) \n",
        "#   blues/=len(color_map) \n",
        "  if min_color is not None:\n",
        "    reds+=min_color[0]\n",
        "    greens+=min_color[1]\n",
        "    blues+=min_color[2]\n",
        "  def cut_(x):\n",
        "    up = [ min(i,1) for i in x ]\n",
        "    down = [ max(i,0) for i in x ]\n",
        "    return down\n",
        "  \n",
        "  return np.array([cut_(reds), cut_(greens), cut_(blues)]).T\n",
        "\n",
        "\n",
        "\n",
        "def render_multicolor_text(tokens, vectors, colormap, min_color=None):\n",
        "  colors = mixclr(colormap, vectors, min_color=min_color)\n",
        "  html=''\n",
        "  for i in range(len(tokens)):\n",
        "    c = colors[i]\n",
        "    r= int(255*c[0])\n",
        "    g= int(255*c[1])\n",
        "    b= int(255*c[2])\n",
        "    if tokens[i]=='\\n':\n",
        "      html+='<br>'\n",
        "    html+=f'<span style=\"background:rgb({r},{g},{b});\"> {tokens[i]} </span>'\n",
        "  display(HTML(html))\n",
        "  \n",
        "  \n",
        "  \n",
        "color_map={\n",
        "    'subj':(0.5,0.5,1),\n",
        "    'price':(1,0.5,0.5)\n",
        "}\n",
        "    \n",
        "v =  {\n",
        "    'subj': [1,0,0.5,0],\n",
        "    'price':[0,0.5,0.5,0.9]\n",
        "}\n",
        "\n",
        "render_multicolor_text('lorem ipsum sid amed'.split(' '),  v, color_map, min_color=(0.2,0.2,0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MK5rjCEl9LJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# factory_replacement = ContractHeadlinesPatternFactory(GLOBALS__['elmo_embedder'])\n",
        "# CTX.hadlines_factory=factory_replacement\n",
        "doc.calculate_distances_per_pattern(CTX.hadlines_factory, pattern_prefix='headline.', merge=True)\n",
        "headlines_attention_vector_1 = np.ones(len(doc.tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wj1xkXvZlI6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from patterns import improve_attention_vector\n",
        "def _find_charter_section_start(doc, headline_pattern_prefix, headlines_attention_vector, additional_attention):\n",
        "\n",
        "  assert headlines_attention_vector is not None\n",
        "\n",
        "  vectors = filter_values_by_key_prefix(doc.distances_per_pattern_dict, headline_pattern_prefix)\n",
        "  # v = rectifyed_sum(vectors, 0.3)\n",
        "  v = max_exclusive_pattern(vectors)\n",
        "  v = relu(v, 0.6)\n",
        "\n",
        "  if additional_attention is not None:\n",
        "    additional_attention_s = smooth_safe(additional_attention, 6)\n",
        "    v += additional_attention_s\n",
        "  \n",
        "#   v, _ = improve_attention_vector(doc.embeddings, v, relu_th=0.1)\n",
        "  v *= (headlines_attention_vector+0.1)\n",
        "  if max(v)>0.75:\n",
        "    v, _ = improve_attention_vector(doc.embeddings, v, relu_th=0.0)\n",
        "  \n",
        "  doc.distances_per_pattern_dict[\"ha$.\"+headline_pattern_prefix]=v\n",
        "  return  v\n",
        "\n",
        "\n",
        "# v = _find_charter_section_start(doc, 'headline.subj', headlines_attention_vector, additional_attention=None)\n",
        " \n",
        "\n",
        "\n",
        "mc_ =0.3 \n",
        "color_map={\n",
        "    'subj':(0,0.2,1),\n",
        "    'price':(1,0,0),\n",
        "    'pricecond':(0,1,0),\n",
        "    'forcemajor':(1,1,0)\n",
        "}\n",
        "from ml_tools import *\n",
        "vectors={\n",
        "    'subj': CTX.sections_finder._find_charter_section_start(doc, 'headline.subj', headlines_attention_vector, additional_attention=None)[2],\n",
        "    'price': CTX.sections_finder._find_charter_section_start(doc, 'headline.price', headlines_attention_vector, additional_attention=None)[2],\n",
        "    'pricecond': CTX.sections_finder._find_charter_section_start(doc, 'headline.pricecond', headlines_attention_vector, additional_attention=None)[2],\n",
        "    'pricecond': CTX.sections_finder._find_charter_section_start(doc, 'headline.rights', headlines_attention_vector, additional_attention=None)[2]\n",
        "}\n",
        "\n",
        " \n",
        "render_multicolor_text(doc.tokens, vectors2, color_map, min_color=(0.2,0.2,0.2))\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SHaeSp_HMuty",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Price (experiments)\n"
      ]
    },
    {
      "metadata": {
        "id": "Tps_JoSqOVAc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GLOBALS__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UFwaS24TxcC4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DOC=\"\"\"\n",
        "\n",
        ".1 . –û–±—â–∞—è —Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 41752,62 —Ä—É–±–ª–µ–π ( –°–æ—Ä–æ–∫ –æ–¥–Ω–∞ —Ç—ã—Å—è—á–∞ —Å–µ–º—å—Å–æ—Ç –ø—è—Ç—å–¥–µ—Å—è—Ç –¥–≤–∞ —Ä—É–±–ª—è ) 62 –∫–æ–ø–µ–π–∫–∏ , –≤ —Ç–æ–º —á–∏—Å–ª–µ –ù–î–° ( 18 % ) 6369,05 —Ä—É–±–ª–µ–π ( –®–µ—Å—Ç—å —Ç—ã—Å—è—á —Ç—Ä–∏—Å—Ç–∞ —à–µ—Å—Ç—å–¥–µ—Å—è—Ç –¥–µ–≤—è—Ç—å —Ä—É–±–ª–µ–π ) 05 –∫–æ–ø–µ–µ–∫ , –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º–∏ —Å–º–µ—Ç–Ω—ã–º–∏ —Ä–∞—Å—á–µ—Ç–∞–º–∏ ( –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ‚Ññ‚Ññ1-3 ) . \n",
        "2.2 . –û–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å —Ä–∞–±–æ—Ç –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –ø–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–º —Ä–∞–±–æ—Ç–∞–º , –ø—Ä–∏ —ç—Ç–æ–º –ø–æ—Ä—è–¥–æ–∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–æ–≥–æ–≤–æ—Ä–Ω–æ–π —Ü–µ–Ω—ã –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–µ–∏–∑–º–µ–Ω–Ω—ã–º . –ü–æ–¥—Ä—è–¥—á–∏–∫ —è–≤–ª—è–µ—Ç—Å—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–º –ø–ª–∞—Ç–µ–ª—å—â–∏–∫–æ–º –Ω–∞–ª–æ–≥–æ–≤ –∏ —Å–±–æ—Ä–æ–≤ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ .\n",
        "\"\"\"\n",
        "_init_contracts()\n",
        "\n",
        "from patterns import AbstractPatternFactoryLowCase\n",
        "from legal_docs import rectifyed_sum_by_pattern_prefix\n",
        "from ml_tools import *\n",
        "class ContractValuePatternFactory(AbstractPatternFactoryLowCase):\n",
        "\n",
        "  def __init__(self, embedder):\n",
        "    AbstractPatternFactoryLowCase.__init__(self, embedder)\n",
        "\n",
        "    self._build_sum_patterns()\n",
        "    self.embedd()\n",
        "\n",
        "  def _build_sum_patterns(self):\n",
        "    def cp(name, tuples):\n",
        "      return self.create_pattern(name, tuples)\n",
        "\n",
        "    suffix = '(–º–ª–Ω. —Ç—ã—Å. –º–∏–ª–ª–∏–æ–Ω–æ–≤ —Ç—ã—Å—è—á —Ä—É–±–ª–µ–π –¥–æ–ª–ª–∞—Ä–æ–≤ –∫–æ–ø–µ–µ–∫ –µ–≤—Ä–æ)'\n",
        "    prefix = '—Ä–µ—à–µ–Ω–∏–π –æ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫ '\n",
        "    \n",
        "      \n",
        "\n",
        "    cp('_phrase.1', ('–æ–±—â–∞—è', '—Å—É–º–º–∞', '–¥–æ–≥–æ–≤–æ—Ä–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç'))\n",
        "    \n",
        "    \n",
        "    cp('_sum.work.1', ('–°—Ç–æ–∏–º–æ—Å—Ç—å –†–∞–±–æ—Ç —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç', '0 —Ä—É–±–ª–µ–π', suffix))\n",
        "    cp('_sum.work.2', ('–†–∞—Å—á–µ—Ç—ã –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É. –°—Ç–æ–∏–º–æ—Å—Ç—å –æ–∫–∞–∑—ã–≤–∞–µ–º—ã—Ö —É—Å–ª—É–≥ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç ', '0', suffix))\n",
        "    cp('_sum.work.3', ('–°—Ç–æ–∏–º–æ—Å—Ç—å —Ä–∞—Å—á–µ—Ç–æ–≤ –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–µ–≤—ã—à–∞—Ç—å', '0', suffix))\n",
        "    cp('_sum.work.4', ('–ø–æ—Å–ª–µ –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å—á–µ—Ç–∞ –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç —Å—É–º–º—É –≤ —Ä–∞–∑–º–µ—Ä–µ', '0', suffix))\n",
        "    cp('_sum.work.5', ('–û–±—â–∞—è —Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç', '0', suffix))\n",
        "\n",
        "    cp('sum_neg.phone', ('—Ç–µ–ª–µ—Ñ–æ–Ω', '00-00-00', ''))\n",
        "\n",
        "    cp('sum_neg.penalty', ('—É–ø–ª–∞—á–∏–≤–∞–µ—Ç—Å—è', '—à—Ç—Ä–∞—Ñ', '0 —Ä—É–±–ª–µ–π –∞ —Ç–∞–∫–∂–µ –≤–æ–∑–º–µ—â–∞—é—Ç—Å—è –ø–æ–Ω–µ—Å–µ–Ω–Ω—ã–µ —É–±—ã—Ç–∫–∏'))\n",
        "    cp('sum_neg.3', (\n",
        "      '–í —Å–ª—É—á–∞–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è  —Å—Ä–æ–∫–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –†–∞–±–æ—Ç –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—é , –ó–∞–∫–∞–∑—á–∏–∫ –∏–º–µ–µ—Ç –ø—Ä–∞–≤–æ –≤–∑—ã—Å–∫–∞—Ç—å –ø–µ–Ω–∏ –≤ —Ä–∞–∑–º–µ—Ä–µ',\n",
        "      '0%', '–æ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ –≤–æ–≤—Ä–µ–º—è —ç—Ç–∞–ø–∞ –†–∞–±–æ—Ç –ø–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—é –∑–∞ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å –ø—Ä–æ—Å—Ä–æ—á–∫–∏'))\n",
        "    cp('sum_neg.date.1', ('–≤ —Å—Ä–æ–∫ –Ω–µ –ø–æ–∑–¥–Ω–µ–µ, —á–µ–º –∑–∞ 0 –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö', '–∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö', ' –¥–Ω–µ–π'))\n",
        "    cp('sum_neg.vat', ('–≤ —Ç–æ–º —á–∏—Å–ª–µ', '–ù–î–°', '0 ' + suffix))\n",
        "    cp('sum_neg.date.2', ('–≤ —Ç–µ—á–µ–Ω–∏–µ', '0', '—Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π '))\n",
        "    \n",
        "   \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "from demo import ContractDocument2\n",
        "cvpf = ContractValuePatternFactory(GLOBALS__['elmo_embedder'])\n",
        "\n",
        "ctx = GLOBALS__['ContractAnlysingContext']\n",
        "\n",
        "\n",
        "doc = ContractDocument2(DOC)\n",
        "doc.parse()\n",
        "render_contents(doc)\n",
        "  \n",
        "# embedded_headlines = doc.embedd_headlines(ctx.hadlines_factory)\n",
        "# hl_meta_by_index = doc.match_headline_types(ctx.hadlines_factory.headlines, embedded_headlines, 'headline.', 0.9)\n",
        "# doc.sections = doc.find_sections_by_headlines(hl_meta_by_index)\n",
        "\n",
        "\n",
        "\n",
        "# values = ctx.fetch_value_from_contract(doc)\n",
        "\n",
        "from demo import _try_to_fetch_value_from_section\n",
        "values = _try_to_fetch_value_from_section(doc, cvpf)  \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cj2OZZLtQ9P8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_contract_value_attention_vectors(subdoc):\n",
        "    sumphrase_attention_vector = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, '_phrase')\n",
        "    sumphrase_attention_vector = momentum(sumphrase_attention_vector,0.99)\n",
        "                                                                      \n",
        "    value_attention_vector, _c1 = rectifyed_sum_by_pattern_prefix(subdoc.distances_per_pattern_dict, '_sum.work',\n",
        "                                                                  relu_th=0.4)\n",
        "    value_attention_vector = cut_above(value_attention_vector, 1)\n",
        "    value_attention_vector = relu(value_attention_vector, 0.6)\n",
        "    value_attention_vector = momentum(value_attention_vector, 0.8)\n",
        "\n",
        "    novalue_attention_vector = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, 'sum_neg')\n",
        "     \n",
        "\n",
        "    novalue_attention_vector_local_contrast = relu(novalue_attention_vector, 0.6)\n",
        "    novalue_attention_vector_local_contrast = momentum(novalue_attention_vector_local_contrast, 0.9)\n",
        "\n",
        "    value_attention_vector_tuned = (value_attention_vector - novalue_attention_vector * 0.7)\n",
        "\n",
        "\n",
        "    \n",
        "    value_attention_vector_tuned = (value_attention_vector_tuned + sumphrase_attention_vector)/2\n",
        "    value_attention_vector_tuned = relu(value_attention_vector_tuned, 0.6)\n",
        "     \n",
        "\n",
        "    return {\n",
        "      'sumphrase_attention_vector':sumphrase_attention_vector,\n",
        "      'value_attention_vector': value_attention_vector,\n",
        "      'novalue_attention_vector': novalue_attention_vector,\n",
        "\n",
        "      'novalue_attention_vector_local_contrast': novalue_attention_vector_local_contrast,\n",
        "      'value_attention_vector_tuned': value_attention_vector_tuned,\n",
        "      \n",
        "    }\n",
        "  \n",
        "  \n",
        "interresting_vectors = make_contract_value_attention_vectors(doc)\n",
        "# for k in vectors:\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(20, 7))\n",
        "ax = plt.axes()\n",
        "offf=0\n",
        "for i in interresting_vectors: \n",
        "  print(i)\n",
        "  render_color_text(doc.tokens, interresting_vectors[i], _range=(0,1))\n",
        "  ax.plot(interresting_vectors[i]+offf, label=i, alpha=0.5);\n",
        "  offf+=1\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "\n",
        "# import re\n",
        "# number_re = re.compile(r'\\d+[,.]\\d+')\n",
        "\n",
        "# def split_by_number(tokens: List[str], attention: List[float], threshold):\n",
        "#   # TODO: mind decimals!!\n",
        "\n",
        "#   indexes = []\n",
        "#   last_token_is_number = False\n",
        "#   for i in range(len(tokens)):\n",
        "   \n",
        "    \n",
        "#     if attention[i] > threshold and number_re.findall(tokens[i]) is not None :\n",
        "#       if not last_token_is_number:\n",
        "#         indexes.append(i)\n",
        "#       last_token_is_number = True\n",
        "#     else:\n",
        "#       last_token_is_number = False\n",
        "\n",
        "#   text_fragments = []\n",
        "#   ranges = []\n",
        "#   if len(indexes) > 0:\n",
        "#     for i in range(1, len(indexes)):\n",
        "#       s = indexes[i - 1]\n",
        "#       e = indexes[i]\n",
        "#       text_fragments.append(tokens[s:e])\n",
        "#       ranges.append((s, e))\n",
        "\n",
        "#     text_fragments.append(tokens[indexes[-1]:])\n",
        "#     ranges.append((indexes[-1], len(tokens)))\n",
        "#   return text_fragments, indexes, ranges\n",
        "\n",
        "\n",
        "#### detectign\n",
        "from legal_docs import extract_all_contraints_from_sentence, split_by_number\n",
        "\n",
        "\n",
        "at_vector = interresting_vectors['value_attention_vector_tuned']\n",
        "value_section=doc\n",
        "value_section.distances_per_pattern_dict = {**value_section.distances_per_pattern_dict, **interresting_vectors}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "text_fragments, indexes, ranges = split_by_number(value_section.tokens, at_vector, 0.2)\n",
        "\n",
        "print('text_fragments',text_fragments)\n",
        "print('indexes',indexes)\n",
        "print('ranges',ranges)\n",
        "\n",
        "\n",
        "# values: List[ProbableValue] = extract_all_contraints_from_sentence(value_section,\n",
        "#                                                                        value_section.distances_per_pattern_dict[\n",
        "#                                                                          'value_attention_vector_tuned'])\n",
        "  \n",
        "# for value in values:\n",
        "#   print(value.confidence, value.value.value)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S6WeQHblQXb-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for value in values:\n",
        "  print(value.confidence, value.value.value)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-SbBGzGOhR3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "41ydXLvMhSb-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Subjects (experimental)"
      ]
    },
    {
      "metadata": {
        "id": "qBfXZt802475",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# raise –ù—É-–∫–∞ —Å—Ç–æ–π —Ç—É—Ç!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IeS5LfZ3hZHX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "contracts_filename_prefix='/content/gdrive/My Drive/GazpromOil/Contracts/'\n",
        "contracts = read_documents(contracts_filename_prefix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8kbsM7XOha79",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from demo import ContractDocument2\n",
        "from legal_docs import HeadlineMeta, rectifyed_sum_by_pattern_prefix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "_init_contracts()\n",
        "ctx = GLOBALS__['ContractAnlysingContext']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "subj_subdocs=[]\n",
        "\n",
        "if False:\n",
        "  for c in contracts:\n",
        "    #   print (contracts[c][:200])\n",
        "    print('='*100)\n",
        "    print(c)\n",
        "    print('-'*100)\n",
        "    contract_text = contracts[c]\n",
        "    doc = ContractDocument2(contract_text)\n",
        "    doc.parse()\n",
        "\n",
        "    #====================================\n",
        "    embedded_headlines = doc.embedd_headlines(ctx.hadlines_factory)\n",
        "    hl_meta_by_index = doc.match_headline_types(ctx.hadlines_factory.headlines, embedded_headlines, 'headline.', 0.9)\n",
        "    doc.sections = doc.find_sections_by_headlines(hl_meta_by_index)\n",
        "    #====================================\n",
        "\n",
        "    if False:\n",
        "      render_sections(doc.sections)\n",
        "      render_contents(doc)\n",
        "\n",
        "    if 'subj' in doc.sections:\n",
        "      subj_section=doc.sections['subj']\n",
        "  #     render_sections( {'subj':subj_section} )\n",
        "\n",
        "      subj_ = subj_section.body\n",
        "\n",
        "      #===================\n",
        "  #     subj_.embedd(ctx.subj_factory)\n",
        "  #     subj_.calculate_distances_per_pattern(ctx.subj_factory)\n",
        "  #     r = make_subj_attention_vectors(subj_)\n",
        "      #===================\n",
        "  #     render_color_text(subj_.tokens_cc, r['charity_attention_vector'])\n",
        "\n",
        "      subj_subdocs.append(subj_)\n",
        "    else:\n",
        "      print('‚ö†Ô∏è —Ä–∞–∑–¥–µ–ª –æ –ø—Ä–µ–¥–º–µ—Ç–µ –¥–æ–≥–æ–≤–æ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω')\n",
        "    del doc\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXsSgd9aBKms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wYX_yKGuCJ7Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### subjs"
      ]
    },
    {
      "metadata": {
        "id": "ynvxde77Bn1d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SUBJS =\"\"\"\n",
        "\"–ù–∞—Å—Ç–æ—è—â–µ–µ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –Ω–µ–æ—Ç—ä–µ–º–ª–µ–º–æ–π —á–∞—Å—Ç—å—é –î–æ–≥–æ–≤–æ—Ä–∞.\n",
        "–ù–∞—Å—Ç–æ—è—â–µ–µ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ –≤—Å—Ç—É–ø–∞–µ—Ç –≤ —Å–∏–ª—É —Å –¥–∞—Ç—ã –µ–≥–æ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è –°—Ç–æ—Ä–æ–Ω–∞–º–∏ –∏ –¥–µ–π—Å—Ç–≤—É–µ—Ç –¥–æ –º–æ–º–µ–Ω—Ç–∞ –ø–æ–ª–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –°—Ç–æ—Ä–æ–Ω–∞–º–∏ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –ø–æ –î–æ–≥–æ–≤–æ—Ä—É. \n",
        " \n",
        " –ù–∞—Å—Ç–æ—è—â–µ–µ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–≥–ª–∞—à–µ–Ω–∏–µ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –≤ 3-—Ö —ç–∫–∑–µ–º–ø–ª—è—Ä–∞—Ö, –∏–º–µ—é—â–∏—Ö —Ä–∞–≤–Ω—É—é —Å–∏–ª—É, –æ–¥–∏–Ω —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –ü—Ä–∏–Ω—Ü–∏–ø–∞–ª–∞, –¥–≤–∞ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –¥–ª—è –ì–∞—Ä–∞–Ω—Ç–∞.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "‚ö†Ô∏è —Ä–∞–∑–¥–µ–ª –æ –ø—Ä–µ–¥–º–µ—Ç–µ –ª—é–±–≤–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"1. –ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê.\n",
        "1.1 –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —Å—á–µ—Ç, –≤—ã—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –Ω–∞ –ë–ª–∞–≥–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—è: \n",
        " 1.1.1. –°—á–µ—Ç ‚Ññ 115 –Ω–∞ –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ —Å–ø–æ—Ä—Ç–∏–≤–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è( —Ç–µ–Ω–Ω–∏—Å–Ω—ã–π —Å—Ç–æ–ª, —Ä—É–∫–æ—Ö–æ–¥ —Å –ø–µ—Ä–µ–∫–ª–∞–¥–∏–Ω–∞–º–∏, —à–≤–µ–¥—Å–∫–∞—è —Å—Ç–µ–Ω–∫–∞). –°—Ç–æ–∏–º–æ—Å—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è 80 000,00( –≤–æ—Å–µ–º—å–¥–µ—Å—è—Ç —Ç—ã—Å—è—á —Ä—É–±–ª–µ–π —Ä—É–±–ª–µ–π 00 –∫–æ–ø–µ–µ–∫) —Ä—É–±–ª–µ–π, –ù–î–° –Ω–µ –æ–±–ª–∞–≥–∞–µ—Ç—Å—è.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–î–û–ì–û–í–û–†.\n",
        "–æ –±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–π –ø–æ–º–æ—â–∏ \n",
        "( –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–µ) \n",
        " \n",
        " –≥. –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ \n",
        " ¬´ 17 ¬ª –∏—é–ª—è 2018 –≥–æ–¥. \n",
        " –û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é ¬´ –ì–∞–∑–ø—Ä–æ–º–Ω–µ—Ñ—Ç—å-–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏ ¬ª, –∏–º–µ–Ω—É–µ–º–æ–µ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º ¬´ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å ¬ª, –≤ –ª–∏—Ü–µ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞ –ü–µ—Ç—Ä–æ–≤–∞ –°–µ–º–µ–Ω–∞ –ê–Ω–∞—Ç–æ–ª—å–µ–≤–∏—á–∞, –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –£—Å—Ç–∞–≤–∞, —Å –æ–¥–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, –∏ –§–æ–Ω–¥ ¬´ –û–ª–∏–º–ø ¬ª, –∏–º–µ–Ω—É–µ–º–æ–µ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º ¬´ –ë–ª–∞–≥–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—å ¬ª, –≤ –ª–∏—Ü–µ –ø—Ä–µ–¥—Å–µ–¥–∞—Ç–µ–ª—è –ø—Ä–∞–≤–ª–µ–Ω–∏—è –®–∞—Ä—Ñ–∏–∫–æ–≤ –í–∞–ª–µ—Ä–∏—è –õ—å–≤–æ–≤–∏—á–∞, –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –£—Å—Ç–∞–≤–∞, —Å –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, –∏–º–µ–Ω—É–µ–º—ã–µ —Å–æ–≤–º–µ—Å—Ç–Ω–æ ¬´ –°—Ç–æ—Ä–æ–Ω—ã ¬ª, –∞ –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏ ¬´ –°—Ç–æ—Ä–æ–Ω–∞ ¬ª, –∑–∞–∫–ª—é—á–∏–ª–∏ –Ω–∞—Å—Ç–æ—è—â–∏–π –î–æ–≥–æ–≤–æ—Ä –æ –Ω–∏–∂–µ—Å–ª–µ–¥—É—é—â–µ–º: \n",
        " –ü—Ä–µ–¥–º–µ—Ç –î–æ–≥–æ–≤–æ—Ä–∞ \n",
        " 1.1. ¬´ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å ¬ª –æ–±—è–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥–∞—Ç—å ¬´ –ë–ª–∞–≥–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—é ¬ª –≤ –ø–æ—Ä—è–¥–∫–µ –¥–æ–±—Ä–æ–≤–æ–ª—å–Ω–æ–≥–æ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è –¥–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –≤ —Å—É–º–º–µ 1500000( –æ–¥–∏–Ω –º–∏–ª–ª–∏–æ–Ω –ø—è—Ç—å—Å–æ—Ç —Ç—ã—Å—è—á) —Ä—É–±–ª–µ–π 00 –∫–æ–ø–µ–µ–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–ª–∞—Ç—Ñ–æ—Ä–º—ã ¬´ –û–ª–∏–º–ø ¬ª –ø–æ –ø–æ–¥–¥–µ—Ä–∂–∫–µ —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤ –≤ —Å—Ñ–µ—Ä–µ –≤–∑–∞–∏–º–æ–ø–æ–º–æ—â–∏. \n",
        " –ü—Ä–∞–≤–∞ –∏ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –°—Ç–æ—Ä–æ–Ω \n",
        " ¬´ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å ¬ª –ø–µ—Ä–µ—á–∏—Å–ª—è–µ—Ç –¥–µ–Ω–µ–∂–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –≤ —Å—É–º–º–µ \"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–°—Ç–∞—Ç—å—è 1. –ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê.\n",
        "1.1. –ü–æ —É—Å–ª–æ–≤–∏—è–º –î–æ–≥–æ–≤–æ—Ä–∞ –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É –∑–∞ –ø–ª–∞—Ç—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ –≤–ª–∞–¥–µ–Ω–∏–µ( –∞—Ä–µ–Ω–¥—É) –Ω–µ–¥–≤–∏–∂–∏–º–æ–µ –∏–º—É—â–µ—Å—Ç–≤–æ ‚Äì –ü–æ–º–µ—â–µ–Ω–∏–µ, –∞ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ–º–µ—â–µ–Ω–∏—è –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–ª–∞–¥–µ–Ω–∏–µ –∏ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ —É–ø–ª–∞—á–∏–≤–∞—Ç—å –∞—Ä–µ–Ω–¥–Ω—É—é –ø–ª–∞—Ç—É –≤ –ø–æ—Ä—è–¥–∫–µ –∏ –Ω–∞ —É—Å–ª–æ–≤–∏—è—Ö, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç–æ—è—â–∏–º –î–æ–≥–æ–≤–æ—Ä–æ–º. \n",
        " 1.2. –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å —Ä–∞—Å–ø–æ—Ä—è–∂–∞–µ—Ç—Å—è –ü–æ–º–µ—â–µ–Ω–∏–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø—Ä–∞–≤–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏, –æ —á–µ–º –≤—ã–¥–∞–Ω–æ —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤–æ –æ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–∞–≤–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ —Å–µ—Ä–∏—è –æ—Ç 20-10-2018 –≥–æ–¥ –∑–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–º –Ω–æ–º–µ—Ä–æ–º. \n",
        " 1.3. –¶–µ–ª—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä–æ–º –∞—Ä–µ–Ω–¥—É–µ–º–æ–≥–æ –ü–æ–º–µ—â–µ–Ω–∏—è ‚Äì –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –æ—Ñ–∏—Å–∞, –∫–æ–Ω—Ç–æ—Ä—ã, –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞. –ù–µ –¥–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä–æ–º –ü–æ–º–µ—â–µ–Ω–∏—è –≤ –∏–Ω—ã—Ö —Ü–µ–ª—è—Ö, –≤ —Ç–æ–º —á–∏—Å–ª–µ –≤ —Ü–µ–ª—è—Ö –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –¥–ª—è —Å–∫–ª–∞–¥—Å–∫–∏—Ö —Ü–µ–ª–µ–π, –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∂–∏–ª–æ–≥–æ –ø–æ–º–µ—â–µ–Ω–∏—è, —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ø—Ç–∏—Ü –∏ –∂–∏–≤–æ—Ç–Ω—ã—Ö, —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ—â–µ–π, –∏–∑—ä—è—Ç—ã—Ö –∏–∑ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–≥–æ –æ–±–æ—Ä–æ—Ç–∞, —è–¥–æ–≤–∏—Ç—ã—Ö –∏–ª–∏ –æ–ø–∞—Å–Ω—ã—Ö –≤–µ—â–µ—Å—Ç–≤ –∏–ª–∏ –ø—Ä–µ–¥–º–µ—Ç–æ–≤, –∞ —Ç–∞–∫–∂–µ –∏–Ω–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞, —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –∑–∞–ø—Ä–µ\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê.\n",
        "–í —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –Ω–∞—Å—Ç–æ—è—â–∏–º –¥–æ–≥–æ–≤–æ—Ä–æ–º –ó–∞–ª–æ–≥–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å –ø—Ä–∏–Ω–∏–º–∞–µ—Ç, –∞ –ó–∞–ª–æ–≥–æ–¥–∞—Ç–µ–ª—å –ø–µ—Ä–µ–¥–∞–µ—Ç –≤ –∑–∞–ª–æ–≥ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –ø–æ –æ–ø—Ü–∏–æ–Ω–Ω–æ–º—É –¥–æ–≥–æ–≤–æ—Ä—É ‚Ññ 262/–î –æ—Ç 01-12-2018 –≥–æ–¥, –∑–∞–∫–ª—é—á–µ–Ω–Ω–æ–º—É –≤ –≥–æ—Ä–æ–¥–µ –ú–æ—Å–∫–≤–µ –º–µ–∂–¥—É –ü–æ–∫—É–ø–∞—Ç–µ–ª–µ–º –û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é ¬´ –ì–∞–∑–ø—Ä–æ–º–Ω–µ—Ñ—Ç—å-–†–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏ ¬ª( –î–æ–ª–∂–Ω–∏–∫–æ–º) –∏ –ó–∞–ª–æ–≥–æ–¥–µ—Ä–∂–∞—Ç–µ–ª–µ–º( –ü–æ—Å—Ç–∞–≤—â–∏–∫–æ–º)( –¥–∞–ª–µ–µ ‚Äì–¥–æ–≥–æ–≤–æ—Ä –æ–ø—Ü–∏–æ–Ω–∞), –Ω–µ–¥–≤–∏–∂–∏–º–æ–µ –∏–º—É—â–µ—Å—Ç–≤–æ, —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤ –ø—É–Ω–∫—Ç–µ 1.2. –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –î–æ–≥–æ–≤–æ—Ä–∞. \n",
        " –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º–æ–≥–æ –ü—Ä–µ–¥–º–µ—Ç–æ–º –∑–∞–ª–æ–≥–∞ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 20 000 000( –¥–≤–∞–¥—Ü–∞—Ç—å –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π( –∑–∞–ª–æ–≥–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤ —Ç–æ–º —á–∏—Å–ª–µ –ù–î–° –ø–æ —Å—Ç–∞–≤–∫–µ, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º –†–§). \n",
        " –ü–æ—Å—Ç–∞–≤—â–∏–∫ –æ–±—è–∑—É–µ—Ç—Å—è –æ–±–µ—Å–ø–µ—á–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –≤ —Ä–µ–∑–µ—Ä–≤—É–∞—Ä–∞—Ö –Ω–∞ –æ–±—ä–µ–∫—Ç–∞—Ö –ü–æ–∫—É–ø–∞—Ç–µ–ª—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω–µ—Ñ—Ç–µ–ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ü–æ–∫—É–ø–∞—Ç–µ–ª—é –æ–ø—Ü–∏–æ–Ω –Ω–∞ –∏—Ö –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ —Å —Ü–µ–ª—å—é –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏, –∞ –ü–æ–∫—É–ø–∞—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –æ–±–µ—Å–ø–µ—á–∏—Ç—å –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ—Ñ—Ç–µ–ø—Ä–æ–¥—É–∫—Ç–æ–≤, –ø—Ä–∏–Ω—è—Ç—å –∏—Ö –≤ —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å –∏ –æ–ø–ª–∞—Ç–∏—Ç—å, –ª–∏–±–æ –≤–µ—Ä–Ω—É—Ç—å –ü–æ—Å—Ç–∞–≤—â–∏–∫—É. –û–ø—Ü–∏–æ–Ω –¥–µ–π—Å—Ç–≤—É–µ\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–ü—Ä–µ–¥–º–µ—Ç –î–æ–≥–æ–≤–æ—Ä–∞.\n",
        "1.1. –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ü–æ–º–µ—â–µ–Ω–∏–µ, –Ω–∞—Ö–æ–¥—è—â–µ–µ—Å—è –≤ –∑–¥–∞–Ω–∏–∏ –ø–æ –∞–¥—Ä–µ—Å—É: –≥. –ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥, —É–ª–∏—Ü–∞ –¢–µ–ª—å–º–∞–Ω–∞, –¥–æ–º 20, –∫–æ–º–Ω–∞—Ç–∞ ‚Ññ5. –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –ü–æ–º–µ—â–µ–Ω–∏–µ, –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—é –∞—Ä–µ–Ω–¥–Ω—É—é –ø–ª–∞—Ç—É, –∞ —Ç–∞–∫–∂–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å –¥—Ä—É–≥–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç–æ—è—â–∏–º –¥–æ–≥–æ–≤–æ—Ä–æ–º. \n",
        " 1.2. –û–±—ä–µ–∫—Ç –∞—Ä–µ–Ω–¥—ã –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ –ø–µ—Ä–≤–æ–º —ç—Ç–∞–∂–µ –∑–¥–∞–Ω–∏—è –∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø–æ—ç—Ç–∞–∂–Ω—ã–º –ø–ª–∞–Ω–æ–º –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –ø–æ–º–µ—â–µ–Ω–∏–µ ‚Ññ5 –ø–ª–æ—â–∞–¥—å—é 17,1 –∫–≤. –º.( –¥–∞–ª–µ–µ ¬´ –ü–æ–º–µ—â–µ–Ω–∏–µ ¬ª). –û–±—â–∞—è –ø–ª–æ—â–∞–¥—å –ü–æ–º–µ—â–µ–Ω–∏—è —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 17,1 –∫–≤. –º. –≠–∫—Å–ø–ª–∏–∫–∞—Ü–∏—è( —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–∑ –ø–æ—ç—Ç–∞–∂–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –ö–æ–º–ø–ª–µ–∫—Å–∞) —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏ –ü–æ–º–µ—â–µ–Ω–∏—è —è–≤–ª—è–µ—Ç—Å—è –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º ‚Ññ 1 –∫ –Ω–∞—Å—Ç–æ—è—â–µ–º—É –¥–æ–≥–æ–≤–æ—Ä—É. \n",
        " –°—Ç–æ—Ä–æ–Ω—ã –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ü–æ–º–µ—â–µ–Ω–∏–µ, –ø–æ–¥–ª–µ–∂–∞—â–µ–µ –ø–µ—Ä–µ–¥–∞—á–µ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—ä–µ–∫—Ç–∞ –∞—Ä–µ–Ω–¥—ã. \n",
        " 1.3. –ü—Ä–∞–≤–æ –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—è –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º–æ–µ –≤ –∞—Ä–µ–Ω–¥—É –ü–æ–º–µ—â–µ–Ω–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –°–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤–æ–º –æ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–∞–≤–∞. \n",
        " 1.4. –ü–æ–º–µ—â–µ–Ω–∏–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É –≤ —Ü–µ–ª—è—Ö –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê.\n",
        "1.1 –ü—Ä–æ–¥–∞–≤–µ—Ü –æ–±—è–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥–∞—Ç—å –≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å, –∞ –ü–æ–∫—É–ø–∞—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –∏ –æ–ø–ª–∞—Ç–∏—Ç—å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —É—Å–ª–æ–≤–∏—è–º–∏ –î–æ–≥–æ–≤–æ—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–µ –∏–º—É—â–µ—Å—Ç–≤–æ: –æ–±—ä–µ–∫—Ç—ã, –∑–µ–º–µ–ª—å–Ω—ã–µ —É—á–∞—Å—Ç–∫–∏, –¥–≤–∏–∂–∏–º–æ–µ –∏–º—É—â–µ—Å—Ç–≤–æ: \n",
        " 1.1.1. –ù–µ–∂–∏–ª–æ–µ –∑–¥–∞–Ω–∏–µ( –ê–ó–°), –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ: –Ω–µ–∂–∏–ª–æ–µ –∑–¥–∞–Ω–∏–µ, –ø–ª–æ—â–∞–¥—å 11,4 –∫–≤. –º., –Ω–∞—Ö–æ–¥—è—â–µ–µ—Å—è –ø–æ –∞–¥—Ä–µ—Å—É: –†–æ—Å—Å–∏–π—Å–∫–∞—è –§–µ–¥–µ—Ä–∞—Ü–∏—è, –ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å, —Å–µ–ª–æ –ü–æ–ª–æ–≤–∏–Ω–Ω–æ–µ.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–°—Ç–∞—Ç—å—è 1. –ü–†–ï–î–ú–ï–¢\n",
        "–ó–∞–∫–∞–∑—á–∏–∫ –ø–æ—Ä—É—á–∞–µ—Ç, –∞ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –æ–∫–∞–∑—ã–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –£—Å–ª—É–≥–∏/–†–∞–±–æ—Ç—ã: \n",
        " –£—Å–ª—É–≥–∏ –ø–æ —É–±–æ—Ä–∫–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø–æ–º–µ—â–µ–Ω–∏–π; \n",
        " –£—Å–ª—É–≥–∏ –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—é –≥—Ä—è–∑–µ–∑–∞—â–∏—Ç–Ω—ã—Ö –∫–æ–≤—Ä–æ–≤, –∏—Ö —á–∏—Å—Ç–∫–µ –∏ –∑–∞–º–µ–Ω–µ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –∑–∞—è–≤–æ–∫ –∏–ª–∏ –∏–Ω—ã—Ö –ø–∏—Å—å–º–µ–Ω–Ω—ã—Ö —É–∫–∞–∑–∞–Ω–∏–π –ó–∞–∫–∞–∑—á–∏–∫–∞. –ü–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–º–µ–Ω—ã –≥—Ä—è–∑–µ–∑–∞—â–∏—Ç–Ω—ã—Ö –∫–æ–≤—Ä–æ–≤ —É–∫–∞–∑–∞–Ω—ã –≤ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ ‚Ññ2 –∫ –î–æ–≥–æ–≤–æ—Ä—É. \n",
        " –ú–µ—Å—Ç–æ—Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∏ –ø–ª–æ—â–∞–¥—å –û–±—ä–µ–∫—Ç–∞, –ø–µ—Ä–µ—á–µ–Ω—å –æ–∫–∞–∑—ã–≤–∞–µ–º—ã—Ö –£—Å–ª—É–≥/–†–∞–±–æ—Ç, –æ–±—ä–µ–º –∏ –≥—Ä–∞—Ñ–∏–∫ –æ–∫–∞–∑–∞–Ω–∏—è –£—Å–ª—É–≥/–†–∞–±–æ—Ç –ø–æ —É–±–æ—Ä–∫–µ —É–∫–∞–∑–∞–Ω—ã –≤ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ ‚Ññ 1.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"5. –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø –ö –î–û–ì–û–í–û–†–£.\n",
        "5.1. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ‚Ññ1- –ê–∫—Ç –ø—Ä–∏—ë–º–∞ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è. \n",
        " 5.2. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ‚Ññ2 ‚Äì –°–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–°–†–û–ö –î–ï–ô–°–¢–í–ò–Ø, –ü–û–†–Ø–î–û–ö –ò–ó–ú–ï–ù–ï–ù–ò–Ø –ò –†–ê–°–¢–û–†–ñ–ï–ù–ò–Ø –î–û–ì–û–í–û–†–ê.\n",
        "8.1. –î–æ–≥–æ–≤–æ—Ä –≤—Å—Ç—É–ø–∞–µ—Ç –≤ —Å–∏–ª—É —Å –º–æ–º–µ–Ω—Ç–∞ –µ–≥–æ –ø–æ–¥–ø–∏—Å–∞–Ω–∏—è –æ–±–µ–∏–º–∏ —Å—Ç–æ—Ä–æ–Ω–∞–º–∏ –∏ –¥–µ–π—Å—Ç–≤—É–µ—Ç –¥–æ –ø–æ–ª–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è —Å—Ç–æ—Ä–æ–Ω–∞–º–∏ —Å–≤–æ–∏—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –ø–æ –Ω–µ–º—É, –∞ –≤ —á–∞—Å—Ç–∏ –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏—è —Ä–∞—Å—á–µ—Ç–æ–≤ –¥–æ –ø–æ–ª–Ω–æ–≥–æ –∏—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è. \n",
        " 8.2. –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∏–ª–∏ –¥–æ—Å—Ä–æ—á–Ω–æ–µ —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏–µ –î–æ–≥–æ–≤–æ—Ä–∞ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –ø–æ —Å–æ–≥–ª–∞—à–µ–Ω–∏—é —Å—Ç–æ—Ä–æ–Ω.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"1. –ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞\n",
        "1.1. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç, –∞ –ó–∞–∫–∞–∑—á–∏–∫ –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –ª–∏—Ü, –æ–ø—Ä–µ–¥–µ–ª—è–µ–º—ã—Ö –≤ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ó–∞–∫–∞–∑—á–∏–∫–∞( –¥–∞–ª–µ–µ –ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å) –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ: ¬´ –í–æ–¥–∏—Ç–µ–ª—å –ø–æ –ø–µ—Ä–µ–≤–æ–∑–∫–µ –æ–ø–∞—Å–Ω—ã—Ö –≥—Ä—É–∑–æ–≤ ¬ª: ¬´ –ë–∞–∑–æ–≤—ã–π –∫—É—Ä—Å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ ¬ª, ¬´ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫—É—Ä—Å –ø–æ –ø–µ—Ä–µ–≤–æ–∑–∫–µ –û–ì –≤ —Ü–∏—Å—Ç–µ—Ä–Ω–∞—Ö ¬ª. \n",
        " 1.2. –°—Ä–æ–∫ –æ–±—É—á–µ–Ω–∏—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —É—á–µ–±–Ω—ã–º –ø–ª–∞–Ω–æ–º( –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º –≥—Ä–∞—Ñ–∏–∫–æ–º) —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç: \n",
        " ¬´ –ë–∞–∑–æ–≤—ã–π –∫—É—Ä—Å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ ¬ª- 28 —á–∞—Å–∞; \n",
        " ¬´ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫—É—Ä—Å –ø–æ –ø–µ—Ä–µ–≤–æ–∑–∫–µ –û–ì –≤ —Ü–∏—Å—Ç–µ—Ä–Ω–∞—Ö ¬ª- 16 —á–∞—Å–æ–≤. \n",
        " 1.3. –§–æ—Ä–º–∞ –æ–±—É—á–µ–Ω–∏—è ‚Äì –æ—á–Ω–∞—è. \n",
        " 1.4. –û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —É—Å–ª—É–≥–∏ –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –Ω–∞ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏ –ì–ê–£ –î–ü–û –°–û ¬´ –ê—Ä–º–∞–≤–∏—Ä—Å–∫–∏–π ¬ª, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω–æ–≥–æ –ø–æ –∞–¥—Ä–µ—Å—É: –°–≤–µ—Ä–¥–ª–æ–≤—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å, –≥. –ê—Ä–∞–º–∏–ª—å,.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"1. –ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞\n",
        "–ó–∞–∫–∞–∑—á–∏–∫ –ø–æ—Ä—É—á–∞–µ—Ç –∏ –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç, –∞ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —É—Å–ª—É–≥–∏ –≤ –≤–∏–¥–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ –ó–∞–∫–∞–∑—á–∏–∫–∞( –¥–∞–ª–µ–µ ¬´ –°–ª—É—à–∞—Ç–µ–ª–∏ ¬ª) –ø–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–º –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –æ–±—É—á–µ–Ω–∏—è. \n",
        " –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ, –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å—Ä–æ–∫–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ü—Ä–æ–≥—Ä–∞–º–º–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º —É—á–µ–±–Ω—ã—Ö –∑–∞–Ω—è—Ç–∏–π –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è. \n",
        " –£—Å–ª—É–≥–∏ –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ —Ä–∞–±–æ—Ç–Ω–∏–∫–∞–º –ó–∞–∫–∞–∑—á–∏–∫–∞, –∏–º–µ–Ω—É–µ–º—ã–º –¥–∞–ª–µ–µ ¬´ –°–ª—É—à–∞—Ç–µ–ª–∏ ¬ª, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–æ—Ö–æ–¥—è—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø–æ–¥–∞–Ω–Ω—ã—Ö –ó–∞–∫–∞–∑—á–∏–∫–æ–º –∑–∞—è–≤–æ–∫, –æ—Ñ–æ—Ä–º–ª–µ–Ω–Ω—ã—Ö –ø–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω–æ–π –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º —Ñ–æ—Ä–º–µ.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"1. –ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞\n",
        "1.1. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –æ–∫–∞–∑–∞—Ç—å, –∞ –ó–∞–∫–∞–∑—á–∏–∫ –ø—Ä–∏–Ω—è—Ç—å –∏ –æ–ø–ª–∞—Ç–∏—Ç—å —É—Å–ª—É–≥–∏ –ø–æ —à–∏–Ω–æ–º–æ–Ω—Ç–∞–∂—É –∫–æ–ª–µ—Å( –¥–∞–ª–µ–µ- —É—Å–ª—É–≥–∏) –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–∏—Ö –ó–∞–∫–∞–∑—á–∏–∫—É –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π( –¥–∞–ª–µ–µ- –¢–°), —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –≤ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ ‚Ññ1, –∞ —Ç–∞–∫–∂–µ –¥—Ä—É–≥–∏–µ —É—Å–ª—É–≥–∏ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Å–ø–∏—Å–∫–∞ –≤–∏–¥–æ–≤ —É—Å–ª—É–≥, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –≤ –ü—Ä–µ–π—Å–∫—É—Ä–∞–Ω—Ç–µ —Ü–µ–Ω( –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ ‚Ññ2). –£—Å–ª—É–≥–∏ –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è –ø–æ –∞–¥—Ä–µ—Å—É: –≥. –ß–µ–ª—è–±–∏–Ω—Å–∫, —É–ª–∏—Ü–∞ –†—ã–ª–µ–µ–≤–∞,20/2. \n",
        " 1.2.1. –°—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞ –Ω–µ –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–≤—ã—à–∞—Ç—å 500 000( –ø—è—Ç—å—Å–æ—Ç —Ç—ã—Å—è—á) —Ä—É–±–ª–µ–π. \n",
        " 1.2.2. –û—Ç—á–µ—Ç–Ω—ã–º –ø–µ—Ä–∏–æ–¥–æ–º –ø–æ –Ω–∞—Å—Ç–æ—è—â–µ–º—É –¥–æ–≥–æ–≤–æ—Ä—É —è–≤–ª—è–µ—Ç—Å—è –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–π –º–µ—Å—è—Ü.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"1.–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞\n",
        "1.1.–ü–æ –¥–æ–≥–æ–≤–æ—Ä—É –≤–æ–∑–º–µ–∑–¥–Ω–æ–≥–æ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥ ¬´ –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å ¬ª –æ–±—è–∑—É–µ—Ç—Å—è –æ–∫–∞–∑–∞—Ç—å —É—Å–ª—É–≥–∏, —É–∫–∞–∑–∞–Ω–Ω—ã–µ –≤ –ø—É–Ω–∫—Ç 1.2 –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –¥–æ–≥–æ–≤–æ—Ä–∞, –∞ ¬´ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä ¬ª –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –∏ –æ–ø–ª–∞—Ç–∏—Ç—å —ç—Ç–∏ —É—Å–ª—É–≥–∏. \n",
        " 1.2. ¬´ –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å ¬ª –æ–±—è–∑—É–µ—Ç—Å—è –æ–∫–∞–∑–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ —É—Å–ª—É–≥–∏: \n",
        " –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤ –∞—Ä–µ–Ω–¥—É –ø–ª–∞–≤–∞—Ç–µ–ª—å–Ω—É—é –¥–æ—Ä–æ–∂–∫—É –≤ –±–∞—Å—Å–µ–π–Ω–µ –¥–ª—è –æ–∑–¥–æ—Ä–æ–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–Ω—è—Ç–∏–π ¬´ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä–∞ ¬ª, –∏–º–µ–Ω—É–µ–º—ã–µ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º ¬´ –£—Å–ª—É–≥–∏ ¬ª. \n",
        " 1.3. –ü–æ –Ω–∞—Å—Ç–æ—è—â–µ–º—É –¥–æ–≥–æ–≤–æ—Ä—É ¬´ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É ¬ª –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –¥–æ—Ä–æ–∂–∫–∞ –ø–æ —Å–ª–µ–¥—É—é—â–µ–º—É —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é: \n",
        " –í—Ç–æ—Ä–Ω–∏–∫ 13-00 \n",
        " –ß–µ—Ç–≤–µ—Ä–≥ 13-00 \n",
        " –í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ 13-00 \n",
        " –í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ 18-00 \n",
        " \n",
        " 1.4. –ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø–æ–¥–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–µ –≤ –ø—É–Ω–∫—Ç–µ 1.3. –¥–æ—Ä–æ–∂–∫–∏ –∏ –≤—Ä–µ–º—è —Ä–µ–∑–µ—Ä–≤–∏—Ä—É—é—Ç—Å—è –¥–ª—è ¬´ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä–∞ ¬ª –Ω–∞ —Å—Ä–æ–∫ –Ω–µ –±–æ–ª–µ–µ 3-—Ö( —Ç—Ä–µ—Ö) —Ä–∞–±–æ—á–∏—Ö –¥–Ω–µ–π. –í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ ¬´ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä ¬ª –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π —Å—Ä–æ–∫ –Ω–µ –ø–µ—Ä–µ—á–∏—Å–ª–∏–ª –ø—Ä–µ–¥–æ–ø–ª–∞—Ç—É, –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –∏ –¥–æ—Ä–æ–∂–∫–∏ —Å–Ω–∏–º–∞—é—Ç—Å—è, –∞ –∑–∞–∫–∞–∑ –∞–Ω–Ω—É–ª–∏—Ä—É–µ—Ç—Å—è.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞\n",
        "1.1. ¬´ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å ¬ª –æ–±—è–∑—É–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ó–∞—è–≤–∫–∏ ¬´ –ó–∞–∫–∞–∑—á–∏–∫–∞ ¬ª –æ–∫–∞–∑—ã–≤–∞—Ç—å —É—Å–ª—É–≥–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–º–æ—â–∏ –ø–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ —Å –ø–æ–º–æ—â—å—é —ç–≤–∞–∫—É–∞—Ç–æ—Ä–∞ –≤–≤–µ—Ä–µ–Ω–Ω—ã—Ö –µ–º—É ¬´ –ó–∞–∫–∞–∑—á–∏–∫–æ–º ¬ª –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π —Å –≥—Ä—É–∑–æ–º –∏–ª–∏ –±–µ–∑ –≥—Ä—É–∑–∞( –¥–∞–ª–µ–µ ‚Äì –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç) –≤ –ø—É–Ω–∫—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è, —É–∫–∞–∑–∞–Ω–Ω—ã–π ¬´ –ó–∞–∫–∞–∑—á–∏–∫–æ–º ¬ª –∞ ¬´ –ó–∞–∫–∞–∑—á–∏–∫ ¬ª –æ–±—è–∑—É–µ—Ç—Å—è –æ–ø–ª–∞—Ç–∏—Ç—å –æ–∫–∞–∑–∞–Ω–Ω—ã–µ ¬´ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º ¬ª —É—Å–ª—É–≥–∏. \n",
        " 1.2. ¬´ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å ¬ª –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∫—É –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å–∏–ª–∞–º–∏. –ú–∞—Ä—à—Ä—É—Ç—ã, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –¥–æ—Å—Ç–∞–≤–ª–µ–Ω –∞–≤—Ç–æ—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç, —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤ –ó–∞—è–≤–∫–∞—Ö ¬´ –ó–∞–∫–∞–∑—á–∏–∫–∞ ¬ª.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"1. –ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê.\n",
        "1.1. –ù–∞—Å—Ç–æ—è—â–∏–π –î–æ–≥–æ–≤–æ—Ä —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—â–∏–µ —É—Å–ª–æ–≤–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–ø–ª–µ–∫—Å–∞ —Ä–∞–±–æ—Ç –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –∏–≥—Ä–æ–≤–æ–≥–æ –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤, –≤–∫–ª—é—á–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–π –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏–≥—Ä–æ–≤–æ–≥–æ –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –ø—Ä–æ—Ç–æ—Ç–∏–ø–æ–≤ –Ω–∏–∑–∫–æ–π –∏ –≤—ã—Å–æ–∫–æ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø—É–±–ª–∏–∫–∞—Ü–∏—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∞–≤—Ç–æ—Ä—Å–∫–∏–π –Ω–∞–¥–∑–æ—Ä –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É, –¥–ª—è –Ω—É–∂–¥ –û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é ¬´ –ì–∞–∑–ø—Ä–æ–º–Ω–µ—Ñ—Ç—å-–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏ ¬ª, –∏–º–µ–Ω—É–µ–º—ã–π –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º ¬´ –†–∞–±–æ—Ç—ã ¬ª, –≤ –ø–æ—Ä—è–¥–∫–µ –∏ –Ω–∞ —É—Å–ª–æ–≤–∏—è—Ö, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –≤ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∫ –Ω–∞—Å—Ç–æ—è—â–µ–º—É –î–æ–≥–æ–≤–æ—Ä—É, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –≤ —Å–ª—É—á–∞–µ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –°—Ç–æ—Ä–æ–Ω–∞–º–∏ –ó–∞—è–≤–æ–∫ –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –†–∞–±–æ—Ç, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ–º—ã–µ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–º –ó–∞–∫–∞–∑—á–∏–∫—É –≤ —Ç–µ—á–µ–Ω–∏–µ —Å—Ä–æ–∫–∞ –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –î–æ–≥–æ–≤–æ—Ä–∞. \n",
        " –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –†–∞–±–æ—Ç –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –ø–µ—Ä–µ–¥–∞–µ—Ç –ó–∞–∫–∞–∑—á–∏–∫—É –≥–æ—Ç–æ–≤—ã–µ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤–∏–¥–µ–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∏ –º–∞–∫–µ—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–∞—Ö wmv/wma, mpg, jpeg, png, ai, html –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π, –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê –ò –û–°–ù–û–í–ê–ù–ò–Ø –ï–ì–û –ó–ê–ö–õ–Æ–ß–ï–ù–ò–Ø.\n",
        "–ü–æ –Ω–∞—Å—Ç–æ—è—â–µ–º—É –î–æ–≥–æ–≤–æ—Ä—É –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É –∑–∞ –ø–ª–∞—Ç—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–ª–∞–¥–µ–Ω–∏–µ –∏ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ–¥–≤–∏–∂–∏–º–æ–µ –∏–º—É—â–µ—Å—Ç–≤–æ ‚Äì –Ω–µ–∂–∏–ª–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ, —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤ –ø—É–Ω–∫—Ç 1.2 –î–æ–≥–æ–≤–æ—Ä–∞, –∞ –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–∏–Ω—è—Ç—å –¥–∞–Ω–Ω–æ–µ –Ω–µ–∂–∏–ª–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–ª–∞–¥–µ–Ω–∏–µ –∏ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏ —É–ø–ª–∞—á–∏–≤–∞—Ç—å –∞—Ä–µ–Ω–¥–Ω—É—é –ø–ª–∞—Ç—É –≤ –ø–æ—Ä—è–¥–∫–µ –∏ –Ω–∞ —É—Å–ª–æ–≤–∏—è—Ö, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –Ω–∞—Å—Ç–æ—è—â–∏–º –î–æ–≥–æ–≤–æ—Ä–æ–º. \n",
        " –û–±—ä–µ–∫—Ç–æ–º –ê—Ä–µ–Ω–¥—ã, –ø–µ—Ä–µ–¥–∞–≤–∞–µ–º—ã–º –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –≤–ª–∞–¥–µ–Ω–∏–µ –∏ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ, —è–≤–ª—è–µ—Ç—Å—è –Ω–µ–∂–∏–ª–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω–æ–µ –≤ –∑–¥–∞–Ω–∏–∏, –Ω–∞—Ö–æ–¥—è—â–µ–º—Å—è –ø–æ –∞–¥—Ä–µ—Å—É: –≥. –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, —É–ª–∏—Ü–∞ –ü—Ä–∞–≤–¥—ã, –¥–æ–º 8, –æ—Ñ. 15, –∫–∞–¥–∞—Å—Ç—Ä–æ–≤—ã–π –Ω–æ–º–µ—Ä 11:2222:3333333:45( –¥–∞–ª–µ–µ ‚Äì ¬´ –ó–¥–∞–Ω–∏–µ ¬ª) –Ω–∞ –∑–µ–º–µ–ª—å–Ω–æ–º —É—á–∞—Å—Ç–∫–µ —Å –∫–∞–¥–∞—Å—Ç—Ä–æ–≤—ã–º –Ω–æ–º–µ—Ä–æ–º 11:2222:3333333. –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å –ø–µ—Ä–µ–¥–∞—ë—Ç –ê—Ä–µ–Ω–¥–∞—Ç–æ—Ä—É –Ω–µ–∂–∏–ª–æ–µ –ø–æ–º–µ—â–µ–Ω–∏–µ, –Ω–∞—Ö–æ–¥—è—â–µ–µ—Å—è –≤ –≤—ã—à–µ—É–∫–∞–∑–∞–Ω–Ω–æ–º –ó–¥–∞–Ω–∏–∏, –∞ –∏–º–µ–Ω–Ω–æ: \n",
        "- –ü–æ–º–µ—â–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥—å—é 50( –ø—è—Ç—å–¥–µ—Å—è—Ç) –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –º–µ—Ç—Ä–æ–≤, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω–æ–µ –Ω–∞ 3( —Ç—Ä–µ—Ç—å–µ–º) —ç—Ç–∞–∂–µ –ó–¥–∞–Ω–∏—è \n",
        "( –¥–∞–ª–µ–µ ‚Äì ¬´ –ü–æ–º–µ—â–µ–Ω–∏–µ ¬ª). \n",
        " –ê—Ä–µ–Ω–¥–æ–¥–∞—Ç–µ–ª—å –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –Ω–∞ –º–æ–º–µ–Ω—Ç –∑–∞–∫–ª—é—á–µ–Ω–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –î–æ–≥–æ–≤–æ—Ä–∞, —Å–¥–∞–≤–∞–µ–º–æ–µ –≤\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"–ü–†–ï–î–ú–ï–¢ –î–û–ì–û–í–û–†–ê.\n",
        "–ó–∞–∫–∞–∑—á–∏–∫ –ø–æ—Ä—É—á–∞–µ—Ç, –∞ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è —Å–≤–æ–∏–º–∏ —Å–∏–ª–∞–º–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ä–∞–±–æ—Ç—ã –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –≤—ç–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞ ¬´ –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ SmartSystem ¬ª —Å–æ–≥–ª–∞—Å–Ω–æ –ø–ª–∞–Ω—É-–≥—Ä–∞—Ñ–∏–∫—É( –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 1 –∫ –î–æ–≥–æ–≤–æ—Ä—É) –∏ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é( –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ 2 –∫ –î–æ–≥–æ–≤–æ—Ä—É). \n",
        " –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –æ–±—è–∑—É–µ—Ç—Å—è –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é —Ä–∞–±–æ—Ç ¬´ 21 ¬ª –º–∞—è 2018 –≥–æ–¥–∞. \n",
        " –†–∞–±–æ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –≤ –ø–æ–ª–Ω–æ–º –æ–±—ä–µ–º–µ –∫ ¬´ 31 ¬ª –∏—é–ª—è 2018 –≥–æ–¥–∞. \n",
        " –î–æ–≥–æ–≤–æ—Ä –¥–µ–π—Å—Ç–≤—É–µ—Ç –¥–æ –ø–æ–ª–Ω–æ–≥–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –°—Ç–æ—Ä–æ–Ω–∞–º–∏ —Å–≤–æ–∏—Ö –æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤, –≤–æ–∑–Ω–∏–∫—à–∏—Ö –∏–∑ –î–æ–≥–æ–≤–æ—Ä–∞. \n",
        " –û—Ç–Ω–æ—à–µ–Ω–∏—è, –≤–æ–∑–Ω–∏–∫–∞—é—â–∏–µ –ø–æ –Ω–∞—Å—Ç–æ—è—â–µ–º—É –î–æ–≥–æ–≤–æ—Ä—É, –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Ç—Ä—É–¥–æ–≤—ã–º–∏ –∏ —Ä–µ–≥—É–ª–∏—Ä—É—é—Ç—Å—è –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ –≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –Ω–µ –≤–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —à—Ç–∞—Ç —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ –ó–∞–∫–∞–∑—á–∏–∫–∞, –ø—Ä–∞–≤–∏–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —Ç—Ä—É–¥–æ–≤–æ–≥–æ —Ä–∞—Å–ø–æ—Ä—è–¥–∫–∞, —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ –ó–∞–∫–∞–∑—á–∏–∫–æ–º, –Ω–∞ –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è –Ω–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—é—Ç—Å—è. –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç –ø—Ä–∞–≤, –ª—å–≥–æ—Ç –∏ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–π, –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤—É—é—â–∏–º —Ç—Ä—É–¥–æ–≤—ã–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º –¥–ª—è —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤, –≤—ã–ø–æ–ª–Ω—è—é—â–∏—Ö —Å–≤–æ—é —Ä–∞–±–æ—Ç—É –ø–æ —Ç—Ä—É–¥–æ–≤–æ–º—É –¥–æ–≥–æ–≤–æ—Ä—É( –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É). –ó–∞–∫–∞–∑—á–∏–∫ –Ω–µ –æ–±—è–∑–∞–Ω –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ –ò\"\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BIwtmkAMCMmv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### parsing hardcoded samples"
      ]
    },
    {
      "metadata": {
        "id": "t7VB1g1bBxSu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from legal_docs import LegalDocument\n",
        "\n",
        "SUBJS_ARR=SUBJS.split('\\n\\n')\n",
        "\n",
        "tf.logging.set_verbosity('FATAL')\n",
        "\n",
        "\n",
        "subj_subdocs=[]\n",
        "for s in SUBJS_ARR[15:18]:\n",
        "  print(\"=\"*100)\n",
        "  print(s)\n",
        "  subj_=LegalDocument(s)\n",
        "  subj_.parse()\n",
        "  subj_.embedd(ctx.subj_factory)\n",
        "  subj_.calculate_distances_per_pattern(ctx.subj_factory)\n",
        "  subj_subdocs.append(subj_)\n",
        "#   r = make_subj_attention_vectors(subj_)\n",
        "#   #===================\n",
        "#   render_color_text(subj_.tokens_cc, r['charity_attention_vector'], _range=(0,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "85iB8yseDJX9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_bLgB3A_b6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from ml_tools import *\n",
        "import numpy as np\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "subject_types={\n",
        "    'charity':'–±–ª–∞–≥-–æ—Å—Ç—å'.upper(),\n",
        "    'comm':'–≥—Ä—è–∑–Ω—ã–π –∫–æ–º–º–µ—Ä—Å'.upper(),    \n",
        "    'comm_estate':'–Ω–µ–¥–≤–∏–∂—É—Ö–∞'.upper(),\n",
        "    'comm_service':'–Ω–∞–∫–∞–∑–∞–Ω–∏–µ —É—Å–ª—É–≥'.upper() \n",
        "}\n",
        "\n",
        "subject_types_dict={**subject_types, **{'unknown':'–ø—Ä–µ–¥–º–µ—Ç –Ω–µ —è—Å–µ–Ω'}}\n",
        "\n",
        "\n",
        "# ////////IMPORT\n",
        "def max_exclusive_pattern_by_prefix(distances_per_pattern_dict, prefix ):\n",
        "\n",
        "  sum = None\n",
        "\n",
        "  for p in distances_per_pattern_dict:\n",
        "    if p.startswith(prefix):\n",
        "      x = distances_per_pattern_dict[p]\n",
        "      \n",
        "      if sum is None:\n",
        "        sum = np.zeros(len(x))\n",
        "\n",
        "      sum = np.maximum(sum, x)\n",
        "\n",
        "\n",
        "  return sum\n",
        "\n",
        "\n",
        "def make_subj_attention_vectors(subdoc, subj_types_prefixes):\n",
        "  r={}\n",
        "  for subj_types_prefix in subj_types_prefixes:\n",
        "    attention_vector = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, subj_types_prefix)  \n",
        "    r[ subj_types_prefix+'attention_vector']=attention_vector\n",
        "    if len(attention_vector>0):\n",
        "      attention_vector_l = relu(attention_vector,0.6)\n",
        "      r[ subj_types_prefix+'attention_vector_l']=attention_vector_l\n",
        "    else:\n",
        "      r[ subj_types_prefix+'attention_vector_l']=[]\n",
        "    \n",
        "  return r\n",
        "#   charity_attention_vector = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, 't_charity_')  \n",
        "#   comm_attention_vector = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, 't_comm_' )\n",
        "  \n",
        "  \n",
        "#   comm_attention_vector=momentum(comm_attention_vector, 0.9)\n",
        "\n",
        "#   comm_attention_vector_l = relu(comm_attention_vector,0.6)\n",
        "#   charity_attention_vector_l = relu(charity_attention_vector,0.6)\n",
        "  \n",
        "  \n",
        "#   return{\n",
        "#       'charity_attention_vector':charity_attention_vector,\n",
        "#       'comm_attention_vector':comm_attention_vector,\n",
        "#       'comm_attention_vector_l':comm_attention_vector_l,\n",
        "#       'charity_attention_vector_l':charity_attention_vector_l\n",
        "#   }\n",
        "\n",
        "for subj_ in subj_subdocs:\n",
        "  \n",
        "  prefixes = [f't_{st}_' for st in subject_types ]\n",
        "  r = make_subj_attention_vectors(subj_, prefixes)\n",
        "  \n",
        "  interresting_vectors = [ r[f't_{st}_attention_vector_l'] for  st in subject_types]\n",
        "  \n",
        "  interresting_vectors_means = [np.nanmean(x) for x in interresting_vectors]\n",
        "  interresting_vectors_maxes = [np.nanmax(x) for x in interresting_vectors]\n",
        "  winner_id = np.argmax(interresting_vectors_means)\n",
        "  \n",
        "  winner_t=prefixes[winner_id][2:-1]\n",
        "  \n",
        "  \n",
        "  fig = plt.figure(figsize=(20, 4))\n",
        "  ax = plt.axes()\n",
        "  for i in range(len(interresting_vectors)):    \n",
        "    ax.plot(interresting_vectors[i], label=prefixes[i]);\n",
        "\n",
        "  plt.legend(loc='upper left')\n",
        "    \n",
        "  #===================\n",
        "  \n",
        "  score = interresting_vectors_maxes[winner_id]\n",
        "  if score<0.3:\n",
        "    winner_t = 'unknown'\n",
        "  print(winner_t, interresting_vectors_means[winner_id], score, '*'*80)\n",
        "#   char_m = np.nanmean(r['t_charity_attention_vector_l'])\n",
        "#   comm_m = np.nanmean(r['t_comm_attention_vector_l'])\n",
        "  print(subject_types_dict[winner_t])\n",
        "  if winner_t is not 'unknown':\n",
        "    render_color_text(subj_.tokens_cc, r[f't_{winner_t}_attention_vector_l'], _range=(0,1))\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "00tKFJXf_UDl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "subj_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U3A_sGm0y7_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "raise –ù–µ —É–≤–µ—Ä–µ–Ω, –Ω–µ —Ö–æ–¥–∏"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rb1Ylzhpy8ge",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### batch"
      ]
    },
    {
      "metadata": {
        "id": "aeeNOnUny-Nf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_from_row=2 #@param {type:\"integer\"}\n",
        "worksheet = google_spread.open('Charter test results').worksheet('Contracts')\n",
        "\n",
        "def subj_batch_method(filename, r, col) -> int:\n",
        "\n",
        "  text = contracts[filename]\n",
        "  doc = ContractDocument2(text)\n",
        "  doc.parse()\n",
        "  \n",
        "  embedded_headlines = doc.embedd_headlines(ctx.hadlines_factory)\n",
        "  hl_meta_by_index = doc.match_headline_types(ctx.hadlines_factory.headlines, embedded_headlines, 'headline.', 0.9)\n",
        "  doc.sections = doc.find_sections_by_headlines(hl_meta_by_index)\n",
        "  \n",
        "  render_sections(doc.sections)\n",
        "\n",
        "#   doc, values = GLOBALS__['ContractAnlysingContext'].analyze_contract(text)\n",
        "\n",
        "  if 'subj' in doc.sections:\n",
        "    section = doc.sections['subj']\n",
        "    \n",
        "    render_sections( {'subj':section} )\n",
        "    \n",
        "    body = section.body.untokenize_cc()[:1000]\n",
        "    headline = section.subdoc.untokenize_cc()[:500]\n",
        "    worksheet.update_cell(r, col, headline+\"\\n\" +body)\n",
        "  else:\n",
        "    worksheet.update_cell(r, col, '‚ö†Ô∏è —Ä–∞–∑–¥–µ–ª –æ –ø—Ä–µ–¥–º–µ—Ç–µ –ª—é–±–≤–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω')\n",
        "#     render_sections( {'subj':subj_section} )\n",
        "  \n",
        " \n",
        "  \n",
        "#   if len(values)>0:\n",
        "#     cnt=1\n",
        "#     for c in values:      \n",
        "#       worksheet.update_cell(r+2, col + cnt+1, c.currency)\n",
        "#       worksheet.update_cell(r+1, col + cnt, c.sign)       \n",
        "#       worksheet.update_cell(r+1, col + cnt+1, c.value)       \n",
        "      \n",
        "#       cnt+=2\n",
        "#   else:\n",
        "#     worksheet.update_cell(r, col, \"–Ω–∏—á–µ–≥–æ—à–µ–Ω—å–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!\")   \n",
        "  \n",
        "  return r + 3\n",
        "  \n",
        "  \n",
        "  \n",
        "run_batch(subj_batch_method, worksheet, contracts_filename_prefix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4LO2g04PhPa_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Garbage"
      ]
    },
    {
      "metadata": {
        "id": "Yi0yZHbPsXHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SAMPLE=\"\"\"\n",
        " \n",
        "\n",
        "–û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "–£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª\n",
        "\n",
        "\n",
        "xxvii –£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª –û–±—â–µ—Å—Ç–≤–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∏–∑ –Ω–æ–º–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–æ–ª–µ–π –µ–≥–æ –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç  6 734 244 615 (–®–µ—Å—Ç—å –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ —Å–µ–º—å—Å–æ—Ç —Ç—Ä–∏–¥—Ü–∞—Ç—å —á–µ—Ç—ã—Ä–µ –º–∏–ª–ª–∏–æ–Ω–∞ –¥–≤–µ—Å—Ç–∏ —Å–æ—Ä–æ–∫ —á–µ—Ç—ã—Ä–µ —Ç—ã—Å—è—á–∏ —à–µ—Å—Ç—å—Å–æ—Ç –ø—è—Ç–Ω–∞–¥—Ü–∞—Ç—å) —Ä—É–±–ª–µ–π.\n",
        "\n",
        "\n",
        "\n",
        "xxxv –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–µ –≤–ø—Ä–∞–≤–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—Ä–∏–±—ã–ª–∏ –û–±—â–µ—Å—Ç–≤–∞ –º–µ–∂–¥—É –£—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ –û–±—â–µ—Å—Ç–≤–∞:\n",
        "\n",
        "       ‚Ä¢ –¥–æ –ø–æ–ª–Ω–æ–π –æ–ø–ª–∞—Ç—ã –≤—Å–µ–≥–æ —É—Å—Ç–∞–≤–Ω–æ–≥–æ –∫–∞–ø–∏—Ç–∞–ª–∞ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "\n",
        "     \n",
        "\n",
        "–û—Ä–≥–∞–Ω—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n",
        "\n",
        "\n",
        "lxxxiv –û—Ä–≥–∞–Ω–∞–º–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è—é—Ç—Å—è:\n",
        "\n",
        "\n",
        "       ‚Ä¢ –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "\n",
        "\n",
        "       ‚Ä¢ –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ ‚Äì –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è;\n",
        "\n",
        "\n",
        "       ‚Ä¢ –ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ - –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω;\n",
        "\n",
        "\n",
        "       ‚Ä¢ –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä - –ï–¥–∏–Ω–æ–ª–∏—á–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω.\n",
        "\n",
        "\n",
        "–û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞\n",
        "\n",
        "\n",
        "lxxxvi –í—ã—Å—à–∏–º –æ—Ä–≥–∞–Ω–æ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è–µ—Ç—Å—è –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞. –û—á–µ—Ä–µ–¥–Ω–æ–µ –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞  —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –∏ —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –û–±—â–µ—Å—Ç–≤–∞ –∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –≥–æ–¥ –∏ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –≤ –ø–µ—Ä–∏–æ–¥ —Å 1 –º–∞—Ä—Ç–∞ –ø–æ 30 –∞–ø—Ä–µ–ª—è. –ü—Ä–æ–≤–æ–¥–∏–º—ã–µ –ø–æ–º–∏–º–æ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ –û–±—â–∏–µ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è—é—Ç—Å—è –≤–Ω–µ–æ—á–µ—Ä–µ–¥–Ω—ã–º–∏. –í–Ω–µ–æ—á–µ—Ä–µ–¥–Ω—ã–µ –û–±—â–∏–µ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –ø—Ä–æ–≤–æ–¥—è—Ç—Å—è –≤ —Å–ª—É—á–∞—è—Ö, –∫–æ–≥–¥–∞ —ç—Ç–æ–≥–æ —Ç—Ä–µ–±—É—é—Ç –∏–Ω—Ç–µ—Ä–µ—Å—ã –û–±—â–µ—Å—Ç–≤–∞.\n",
        "\n",
        "\n",
        "lxxxvii –ö –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –æ—Ç–Ω–æ—Å—è—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:\n",
        "\n",
        "    \n",
        "\n",
        "       12) —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞, —Å–æ—Å—Ç–∞–≤–∞, —Ñ–æ—Ä–º—ã –∏ –ø–æ—Ä—è–¥–∫–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç–∞–∫–∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤, –∞ —Ç–∞–∫–∂–µ –∏–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π –≤–Ω–µ—Å–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤ –£—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "       13) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –ø—Ä—è–º–æ –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ –∏–º—É—â–µ—Å—Ç–≤–∞, —Ü–µ–Ω–∞ –∏–ª–∏ –±–∞–ª–∞–Ω—Å–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 25 (–î–≤–∞–¥—Ü–∞—Ç—å –ø—è—Ç—å) –∏ –±–æ–ª–µ–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ø–æ –¥–∞–Ω–Ω—ã–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –æ—Ç—á–µ—Ç–Ω—É—é –¥–∞—Ç—É;\n",
        "       14) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, –≤ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –∏–º–µ–µ—Ç—Å—è –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ —Ü–µ–Ω–∞ –∏–ª–∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –∏–º—É—â–µ—Å—Ç–≤–∞, —è–≤–ª—è—é—â–µ–≥–æ—Å—è –ø—Ä–µ–¥–º–µ—Ç–æ–º —Å–¥–µ–ª–∫–∏,  –ø—Ä–µ–≤—ã—à–∞–µ—Ç 10 (–¥–µ—Å—è—Ç—å) –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤  –±–∞–ª–∞–Ω—Å–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ø–æ –¥–∞–Ω–Ω—ã–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –æ—Ç—á–µ—Ç–Ω—É—é –¥–∞—Ç—É.\n",
        "       15) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "       26) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫ –º–µ–Ω—ã, –¥–∞—Ä–µ–Ω–∏—è, –∏–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞—é—â–∏—Ö –±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–µ –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ª–∏–±–æ –æ–ø–ª–∞—Ç—É (–≤—Å—Ç—Ä–µ—á–Ω–æ–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ) –≤ –Ω–µ–¥–µ–Ω–µ–∂–Ω–æ–π —Ñ–æ—Ä–º–µ,  –æ–¥–æ–±—Ä–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–æ–≤ —Å–ø–æ–Ω—Å–æ—Ä—Å–∫–æ–≥–æ –∏ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Å—É–º–º—ã —Å–¥–µ–ª–∫–∏, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ –∫–∞–∫ –∫—Ä—É–ø–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –∏ —Å–¥–µ–ª–∫–∏ —Å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å—é;\n",
        "       27) —Ä–µ—à–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤, –æ—Ç–Ω–µ—Å–µ–Ω–Ω—ã—Ö –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤, –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –Ω–µ –∏–∑–±—Ä–∞–Ω;\n",
        "       28) —Ä–µ—à–µ–Ω–∏–µ –∏–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, –æ—Ç–Ω–µ—Å–µ–Ω–Ω—ã—Ö –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞.\n",
        "\n",
        "\n",
        "\n",
        "–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞\n",
        "\n",
        "\n",
        "      1. –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç –æ–±—â–µ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞, –∞ —Ç–∞–∫–∂–µ –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏–π –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –∏ –∏–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –µ–≥–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ä–≥–∞–Ω–∞.\n",
        "\n",
        "      2. –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 4 (–ß–µ—Ç—ã—Ä–µ—Ö) —á–µ–ª–æ–≤–µ–∫.\n",
        "\n",
        "      3. –ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è:\n",
        "\n",
        "\n",
        "      14) —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ-—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞, –≤ —Ç–æ–º —á–∏—Å–ª–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è –æ –≤–Ω—É—Ç—Ä–∏—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç—Ä–æ–ª–µ, –¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞—Ö –∏ —Ä–µ–≤–∏–∑–∏—è—Ö;\n",
        "\n",
        "      15) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–µ–º –¥–µ–Ω–µ–∂–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –∏ (–∏–ª–∏) –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è, –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∏–º—É—â–µ—Å—Ç–≤–∞, –≤ —Ä–∞–º–∫–∞—Ö –∫–æ—Ç–æ—Ä—ã—Ö —Ü–µ–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –æ—Ç—á—É–∂–¥–∞–µ–º–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è —Å–¥–µ–ª–∫–∏, –ø—Ä–µ–≤—ã—à–∞–µ—Ç –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π —Å–¥–µ–ª–∫–∏ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, –∑–∞–∫–ª—é—á–µ–Ω–Ω—ã—Ö –≤ —Ç–µ—á–µ–Ω–∏–µ 6 (—à–µ—Å—Ç–∏) –º–µ—Å—è—Ü–µ–≤, –≤ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π –∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –¥–∞–Ω–Ω–æ–π —Å—É–º–º—ã –≤ –∏–Ω–æ–π –≤–∞–ª—é—Ç–µ, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞  –∫–∞–∫ –∫—Ä—É–ø–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –∏ —Å–¥–µ–ª–∫–∏ —Å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å—é, –∞ —Ç–∞–∫–∂–µ –¥–ª—è —Å–¥–µ–ª–æ–∫, –æ–¥–æ–±—Ä—è–µ–º—ã—Ö –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ 22)-26) –ø—É–Ω–∫—Ç–∞ 11.2 –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞, –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ 17) ‚Äì22), 30) –ø—É–Ω–∫—Ç–∞ 12.3 –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞;\n",
        "\n",
        "      16) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ/—É—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –ª—é–±—ã—Ö —Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤ –∏ —Ä–∞–∑–±–∏—Ä–∞—Ç–µ–ª—å—Å—Ç–≤, —Ü–µ–Ω–∞ –∏—Å–∫–∞ –ø–æ –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–µ–≤—ã—à–∞–µ—Ç 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π (–∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –≤ –¥—Ä—É–≥–æ–π –≤–∞–ª—é—Ç–µ) –≤ —Ç–æ–º —á–∏—Å–ª–µ, –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –º–∏—Ä–æ–≤–æ–≥–æ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è, –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ –∏—Å–∫–∞, –æ—Ç–∫–∞–∑ –æ—Ç –∏—Å–∫–∞, –∞ —Ç–∞–∫–∂–µ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, –∫—Ä–æ–º–µ —Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤, –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è, –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç–Ω–µ—Å–µ–Ω–æ –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞;\n",
        "\n",
        "\n",
        "–ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞\n",
        "\n",
        "\n",
        " 1. –ü—Ä–∞–≤–ª–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –æ—Ä–≥–∞–Ω–æ–º –û–±—â–µ—Å—Ç–≤–∞. –ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –∏–∑–±–∏—Ä–∞–µ—Ç—Å—è –û–±—â–∏–º —Å–æ–±—Ä–∞–Ω–∏–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ  2 (–î–≤—É—Ö) —á–µ–ª–æ–≤–µ–∫ ‚Äì —á–ª–µ–Ω–æ–≤ –ü—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞.\n",
        "\n",
        "\n",
        "12. –í —Å–ª—É—á–∞–µ –Ω–µ–ø—Ä–∏–Ω—è—Ç–∏—è –ü—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏—è –ø–æ –æ–¥–Ω–æ–º—É –∏ —Ç–æ–º—É –∂–µ –≤–æ–ø—Ä–æ—Å—É –≤ —Ö–æ–¥–µ 2 (–î–≤—É—Ö) –Ω–∞–¥–ª–µ–∂–∞—â–µ —Å–æ–∑–≤–∞–Ω–Ω—ã—Ö –∑–∞—Å–µ–¥–∞–Ω–∏–π –ü—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ –ª—é–±—ã–º –ø—Ä–∏—á–∏–Ω–∞–º, –≤–∫–ª—é—á–∞—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–≤–æ—Ä—É–º–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–æ–≤ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è, –≤–æ–ø—Ä–æ—Å, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –Ω–µ –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ, –≤—ã–Ω–æ—Å–∏—Ç—Å—è –Ω–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ (–≤–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –ø–æ–≤–µ—Å—Ç–∫—É –¥–Ω—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–∑—ã–≤–∞–µ–º–æ–≥–æ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤). –í–æ –∏–∑–±–µ–∂–∞–Ω–∏–µ —Å–æ–º–Ω–µ–Ω–∏–π, —Ä–µ—à–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å—Å—è –∫–∞–∫ –Ω–µ–ø—Ä–∏–Ω—è—Ç–æ–µ –¥–ª—è —Ü–µ–ª–µ–π –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –ø—É–Ω–∫—Ç–∞, –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ —Ä–µ—à–µ–Ω–∏–µ –Ω–µ –ø—Ä–∏–Ω—è—Ç–æ –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –ø—Ä–æ—Ç–∏–≤ –Ω–µ–≥–æ –ø—Ä–æ–≥–æ–ª–æ—Å–æ–≤–∞–ª–∏ –∏–ª–∏ –≤–æ–∑–¥–µ—Ä–∂–∞–ª–∏—Å—å –æ—Ç –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è –≤—Å–µ —á–ª–µ–Ω—ã –ü—Ä–∞–≤–ª–µ–Ω–∏—è.\n",
        "\n",
        "13. –ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ü—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ –æ—Ç–Ω–æ—Å—è—Ç—Å—è:\n",
        "\n",
        "\n",
        "\n",
        "         ‚Ä¢ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—É—Ä –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π (–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Ñ–∏–ª–∏–∞–ª–æ–≤ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤) –û–±—â–µ—Å—Ç–≤–∞, –∞ —Ç–∞–∫–∂–µ —É—Å–ª–æ–≤–∏–π —Ç—Ä—É–¥–æ–≤—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –ª–∏—Ü–∞–º–∏, —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –æ—Ç –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ª–∏—Ü;\n",
        "\n",
        "\n",
        "         ‚Ä¢ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–µ–º –¥–µ–Ω–µ–∂–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –∏ (–∏–ª–∏) –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è, –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∏–º—É—â–µ—Å—Ç–≤–∞, —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ—Ç–æ—Ä–æ–≥–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π —Å–¥–µ–ª–∫–∏ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –≤ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Ç 1 000 000 (–û–¥–Ω–æ–≥–æ) –º–∏–ª–ª–∏–æ–Ω–∞ —Ä—É–±–ª–µ–π –¥–æ 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π –∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –¥–∞–Ω–Ω–æ–π —Å—É–º–º—ã –≤ –∏–Ω–æ–π –≤–∞–ª—é—Ç–µ, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞  —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞  –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ó–∞–∫–æ–Ω–æ–º –∏ –£—Å—Ç–∞–≤–æ–º;\n",
        "\n",
        "\n",
        "         ‚Ä¢ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –ø–æ –ø—Ä–∏–µ–º–∫–µ –∏ –æ–ø–ª–∞—Ç–µ –û–±—â–µ—Å—Ç–≤–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç –ø–æ –ê–≥–µ–Ω—Ç—Å–∫–æ–º—É –¥–æ–≥–æ–≤–æ—Ä—É –Ω–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–∞ ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –≥–∞–∑–æ–ø–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∏–π –∑–∞–≤–æ–¥ (–Æ–ü –ì–ü–ó). –ì–∞–∑–æ–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–Ω–∞—è —Å—Ç–∞–Ω—Ü–∏—è –Æ–õ–¢ –ü—Ä–∏–æ–±—Å–∫–æ–≥–æ –º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏—è¬ª ‚Ññ10-875 –æ—Ç 29.09.2010 –≥., –∑–∞–∫–ª—é—á–µ–Ω–Ω–æ–º—É –º–µ–∂–¥—É –û–±—â–µ—Å—Ç–≤–æ–º –∏ –û–û–û ¬´–ì–∞–∑–ø—Ä–æ–º–Ω–µ—Ñ—Ç—å-–•–∞–Ω—Ç–æ—Å¬ª.\n",
        "\n",
        "\n",
        "–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –û–±—â–µ—Å—Ç–≤–∞\n",
        "\n",
        "\n",
        "cvi –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Ç–µ–∫—É—â–µ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –µ–¥–∏–Ω–æ–ª–∏—á–Ω—ã–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –æ—Ä–≥–∞–Ω–æ–º –û–±—â–µ—Å—Ç–≤–∞ - –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –∏–∑–±–∏—Ä–∞–µ—Ç—Å—è –û–±—â–∏–º —Å–æ–±—Ä–∞–Ω–∏–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ —Å—Ä–æ–∫–æ–º –Ω–∞ 3 (–¢—Ä–∏) –≥–æ–¥–∞, –µ—Å–ª–∏ —Ä–µ—à–µ–Ω–∏–µ–º –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω –∏–Ω–æ–π —Å—Ä–æ–∫. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–∏–∑–±—Ä–∞–Ω —Ä–µ—à–µ–Ω–∏–µ–º –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –¥–µ–π—Å—Ç–≤—É–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –£—Å—Ç–∞–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –∏ —Ç—Ä—É–¥–æ–≤–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä–∞, –∑–∞–∫–ª—é—á–∞–µ–º–æ–≥–æ —Å –Ω–∏–º –û–±—â–µ—Å—Ç–≤–æ–º.\n",
        "\n",
        "\n",
        "       ‚Ä¢ —É—Ç–≤–µ—Ä–∂–¥–∞—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Ä–µ–≥—É–ª–∏—Ä—É—é—â–∏–µ —Ç–µ–∫—É—â—É—é (–æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—É—é) –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –û–±—â–µ—Å—Ç–≤–∞, –∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã (–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏—Ö —Å–∏—Å—Ç–µ–º—ã –æ–ø–ª–∞—Ç—ã —Ç—Ä—É–¥–∞ –∏ –¥—Ä—É–≥–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç–Ω–µ—Å–µ–Ω–æ –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –∏–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞);\n",
        "\n",
        "       ‚Ä¢ –≤–Ω–æ—Å–∏—Ç—å –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –û–±—â–∏—Ö —Å–æ–±—Ä–∞–Ω–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞, –∑–∞—Å–µ–¥–∞–Ω–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤;\n",
        "\n",
        "       ‚Ä¢ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è –ø–æ –¥—Ä—É–≥–∏–º –≤–æ–ø—Ä–æ—Å–∞–º, –æ—Ç–Ω–æ—Å—è—â–∏–º—Å—è –∫ –µ–≥–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏.\n",
        "\n",
        "\n",
        "\n",
        "cxlv –ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ª—é–±–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞ –Ω–µ –≤–ª–µ—á–µ—Ç –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –µ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏–π. –í —Å–ª—É—á–∞–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ —Å–∏–ª—É –Ω–æ–≤—ã—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤, –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º–∏, –∏ –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –≤–Ω–µ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –£—Å—Ç–∞–≤, –£—á–∞—Å—Ç–Ω–∏–∫–∏ –æ–±—è–∑–∞–Ω—ã –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏—è –æ –≤–Ω–µ—Å–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –Ω–∞—Å—Ç–æ—è—â–∏–π –£—Å—Ç–∞–≤.\n",
        "\n",
        "v –ü–æ–ª–Ω–æ–µ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:\n",
        "\n",
        "      –û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –≥–∞–∑–æ–ø–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∏–π –∑–∞–≤–æ–¥¬ª.\n",
        "\n",
        "      –°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:\n",
        "\n",
        "      –û–û–û ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –ì–ü–ó¬ª.\n",
        "\n",
        "\n",
        "      –ü–æ–ª–Ω–æ–µ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ: Yuzhno-Priobsky Gaz Processing Plant Limited Liability Company.\n",
        "\n",
        "\n",
        "      –°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ:  Yuzhno-Priobsky GPP LLC.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "GLOBALS__['CharterAnlysingContext'].analyze_charter(SAMPLE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XpYNZGtEJRmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.core.display import display, HTML\n",
        "doc = GLOBALS__['CharterAnlysingContext'].doc\n",
        "GLOBALS__['renderer'].render_contents(doc)\n",
        "\n",
        " \n",
        "GLOBALS__['renderer'].render_charter_parsing_results(\n",
        "    GLOBALS__['CharterAnlysingContext'].org,\n",
        "    GLOBALS__['CharterAnlysingContext'].constraints)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "twCGd5TFcTKI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "uploaded = interactive_upload('Charter')  \n",
        "org, rz = GLOBALS__['CharterAnlysingContext'] .analyze_charter(uploaded[0])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dGRLbJ5kJuaO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_init_contracts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6c9siQi9k_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GLOBALS__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HEyYz8iPJ-4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded = interactive_upload('–î–æ–≥–æ–≤–æ—Ä')  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xIOjRq7EKQA9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GLOBALS__['ContractAnlysingContext'].analyze_contract(uploaded[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BhF8cq_PKKaK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "h = GLOBALS__['renderer'].render_constraint_values(GLOBALS__['CharterAnlysingContext'].constraints)\n",
        "display(HTML(h))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}