{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 test demo no UI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "vXHjbkIfc8Ws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "GLOBALS__={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zGPbyfYp6nIq",
        "colab_type": "code",
        "outputId": "5696d5cc-6878-4db5-af0e-5fb1fb57f19b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title –ù–∞—Å—Ç—Ä–æ–π–∫–∏ { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "USD_to_RUB = 65 #@param {type:\"number\"}\n",
        "RUB_to_USD = 1.0/USD_to_RUB\n",
        "\n",
        "# print('USD_to_RUB=',USD_to_RUB)\n",
        "# print('RUB_to_USD=',RUB_to_USD)\n",
        "\n",
        "\n",
        "\n",
        "currency_converter = {\n",
        "  'USD': USD_to_RUB,\n",
        "  'RUB': 1.0\n",
        "}\n",
        "\n",
        "print(currency_converter)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'USD': 65, 'RUB': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nwpPPXqRQs6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#MAIN"
      ]
    },
    {
      "metadata": {
        "id": "-2Oe-BsTcCIW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4464d6f1-295d-4a86-f4a9-35c6de2fc703"
      },
      "cell_type": "code",
      "source": [
        "# @title –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ { output-height: 800, form-width: \"300px\", display-mode: \"form\" }\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "def interactive_upload(filetype):\n",
        "  from google.colab import files\n",
        "  import docx2txt\n",
        "\n",
        "  print(f'Please select \"{filetype}\" .docx file:')\n",
        "  uploaded = files.upload()\n",
        "  docs = []\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "    with open(fn, \"wb\") as df:\n",
        "      df.write(uploaded[fn])\n",
        "      df.close()\n",
        "\n",
        "    # extract text\n",
        "\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "    print(\"–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ:\", len(text))\n",
        "    docs.append(text)\n",
        "    return docs\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# ====================================\n",
        "_git_branch = \"protocols-2\"  # @param {type:\"string\"}\n",
        "# ====================================\n",
        "# ====================================\n",
        "\n",
        "\n",
        "# ''' AZ:-IMPORT CODE GITHUB----------------------------------------------üò∫------ '''\n",
        "import sys\n",
        "\n",
        "\n",
        "def _init_import_code_from_gh():\n",
        "  if 'GLOBALS__' not in globals():\n",
        "    print('adding global GLOBALS__')\n",
        "    global GLOBALS__\n",
        "    GLOBALS__ = {}\n",
        "\n",
        "  if '_init_import_code_from_gh' in GLOBALS__:\n",
        "    print('üëå code already imported from GitHub!')\n",
        "    return\n",
        "\n",
        "  import subprocess\n",
        "  def exec(x):\n",
        "    r = subprocess.check_output(x, shell=True)\n",
        "    r = r.decode('unicode-escape').encode('latin1').decode('utf8')\n",
        "    print(r)\n",
        "\n",
        "  print(f\"fetching code from GitHub.....{_git_branch}\")\n",
        "  try:\n",
        "    exec('rm -r nlp_tools')\n",
        "  except:\n",
        "    pass\n",
        "  exec(f'git clone --single-branch --branch {_git_branch} https://github.com/compartia/nlp_tools.git nlp_tools')\n",
        "\n",
        "  print('ü¶ä GIT revision:')\n",
        "  exec('cd nlp_tools\\ngit rev-list --reverse HEAD | awk \"{ print NR }\" | tail -n 1\\ngit branch\\ngit log -3 --pretty=%B')\n",
        "\n",
        "  sys.path.insert(0, 'nlp_tools')\n",
        "\n",
        "  # self-test\n",
        "  from text_tools import untokenize\n",
        "  print(untokenize(['code', 'imported', 'OK üëç']))\n",
        "\n",
        "  print('installing antiword...')\n",
        "  exec('sudo apt-get install antiword')\n",
        "\n",
        "  print('installing docx2txt...')\n",
        "  exec(\"pip install docx2txt\")\n",
        "\n",
        "  GLOBALS__['_init_import_code_from_gh'] = True\n",
        "\n",
        "  ''' AZ:-------------------------------------------------IMPORT CODE GITHUB-üò∫---'''\n",
        "  print('‚ù§Ô∏è DONE importing Code fro GitHub')\n",
        "\n",
        "\n",
        "# AZ:-INIT ELMO-----------------------------------------------------------------------------------\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "def _import_elmo():\n",
        "  \"\"\"\n",
        "  ACHTUNG!! this method is called later by ElmoEmbedder\n",
        "  \"\"\"\n",
        "\n",
        "  elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz',\n",
        "                    trainable=False)  # news\n",
        "  #   elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-twitter_2013-01_2018-04_600k_steps.tar.gz',\n",
        "  #                     trainable=False)  # twitter\n",
        "  print('‚ù§Ô∏è ‚ù§Ô∏è ‚ù§Ô∏è DONE (re)importing Tensorflow hub.Module ')\n",
        "  print('Tensorflow version is', tf.__version__)\n",
        "\n",
        "  return elmo\n",
        "\n",
        "\n",
        "# AZ:-INIT EMBEDDER-----------------------------------------------------------------------------------\n",
        "\n",
        "def _init_embedder():\n",
        "  if 'elmo_embedder' in GLOBALS__:\n",
        "    print('üëå Embedder is already created! ')\n",
        "    return\n",
        "\n",
        "  from embedding_tools import ElmoEmbedder\n",
        "  GLOBALS__['elmo_embedder'] = ElmoEmbedder(_import_elmo(), tf, 'elmo', _import_elmo)\n",
        "\n",
        "  print('‚ù§Ô∏è DONE creating words embedding model')\n",
        "  return GLOBALS__['elmo_embedder']\n",
        "\n",
        "\n",
        "# AZ:-Init chartes context-----------------------------------------------------------------------------------\n",
        "def _init_charters():\n",
        "  if 'CharterAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Charters-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  _init_embedder()  # PRECONDITION\n",
        "  from charter_patterns import CharterPatternFactory\n",
        "  from charter_parser import CharterDocumentParser\n",
        "  CPF = CharterPatternFactory(GLOBALS__['elmo_embedder'])\n",
        "  GLOBALS__['CharterAnlysingContext'] = CharterDocumentParser(CPF)\n",
        "  print('‚ù§Ô∏è DONE initing Charters-related tools and models ')\n",
        "\n",
        "\n",
        "def _init_contracts():\n",
        "  if 'ContractAnlysingContext' in GLOBALS__:\n",
        "    print('üëå Contracts-related tools are already inited ')\n",
        "    return\n",
        "\n",
        "  from contract_parser import ContractAnlysingContext\n",
        "  GLOBALS__['ContractAnlysingContext'] = ContractAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['renderer'])\n",
        "  print('‚ù§Ô∏è DONE initing Contracts-related tools and models ')\n",
        "\n",
        "\n",
        "# AZ:- THE CODE----------------------------------------------------------------------------------\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def _init_the_code(reset=False):\n",
        "  if '_init_the_code' in GLOBALS__ and not reset:\n",
        "    print('üëå Code is alredy imported!')\n",
        "    return\n",
        "\n",
        "  from transaction_values import ValueConstraint\n",
        "\n",
        "  import matplotlib as mpl\n",
        "  from IPython.core.display import display, HTML\n",
        "  import matplotlib.pyplot as plt\n",
        "  \n",
        "  from renderer import AbstractRenderer, HtmlRenderer, head_types_colors\n",
        "  from renderer import to_multicolor_text, as_headline_3, as_offset\n",
        "  from renderer import as_msg, as_quote, as_c_quote\n",
        "  from renderer import as_error_html, known_subjects_dict, v_color_map\n",
        "  from transaction_values import ValueConstraint\n",
        "  from parsing import head_types_dict, head_types\n",
        "  from legal_docs import PatternSearchResults, ConstraintsSearchResult, PatternSearchResult, CharterDocument\n",
        "  \n",
        "  import numpy as np\n",
        "  \n",
        "  from charter_patterns import known_subjects\n",
        "  from patterns import AV_SOFT, AV_PREFIX\n",
        "  from structures import ContractSubject\n",
        "  from contract_parser import ContractDocument3\n",
        "\n",
        "  def _as_smaller(txt):\n",
        "    return f'<div font-size:12px\">{txt}</div>'\n",
        " \n",
        "  \n",
        "      \n",
        "  class DemoRenderer(HtmlRenderer):\n",
        "\n",
        "    def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      print('render_color_text')\n",
        "      html = self.to_color_text(tokens, weights, colormap, print_debug, _range)\n",
        "      display(HTML(html))\n",
        "                \n",
        "\n",
        "    def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):\n",
        "      if len(tokens) == 0:\n",
        "        return \" - empty -\"\n",
        "      if len(weights) != len(tokens):\n",
        "        raise ValueError(\"number of weights differs weights={} tokens={}\".format(len(weights), len(tokens)))\n",
        "\n",
        "      #   if()\n",
        "      vmin = weights.min()\n",
        "      vmax = weights.max()\n",
        "\n",
        "      if _range is not None:\n",
        "        vmin = _range[0]\n",
        "        vmax = _range[1]\n",
        "\n",
        "      if print_debug:\n",
        "        print(vmin, vmax)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmin=vmin - 0.5, vmax=vmax)\n",
        "      html = \"\"\n",
        "      cmap = mpl.cm.get_cmap(colormap)\n",
        "\n",
        "      for d in range(0, len(weights)):\n",
        "        word = tokens[d]\n",
        "        if word == ' ':\n",
        "          word = '&nbsp;_ '\n",
        "\n",
        "        html += '<span title=\"{} {:.4f}\" style=\"background-color:{}\">{} </span>'.format(\n",
        "          d,\n",
        "          weights[d],\n",
        "          mpl.colors.to_hex(cmap(norm(weights[d]))),\n",
        "          word)\n",
        "\n",
        "        #     html+='<span style=\"background-color:' +mpl.colors.to_hex(cmap(norm(weights[d]) ))+ '\">' + str(tokens[d]) + \" </span>\"\n",
        "        if tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "\n",
        "    ''' AZ:-Rendering CHARITYüî•-----üí∏------üí∏-------üí∏------------------------------'''\n",
        "    def render_multicolor_text(self, tokens, vectors, colormap, min_color=None, _slice=None):\n",
        "      display(HTML(to_multicolor_text(tokens, vectors, colormap, min_color=min_color, _slice=_slice)))\n",
        "\n",
        "    \n",
        "\n",
        "    ''' AZ:------üí∏------üí∏-------üí∏----------------------END--Rendering CHARITYüî•------'''\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    def render_subj(self, contract: ContractDocument3):\n",
        "      subjects: List[ProbableValue] = contract.subjects\n",
        "\n",
        "      if len(subjects) > 0:\n",
        "        sorted_ = [y for y in sorted(subjects, key=lambda x: -x.confidence)]\n",
        "        subject_kind = sorted_[0].value\n",
        "        confidence = sorted_[0].confidence\n",
        "      else:\n",
        "        subject_kind = ContractSubject.Other\n",
        "\n",
        "      if subject_kind in known_subjects_dict:\n",
        "        rendering_name = known_subjects_dict[subject_kind]\n",
        "      else:\n",
        "        rendering_name = '–ø—Ä–æ—á–µ–µ'\n",
        "\n",
        "      display(\n",
        "        HTML(f'–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:'\n",
        "             f'<h3 style=\"margin:0\">{rendering_name}<sup> {subject_kind}</sup> </h3> '\n",
        "             f'confidence:{confidence:20,.2f}'))\n",
        "\n",
        "\n",
        "\n",
        "    def sign_to_text(self, sign: int):\n",
        "      if sign < 0: return \" &lt; \"\n",
        "      if sign > 0: return \" &gt; \"\n",
        "      return ' = '\n",
        "\n",
        "    def probable_value_to_html(self, pv):\n",
        "      vc = pv.value\n",
        "      color = '#333333'\n",
        "      if vc.sign > 0:\n",
        "        color = '#993300'\n",
        "      elif vc.sign < 0:\n",
        "        color = '#009933'\n",
        "\n",
        "      return f'<b style=\"color:{color}\">{self.sign_to_text(vc.sign)} {vc.currency} {vc.value:20,.2f}' \\\n",
        "             f'<sup>confidence={pv.confidence:20,.2f}</sup></b> '\n",
        "\n",
        "    def render_contents(self, doc):\n",
        "      html = as_headline_3('–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞')\n",
        "      html += \"<ul>\"\n",
        "      for i in doc.structure.headline_indexes:\n",
        "        line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li> {line} <sup>line {i}</sup></li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_sections(self, sections):\n",
        "      from legal_docs import HeadlineMeta\n",
        "      html = as_headline_3('–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞')\n",
        "      html += \"<ul>\"\n",
        "      for section_type in sections:\n",
        "        section: HeadlineMeta = sections[section_type]\n",
        "        body = section.body.untokenize_cc()[:1000]\n",
        "        headline = section.subdoc.untokenize_cc()[:500]\n",
        "        #     line = doc.structure.structure[i].to_string(doc.tokens_cc)\n",
        "        html += f'<li><h3> {headline} <sup>type: {section_type}</sup> </h3> <p>{body}</p> </li>'\n",
        "      html += \"</ul>\"\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        "    def render_values(self, values):\n",
        "      if len(values) > 0:\n",
        "        for pv in values:\n",
        "          h = self.probable_value_to_html(pv)\n",
        "          display(HTML(h))\n",
        "      else:\n",
        "        display(HTML('—Å—É–º–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'))\n",
        "\n",
        "    def render_value_section_details(self, value_section_info):\n",
        "      value_section = value_section_info.body\n",
        "      headline_doc = value_section_info.subdoc\n",
        "\n",
        "      headline = headline_doc.untokenize_cc()\n",
        "\n",
        "      v_names = {\n",
        "        'value_attention_vector',\n",
        "        'novalue_attention_vector',\n",
        "\n",
        "        'novalue_attention_vector_local_contrast',\n",
        "        'value_attention_vector_tuned'}\n",
        "\n",
        "      fig = plt.figure(figsize=(20, 6))\n",
        "      ax = plt.axes()\n",
        "      for vector_name in v_names:\n",
        "        ax.plot(value_section.distances_per_pattern_dict[vector_name], label=vector_name, alpha=0.4)\n",
        "\n",
        "      ax.plot(value_section.distances_per_pattern_dict['value_attention_vector_tuned'], label='value_attention result',\n",
        "              alpha=0.9, color='black')\n",
        "      plt.legend(loc='upper right')\n",
        "\n",
        "      text = self.to_color_text(value_section.tokens_cc,\n",
        "                                value_section.distances_per_pattern_dict['value_attention_vector_tuned'], _range=(0, 1))\n",
        "      html = f'{ as_headline_3(headline)} <div style=\"margin-left:4em; font-size=90%\">{text}</div>'\n",
        "      display(HTML(html))\n",
        "\n",
        "     \n",
        "    def render_charter_parsing_results_2(self, charter):\n",
        "      display(HTML(self.charter_parsing_results_to_html(charter)))\n",
        "      \n",
        "    def render_charter_parsing_results(self, doc, org, rz, charity_constraints):\n",
        "      WARN = '\\033[1;31m======== Dear Artem, ACHTUNG! üîû '\n",
        "      print (WARN+f\"use {self.render_charter_parsing_results} is deprecated\")\n",
        "      txt_html = self.to_color_text(org['tokens'], org['attention_vector'], _range=[0, 1])\n",
        "\n",
        "      html = '<div style=\"background:#eeeeff; padding:0.5em\"> recognized NE(s): <br><br> org type:<h3 style=\"margin:0\">  {} </h3>org full name:<h2 style=\"margin:0\">  {} </h2> <br>quote: <div style=\"font-size:90%; background:white\">{}</div> </div>'.format(\n",
        "        org['type_name'], org['name'], txt_html)\n",
        "      # html+=txt_html\n",
        "      html += self.render_constraint_values(doc, rz, charity_constraints)\n",
        "\n",
        "      display(HTML(html))\n",
        "\n",
        " \n",
        "\n",
        "     \n",
        "\n",
        "    \n",
        " \n",
        "\n",
        "  GLOBALS__['renderer'] = DemoRenderer()\n",
        "\n",
        "  # AZ:----------PROTOCOLS RENDERER-------------------------\n",
        "\n",
        "  from legal_docs import LegalDocument\n",
        "\n",
        "  import matplotlib as mpl\n",
        "  from IPython.core.display import display, HTML\n",
        "  from renderer import as_headline_3, as_headline_4\n",
        "  from legal_docs import LegalDocument\n",
        "  from renderer import as_warning, as_headline_3, as_offset, as_smaller\n",
        "\n",
        "\n",
        "  class ProtocolRenderer(DemoRenderer):\n",
        "\n",
        "    def winning_patterns_to_html(self, _tokens, ranges, winning_patterns, _range,\n",
        "                                 colormaps=['Reds', 'Purples', 'Blues', 'Greens', 'Greys']):\n",
        "      vmin = -ranges[1]\n",
        "      vmax = -ranges[0]\n",
        "\n",
        "      #     print(\"winning_patterns_to_html _range\", _range, \"min max=\", ranges)\n",
        "\n",
        "      norm = mpl.colors.Normalize(vmax=vmax, vmin=vmin)\n",
        "\n",
        "      cmaps = []\n",
        "\n",
        "      #     print (colormaps)\n",
        "      for n in colormaps:\n",
        "        cmap = mpl.cm.get_cmap(n)\n",
        "        cmaps.append(cmap)\n",
        "\n",
        "      html = \"\"\n",
        "\n",
        "      for d in _range:\n",
        "        winning_pattern_i = winning_patterns[d][0]\n",
        "        colormap = cmaps[winning_pattern_i % len(colormaps)]\n",
        "        normed = norm(-winning_patterns[d][1])\n",
        "        color = mpl.colors.to_hex(colormap(normed))\n",
        "        html += '<span title=\"' + '{} {:.2f}'.format(d, winning_patterns[d][\n",
        "          1]) + '\" style=\"background-color:' + color + '\">' + str(\n",
        "          _tokens[d]) + \" </span>\"\n",
        "        if _tokens[d] == '\\n':\n",
        "          html += \"<br>\"\n",
        "\n",
        "      return html\n",
        "\n",
        "    def _render_doc_subject_fragments(self, doc):\n",
        "      #     print(doc.per_subject_distances)\n",
        "\n",
        "      _html = \"\"\n",
        "      if doc.per_subject_distances is not None:\n",
        "\n",
        "        type = \"–î–æ–≥–æ–≤–æ—Ä  –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è\"\n",
        "        if doc.per_subject_distances[0] > doc.per_subject_distances[1]:\n",
        "          type = \"–î–æ–≥–æ–≤–æ—Ä –≤–æ–∑–º–µ–∑–¥–Ω–æ–≥–æ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥\"\n",
        "\n",
        "        _html += \"<h3>\" + type + \"</h3>\"\n",
        "\n",
        "        colormaps = ['PuRd'] * 5 + ['Blues'] * 7 + ['Greys']\n",
        "\n",
        "        _html += as_headline_4('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞')\n",
        "\n",
        "        for region in [doc.subj_range]:\n",
        "          _html += self.winning_patterns_to_html(_tokens=doc.tokens, ranges=doc.subj_ranges,\n",
        "                                                 winning_patterns=doc.winning_subj_patterns, _range=region,\n",
        "                                                 colormaps=colormaps)\n",
        "\n",
        "      return _html\n",
        "\n",
        "    def render_subject(self, counter):\n",
        "      html = as_headline_3('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (X):') + self.subject_type_weights_to_html(counter)\n",
        "      display(HTML(html))\n",
        "\n",
        "    def print_results(self, _doc: LegalDocument, results=None):\n",
        "      values = sorted(_doc.values, key=lambda item: -item.confidence)\n",
        "\n",
        "      if values is None or len(values)==0:\n",
        "        display(HTML(as_warning('—Å—É–º–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')))\n",
        "        return \n",
        "\n",
        "\n",
        "      cc = 0  \n",
        "      for vl in values:\n",
        "\n",
        "        h = as_headline_3(self.probable_value_to_html(vl))\n",
        "        h += as_offset(self.to_color_text(vl.value.context.tokens, vl.value.context.attention, colormap='jet'))\n",
        "        if cc > 0:\n",
        "          h = as_offset(as_smaller(h))\n",
        "\n",
        "        display(HTML(h))\n",
        "\n",
        "        cc += 1\n",
        "    \n",
        "    def subject_type_weights_to_html(self, counter):\n",
        "      dict = {\n",
        "        't_dea': '–°–¥–µ–ª–∫–∞',\n",
        "        't_cha': '–ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å',\n",
        "        't_org': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è'\n",
        "      }\n",
        "\n",
        "      maxkey = \"None\"\n",
        "      for key in dict:\n",
        "        if counter[key] > counter[maxkey]:\n",
        "          maxkey = key\n",
        "\n",
        "      html = \"\"\n",
        "      for key in dict:\n",
        "        templ = \"<div>{}: {}</div>\"\n",
        "        if key == maxkey:\n",
        "          templ = '<b style=\"font-size:135%; color:maroon\">{}: {}</b>'\n",
        "        html += templ.format(counter[key], dict[key])\n",
        "\n",
        "      return html\n",
        "\n",
        "  GLOBALS__['ProtocolRenderer'] = ProtocolRenderer()\n",
        "\n",
        "  from demo_protocols import ProtocolAnlysingContext\n",
        "  GLOBALS__['ProtocolAnlysingContext'] = ProtocolAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['ProtocolRenderer'])\n",
        "  GLOBALS__['_init_the_code'] = True\n",
        "\n",
        "  # AZ:-------------------------------------------------Init Protocols context===\n",
        "\n",
        "  # AZ:-------------------------------------------------Init Charters context====\n",
        "\n",
        "  def read_doc(fn):\n",
        "    import docx2txt, sys, os\n",
        "    text = ''\n",
        "    try:\n",
        "      text = docx2txt.process(fn)\n",
        "    except:\n",
        "      print(\"Unexpected error:\", sys.exc_info())\n",
        "      os.system('antiword -w 0 \"' + fn + '\" > \"' + fn + '.txt\"')\n",
        "      with open(fn + '.txt') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    return text\n",
        "\n",
        "  GLOBALS__['read_doc'] = read_doc\n",
        "\n",
        "  print(\"‚ù§Ô∏è DONE initializing the code\")\n",
        "\n",
        "\n",
        "# AZ:-FINDING_VIOLATIONS--------------------------------------------------------\n",
        "def find_and_show_violations():\n",
        "  from IPython.core.display import display, HTML\n",
        "\n",
        "  from contract_parser import ContractAnlysingContext\n",
        "  from renderer import as_headline_2, as_error_html\n",
        "\n",
        "  print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')\n",
        "\n",
        "  charterAnlysingContext: CharterAnlysingContext = GLOBALS__['CharterAnlysingContext']\n",
        "  contractAnlysingContext: ContractAnlysingContext = GLOBALS__['ContractAnlysingContext']\n",
        "\n",
        "  contract = contractAnlysingContext.contract\n",
        "  charter = charterAnlysingContext.doc\n",
        "  charter_constraints = charterAnlysingContext.constraints  # XXX: move to doc\n",
        "\n",
        "  renderer = GLOBALS__['renderer']\n",
        "  renderer.render_subj(contract)\n",
        "\n",
        "  import copy\n",
        "\n",
        "  def convert(v):\n",
        "    v_converted = copy.copy(v)\n",
        "    if v.currency in currency_converter:\n",
        "      v_converted.value = currency_converter[v.currency] * v.value\n",
        "      v_converted.currency = 'RUB'\n",
        "      return v_converted\n",
        "    else:\n",
        "      display(HTML(as_error_html(\n",
        "        f\"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?\")))\n",
        "      return v\n",
        "\n",
        "  best_value = contractAnlysingContext.find_contract_best_value(convert)\n",
        "\n",
        "  # rendering:----------------------------\n",
        "\n",
        "  def _render_violations(ranges_by_group, best_value):\n",
        "    for group_key in ranges_by_group:\n",
        "      group = ranges_by_group[group_key]\n",
        "      display(HTML(as_headline_2(group['name'])))\n",
        "\n",
        "      for rk in group['ranges']:\n",
        "        r = group['ranges'][rk]\n",
        "        display(HTML(r.check_contract_value(best_value, convert, renderer)))\n",
        "\n",
        "  print(\"–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:\")\n",
        "  renderer.render_values([best_value])\n",
        "  renderer.render_color_text(best_value.value.context.tokens, best_value.value.context.attention, _range=[0, 1])\n",
        "\n",
        "  _render_violations(\n",
        "    charterAnlysingContext.find_ranges_by_group(charter_constraints, convert, verbose=False),\n",
        "    best_value)\n",
        "\n",
        "#   display(HTML(renderer.render_constraint_values(charter_constraints)))\n",
        "\n",
        "\n",
        "# AZ:--------------------------------------------------------FINDING_VIOLATIONS-\n",
        "\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX\n",
        "# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0425 11:36:51.208781 140629173753728 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YhjI5YF61cpd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# step 0. –ò–Ω–∏—Ç "
      ]
    },
    {
      "metadata": {
        "id": "6BnrLv2k1iVq",
        "colab_type": "code",
        "outputId": "f32c52d8-5be5-4675-c083-06d695123cc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        }
      },
      "cell_type": "code",
      "source": [
        "## do preparation here\n",
        "\n",
        "# 1.\n",
        "_init_import_code_from_gh()\n",
        "# 2.\n",
        "_init_embedder()\n",
        "# 3.\n",
        "_init_the_code()\n",
        "# 4.\n",
        "# _init_charters()\n",
        "# # 5.\n",
        "# _init_contracts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fetching code from GitHub.....protocols-2\n",
            "\n",
            "\n",
            "ü¶ä GIT revision:\n",
            "385\n",
            "* protocols-2\n",
            "Created using Colaboratory\n",
            "Add found_sum property for compatibility\n",
            "\n",
            "Protocols: another way of fetching values\n",
            "\n",
            "\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "code imported OK üëç\n",
            "installing antiword...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "antiword is already the newest version (0.37-11build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
            "\n",
            "installing docx2txt...\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.6/dist-packages (0.7)\n",
            "\n",
            "‚ù§Ô∏è DONE importing Code fro GitHub\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0425 11:37:38.853291 140629173753728 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "‚ù§Ô∏è ‚ù§Ô∏è ‚ù§Ô∏è DONE (re)importing Tensorflow hub.Module \n",
            "Tensorflow version is 1.13.1\n",
            "‚ù§Ô∏è DONE creating words embedding model\n",
            "<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x7fe653d344a8>\n",
            "‚ù§Ô∏è DONE initializing the code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NQMHGw2NzZU1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# step 4. –ü—Ä–æ—Ç–æ–∫–æ–ª\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "85aO_7B1zKFq",
        "colab_type": "code",
        "outputId": "27982bdf-5574-4491-a728-7ce55f93dfa8",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = interactive_upload('Protocol')\n",
        "GLOBALS__['ProtocolAnlysingContext'].process(uploaded[0])\n",
        "# GLOBALS__['ProtocolRenderer'].print_results(GLOBALS__['ProtocolAnlysingContext'].protocol)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please select \"Protocol\" .docx file:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-778f2185-2f88-415d-aaeb-e9d3a94d3a1c\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-778f2185-2f88-415d-aaeb-e9d3a94d3a1c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving –ì–ü–ù 1 –ü—Ä–æ—Ç–æ–∫–æ–ª –°–î (–∫-–ø –Ω–µ–¥–≤–∏–∂ –ù).docx to –ì–ü–ù 1 –ü—Ä–æ—Ç–æ–∫–æ–ª –°–î (–∫-–ø –Ω–µ–¥–≤–∏–∂ –ù) (1).docx\n",
            "User uploaded file \"–ì–ü–ù 1 –ü—Ä–æ—Ç–æ–∫–æ–ª –°–î (–∫-–ø –Ω–µ–¥–≤–∏–∂ –ù).docx\" with length 26631 bytes\n",
            "–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ: 4131\n",
            "üêå Embedding 382 words... it takes time (‚òïÔ∏è?)..\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0425 11:38:04.492181 140629173753728 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding complete üêå ; the shape is (36, 16, 1024)\n",
            "‚ù§Ô∏è ACCOMPLISHED: \t 0.\t Pattern factory created, patterns embedded into ELMO space\n",
            "ProtocolDocument text: len(4131)\n",
            "üêå Embedding 782 words... it takes time (‚òïÔ∏è?)..\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0425 11:38:13.281326 140629173753728 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Embedding complete üêå ; the shape is (1, 782, 1024)\n",
            "Function _emb called 1 times. \n",
            "Execution time max: 6.1290, average: 6.1290\n",
            "‚ù§Ô∏è ACCOMPLISHED: \t 1.\t Document embedded into ELMO space\n",
            "----WARNING!: function remove_similar_indexes is deprecated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "nlp_tools/demo_protocols.py:231: RuntimeWarning: All-NaN slice encountered\n",
            "  dist_per_pat.append(np.nanmin(row))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REG: 55000000 ( –ø—è—Ç—å–¥–µ—Å—è—Ç –ø—è—Ç—å –æ–¥–∏–Ω –º–∏–ª–ª–∏–æ–Ω ) —Ä—É–±–ª–µ–π ,\n",
            "REG: 155 000 000 ( —Å—Ç–æ –ø—è—Ç—å–¥–µ—Å—è—Ç –ø—è—Ç—å –º–∏–ª–ª–∏–æ–Ω–æ–≤ ) —Ä—É–±–ª–µ–π ,\n",
            "REG: 55000000 ( –ø—è—Ç—å–¥–µ—Å—è—Ç –ø—è—Ç—å –æ–¥–∏–Ω –º–∏–ª–ª–∏–æ–Ω ) —Ä—É–±–ª–µ–π ,\n",
            "REG: 155 000 000 ( —Å—Ç–æ –ø—è—Ç—å–¥–µ—Å—è—Ç –ø—è—Ç—å –º–∏–ª–ª–∏–æ–Ω–æ–≤ ) —Ä—É–±–ª–µ–π ,\n",
            "‚ù§Ô∏è ACCOMPLISHED: \t 2.\t value found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3 style=\"margin:0\"><b style=\"color:#333333\"> =  RUB        55,000,000.00<sup>confidence=                0.85</sup></b> </h3><div style=\"margin-left:2em\"><span title=\"0 0.6781\" style=\"background-color:#ff9800\">–ø—Ä–∞–≤–∞ </span><span title=\"1 0.6774\" style=\"background-color:#ff9c00\">–∞—Ä–µ–Ω–¥—ã </span><span title=\"2 0.6796\" style=\"background-color:#ff9800\">–∑–µ–º–µ–ª—å–Ω–æ–≥–æ </span><span title=\"3 0.6928\" style=\"background-color:#ff8600\">—É—á–∞—Å—Ç–∫–∞ </span><span title=\"4 0.7073\" style=\"background-color:#ff6f00\">. </span><span title=\"5 0.6958\" style=\"background-color:#ff7e00\">–ø—Ä–∏ </span><span title=\"6 0.6988\" style=\"background-color:#ff7a00\">—ç—Ç–æ–º </span><span title=\"7 0.7296\" style=\"background-color:#ff5200\">—Ü–µ–Ω–∞ </span><span title=\"8 0.7248\" style=\"background-color:#ff5500\">–æ–±—ä–µ–∫—Ç–∞ </span><span title=\"9 0.7432\" style=\"background-color:#ff3b00\">—Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç </span><span title=\"10 0.8475\" style=\"background-color:#800000\">55000000 </span><span title=\"11 0.7478\" style=\"background-color:#ff3800\">( </span><span title=\"12 0.7861\" style=\"background-color:#e80000\">–ø—è—Ç—å–¥–µ—Å—è—Ç </span><span title=\"13 0.7895\" style=\"background-color:#e40000\">–ø—è—Ç—å </span><span title=\"14 0.7779\" style=\"background-color:#f60b00\">–æ–¥–∏–Ω </span><span title=\"15 0.7697\" style=\"background-color:#ff1600\">–º–∏–ª–ª–∏–æ–Ω </span><span title=\"16 0.7504\" style=\"background-color:#ff3400\">) </span><span title=\"17 0.7341\" style=\"background-color:#ff4a00\">—Ä—É–±–ª–µ–π </span><span title=\"18 0.7381\" style=\"background-color:#ff4300\">, </span><span title=\"19 0.7295\" style=\"background-color:#ff5200\">–≤ </span><span title=\"20 0.7304\" style=\"background-color:#ff4e00\">—Ç–æ–º </span><span title=\"21 0.7448\" style=\"background-color:#ff3b00\">—á–∏—Å–ª–µ </span><span title=\"22 0.7835\" style=\"background-color:#ed0400\">–Ω–¥—Å </span><span title=\"23 0.8102\" style=\"background-color:#bf0000\">20 </span><span title=\"24 0.7395\" style=\"background-color:#ff4300\">% </span><span title=\"25 0.7249\" style=\"background-color:#ff5500\">—Ä—É–±–ª–µ–π </span><span title=\"26 0.7146\" style=\"background-color:#ff6400\">, </span><span title=\"27 0.7104\" style=\"background-color:#ff6c00\">—Ü–µ–Ω–∞ </span><span title=\"28 0.6827\" style=\"background-color:#ff9100\">–ø—Ä–∞–≤–∞ </span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"margin-left:2em\"><span style=\"font-size:80%;\"><h3 style=\"margin:0\"><b style=\"color:#333333\"> =  RUB        55,000,000.00<sup>confidence=                0.84</sup></b> </h3><div style=\"margin-left:2em\"><span title=\"0 0.7068\" style=\"background-color:#ff6400\">–∏ </span><span title=\"1 0.7097\" style=\"background-color:#ff5d00\">—Ü–µ–Ω—É </span><span title=\"2 0.6768\" style=\"background-color:#ff8d00\">–ø—Ä–∞–≤–∞ </span><span title=\"3 0.6765\" style=\"background-color:#ff8d00\">–∞—Ä–µ–Ω–¥—ã </span><span title=\"4 0.6792\" style=\"background-color:#ff8900\">–∑–µ–º–µ–ª—å–Ω–æ–≥–æ </span><span title=\"5 0.6923\" style=\"background-color:#ff7700\">—É—á–∞—Å—Ç–∫–∞ </span><span title=\"6 0.7067\" style=\"background-color:#ff6400\">. </span><span title=\"7 0.6932\" style=\"background-color:#ff7700\">–ø—Ä–∏ </span><span title=\"8 0.7081\" style=\"background-color:#ff6000\">—ç—Ç–æ–º </span><span title=\"9 0.7285\" style=\"background-color:#ff4300\">—Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç </span><span title=\"10 0.8357\" style=\"background-color:#800000\">55000000 </span><span title=\"11 0.7419\" style=\"background-color:#ff3000\">( </span><span title=\"12 0.7811\" style=\"background-color:#df0000\">–ø—è—Ç—å–¥–µ—Å—è—Ç </span><span title=\"13 0.7847\" style=\"background-color:#d60000\">–ø—è—Ç—å </span><span title=\"14 0.7679\" style=\"background-color:#f60b00\">–æ–¥–∏–Ω </span><span title=\"15 0.7557\" style=\"background-color:#ff1e00\">–º–∏–ª–ª–∏–æ–Ω </span><span title=\"16 0.7389\" style=\"background-color:#ff3400\">) </span><span title=\"17 0.7273\" style=\"background-color:#ff4700\">—Ä—É–±–ª–µ–π </span><span title=\"18 0.7313\" style=\"background-color:#ff3f00\">, </span><span title=\"19 0.7221\" style=\"background-color:#ff4e00\">–≤ </span><span title=\"20 0.7232\" style=\"background-color:#ff4a00\">—Ç–æ–º </span><span title=\"21 0.7365\" style=\"background-color:#ff3800\">—á–∏—Å–ª–µ </span><span title=\"22 0.7772\" style=\"background-color:#e40000\">–Ω–¥—Å </span><span title=\"23 0.8051\" style=\"background-color:#b20000\">20 </span><span title=\"24 0.7342\" style=\"background-color:#ff3b00\">% </span><span title=\"25 0.7213\" style=\"background-color:#ff4e00\">—Ä—É–±–ª–µ–π </span><span title=\"26 0.7106\" style=\"background-color:#ff5d00\">, </span><span title=\"27 0.7121\" style=\"background-color:#ff5d00\">—Ü–µ–Ω–∞ </span><span title=\"28 0.6827\" style=\"background-color:#ff8600\">–ø—Ä–∞–≤–∞ </span></div></span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"margin-left:2em\"><span style=\"font-size:80%;\"><h3 style=\"margin:0\"><b style=\"color:#333333\"> =  RUB       155,000,000.00<sup>confidence=                0.83</sup></b> </h3><div style=\"margin-left:2em\"><span title=\"0 0.7436\" style=\"background-color:#ff3000\">—á–∏—Å–ª–µ </span><span title=\"1 0.7753\" style=\"background-color:#e80000\">–Ω–¥—Å </span><span title=\"2 0.8035\" style=\"background-color:#b60000\">20 </span><span title=\"3 0.7327\" style=\"background-color:#ff4300\">% </span><span title=\"4 0.7232\" style=\"background-color:#ff5200\">. </span><span title=\"5 0.7119\" style=\"background-color:#ff6000\">\n",
              " </span><br><span title=\"6 0.7180\" style=\"background-color:#ff5900\">–æ–±—â–∞—è </span><span title=\"7 0.7247\" style=\"background-color:#ff4e00\">—Å—Ç–æ–∏–º–æ—Å—Ç—å </span><span title=\"8 0.7314\" style=\"background-color:#ff4300\">–∏–º—É—â–µ—Å—Ç–≤–∞ </span><span title=\"9 0.7561\" style=\"background-color:#ff1e00\">—Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç </span><span title=\"10 0.8332\" style=\"background-color:#800000\">155 </span><span title=\"11 0.7964\" style=\"background-color:#c40000\">000 </span><span title=\"12 0.7804\" style=\"background-color:#df0000\">000 </span><span title=\"13 0.7508\" style=\"background-color:#ff2500\">( </span><span title=\"14 0.7756\" style=\"background-color:#e80000\">—Å—Ç–æ </span><span title=\"15 0.7715\" style=\"background-color:#f10800\">–ø—è—Ç—å–¥–µ—Å—è—Ç </span><span title=\"16 0.7819\" style=\"background-color:#df0000\">–ø—è—Ç—å </span><span title=\"17 0.7581\" style=\"background-color:#ff1a00\">–º–∏–ª–ª–∏–æ–Ω–æ–≤ </span><span title=\"18 0.7471\" style=\"background-color:#ff2d00\">) </span><span title=\"19 0.7403\" style=\"background-color:#ff3800\">—Ä—É–±–ª–µ–π </span><span title=\"20 0.7381\" style=\"background-color:#ff3b00\">, </span><span title=\"21 0.7252\" style=\"background-color:#ff4e00\">–≤ </span><span title=\"22 0.7308\" style=\"background-color:#ff4700\">—Ç–æ–º </span><span title=\"23 0.7407\" style=\"background-color:#ff3800\">—á–∏—Å–ª–µ </span><span title=\"24 0.7814\" style=\"background-color:#df0000\">–Ω–¥—Å </span><span title=\"25 0.8163\" style=\"background-color:#9b0000\">20 </span><span title=\"26 0.7447\" style=\"background-color:#ff3000\">% </span><span title=\"27 0.7140\" style=\"background-color:#ff6000\">. </span><span title=\"28 0.7168\" style=\"background-color:#ff5900\">\n",
              " </span><br><span title=\"29 0.7111\" style=\"background-color:#ff6400\">\n",
              " </span><br><span title=\"30 0.7214\" style=\"background-color:#ff5500\">—Å—É–º–º–∞ </span></div></span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"margin-left:2em\"><span style=\"font-size:80%;\"><h3 style=\"margin:0\"><b style=\"color:#333333\"> =  RUB       155,000,000.00<sup>confidence=                0.83</sup></b> </h3><div style=\"margin-left:2em\"><span title=\"0 0.7435\" style=\"background-color:#ff2900\">—á–∏—Å–ª–µ </span><span title=\"1 0.7755\" style=\"background-color:#e40000\">–Ω–¥—Å </span><span title=\"2 0.8041\" style=\"background-color:#ad0000\">20 </span><span title=\"3 0.7329\" style=\"background-color:#ff3b00\">% </span><span title=\"4 0.7219\" style=\"background-color:#ff4a00\">. </span><span title=\"5 0.7109\" style=\"background-color:#ff5900\">\n",
              " </span><br><span title=\"6 0.7157\" style=\"background-color:#ff5500\">–æ–±—â–∞—è </span><span title=\"7 0.7231\" style=\"background-color:#ff4a00\">—Å—Ç–æ–∏–º–æ—Å—Ç—å </span><span title=\"8 0.7290\" style=\"background-color:#ff3f00\">–∏–º—É—â–µ—Å—Ç–≤–∞ </span><span title=\"9 0.7532\" style=\"background-color:#ff1e00\">—Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç </span><span title=\"10 0.8309\" style=\"background-color:#800000\">155 </span><span title=\"11 0.7952\" style=\"background-color:#bf0000\">000 </span><span title=\"12 0.7807\" style=\"background-color:#da0000\">000 </span><span title=\"13 0.7502\" style=\"background-color:#ff2200\">( </span><span title=\"14 0.7747\" style=\"background-color:#e40000\">—Å—Ç–æ </span><span title=\"15 0.7705\" style=\"background-color:#ed0400\">–ø—è—Ç—å–¥–µ—Å—è—Ç </span><span title=\"16 0.7812\" style=\"background-color:#d60000\">–ø—è—Ç—å </span><span title=\"17 0.7580\" style=\"background-color:#ff1600\">–º–∏–ª–ª–∏–æ–Ω–æ–≤ </span><span title=\"18 0.7473\" style=\"background-color:#ff2500\">) </span><span title=\"19 0.7417\" style=\"background-color:#ff2d00\">—Ä—É–±–ª–µ–π </span><span title=\"20 0.7398\" style=\"background-color:#ff3000\">, </span><span title=\"21 0.7276\" style=\"background-color:#ff4300\">–≤ </span><span title=\"22 0.7332\" style=\"background-color:#ff3b00\">—Ç–æ–º </span><span title=\"23 0.7438\" style=\"background-color:#ff2900\">—á–∏—Å–ª–µ </span><span title=\"24 0.7840\" style=\"background-color:#d10000\">–Ω–¥—Å </span><span title=\"25 0.8168\" style=\"background-color:#960000\">20 </span><span title=\"26 0.7470\" style=\"background-color:#ff2500\">% </span><span title=\"27 0.7258\" style=\"background-color:#ff4700\">. </span><span title=\"28 0.7118\" style=\"background-color:#ff5900\">\n",
              " </span><br><span title=\"29 0.7204\" style=\"background-color:#ff4e00\">—Å—É–º–º–∞ </span><span title=\"30 0.6909\" style=\"background-color:#ff7700\">–¥–æ–≥–æ–≤–æ—Ä–∞ </span></div></span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3 style=\"margin:0\">–ü—Ä–µ–¥–º–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (X):</h3><b style=\"font-size:135%; color:maroon\">7: –°–¥–µ–ª–∫–∞</b><div>0: –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å</div><div>1: –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "yXlLLods6UxY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Ext"
      ]
    },
    {
      "metadata": {
        "id": "5mwCvHk55yQx",
        "colab_type": "code",
        "outputId": "e2ad75ac-10a9-4b27-ef23-ca66ce3125e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "cell_type": "code",
      "source": [
        "from patterns import make_pattern_attention_vector\n",
        "from legal_docs import LegalDocument\n",
        "from contract_parser import extract_all_contraints_from_sr_2\n",
        "\n",
        "dists = 1.0 - CTX.protocols_factory.sum_pattern._find_patterns( protocol.embeddings)\n",
        "GLOBALS__['renderer'].render_color_text( protocol.tokens, dists )\n",
        "\n",
        "\n",
        "\n",
        "def find_values_2(value_section:LegalDocument):\n",
        "\n",
        "#   dists = make_pattern_attention_vector(pat, doc.embeddings, dist_function)\n",
        "  value_section.distances_per_pattern_dict['value_attention_vector_tuned'] = dists\n",
        "\n",
        "  values: List[ProbableValue] = extract_all_contraints_from_sr_2(value_section,\n",
        "                                                                 value_section.distances_per_pattern_dict[\n",
        "                                                                   'value_attention_vector_tuned'])\n",
        "\n",
        "  return values\n",
        "\n",
        "[ x.value.value for x in find_values_2(protocol)]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ef412f9e7823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontract_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_all_contraints_from_sr_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mCTX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocols_factory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_patterns\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mGLOBALS__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'renderer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_color_text\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdists\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CTX' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "h_nS3sP9OslB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from patterns import DIST_FUNC\n",
        "from ml_tools import *\n",
        "CENTER = np.array([ np.mean(protocol.embeddings, axis=0) ])\n",
        "print (protocol.embeddings.shape)\n",
        "print (CENTER.shape)\n",
        "\n",
        "DIST_FUNC ( CENTER, protocol.embeddings[200:201])\n",
        "\n",
        "\n",
        "def calc_distance_to_center(CENTER, embeddings):\n",
        "  distance_to_center = np.zeros(len(embeddings))\n",
        "  for i in range(len(embeddings)):\n",
        "    d = DIST_FUNC ( CENTER, embeddings[i:i+1])\n",
        "    distance_to_center[i]=d\n",
        "\n",
        "  distance_to_center = 1.0 - distance_to_center\n",
        "  return distance_to_center\n",
        "\n",
        "\n",
        "distance_to_center = calc_distance_to_center(CENTER, protocol.embeddings)\n",
        "distance_to_center =relu(distance_to_center, 0.4)\n",
        "GLOBALS__['renderer'].render_color_text( protocol.tokens, distance_to_center )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sJ_UCt-bYb_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### removing outliers and re-estimating center"
      ]
    },
    {
      "metadata": {
        "id": "ZGJp8huGYgl9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy.ma as ma\n",
        "\n",
        "\n",
        "# distance_to_center = relu(distance_to_center, 0.4)\n",
        "\n",
        "masked = ma.masked_less_equal (distance_to_center, 0.68)\n",
        "outliers_mask = masked.mask\n",
        "\n",
        "embeddings_masked = protocol.embeddings.view(ma.MaskedArray)\n",
        "embeddings_masked.mask=outliers_mask\n",
        "\n",
        "CENTER_2 = np.array([ np.mean(embeddings_masked, axis=0) ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "distance_to_center = calc_distance_to_center(CENTER_2, protocol.embeddings)\n",
        "distance_to_center =relu(distance_to_center, 0.3)\n",
        "print( f'\"{protocol.tokens_cc[ np.argmax(distance_to_center) ]}\"', distance_to_center.max())\n",
        "GLOBALS__['renderer'].render_color_text( protocol.tokens, distance_to_center )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}