# -*- coding: utf-8 -*-
"""2 test demo no UI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rPnNnbe5SJYck6yUymP04mMNdWpHEj3y
"""

GLOBALS__={}

#@title –ù–∞—Å—Ç—Ä–æ–π–∫–∏ { run: "auto", vertical-output: true, display-mode: "form" }
USD_to_RUB = 20034.02 #@param {type:"number"}
RUB_to_USD = 1.0/USD_to_RUB

# print('USD_to_RUB=',USD_to_RUB)
# print('RUB_to_USD=',RUB_to_USD)



currency_converter = {
  'USD': USD_to_RUB,
  'RUB': 1.0
}

print(currency_converter)

"""#MAIN"""

# @title –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ { output-height: 800, form-width: "300px", display-mode: "form" }


import os
import sys


def interactive_upload(filetype):
  from google.colab import files
  import docx2txt

  print(f'Please select "{filetype}" .docx file:')
  uploaded = files.upload()
  docs = []
  for fn in uploaded.keys():
    print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

    with open(fn, "wb") as df:
      df.write(uploaded[fn])
      df.close()

    # extract text

    text = ''
    try:
      text = docx2txt.process(fn)
    except:
      print("Unexpected error:", sys.exc_info())
      os.system('antiword -w 0 "' + fn + '" > "' + fn + '.txt"')
      with open(fn + '.txt') as f:
        text = f.read()
    print("–°–∏–º–≤–æ–ª–æ–≤ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–µ:", len(text))
    docs.append(text)
    return docs


# ====================================
# ====================================
_git_branch = "constraints"  # @param {type:"string"}
# ====================================
# ====================================


# ''' AZ:-IMPORT CODE GITHUB----------------------------------------------üò∫------ '''
import sys


def _init_import_code_from_gh():
  if 'GLOBALS__' not in globals():
    print('adding global GLOBALS__')
    global GLOBALS__
    GLOBALS__ = {}

  if '_init_import_code_from_gh' in GLOBALS__:
    print('üëå code already imported from GitHub!')
    return

  import subprocess
  def exec(x):
    r = subprocess.check_output(x, shell=True)
    r = r.decode('unicode-escape').encode('latin1').decode('utf8')
    print(r)

  print(f"fetching code from GitHub.....{_git_branch}")
  try:
    exec('rm -r nlp_tools')
  except:
    pass
  exec(f'git clone --single-branch --branch {_git_branch} https://github.com/compartia/nlp_tools.git nlp_tools')

  print('ü¶ä GIT revision:')
  exec('cd nlp_tools\ngit rev-list --reverse HEAD | awk "{ print NR }" | tail -n 1\ngit branch\ngit log -3 --pretty=%B')

  sys.path.insert(0, 'nlp_tools')

  # self-test
  from text_tools import untokenize
  print(untokenize(['code', 'imported', 'OK üëç']))

  print('installing antiword...')
  exec('sudo apt-get install antiword')

  print('installing docx2txt...')
  exec("pip install docx2txt")

  GLOBALS__['_init_import_code_from_gh'] = True

  ''' AZ:-------------------------------------------------IMPORT CODE GITHUB-üò∫---'''
  print('‚ù§Ô∏è DONE importing Code fro GitHub')


# AZ:-INIT ELMO-----------------------------------------------------------------------------------

import tensorflow as tf
import tensorflow_hub as hub


def _import_elmo():
  """
  ACHTUNG!! this method is called later by ElmoEmbedder
  """

  elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz',
                    trainable=False)  # news
  #   elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-twitter_2013-01_2018-04_600k_steps.tar.gz',
  #                     trainable=False)  # twitter
  print('‚ù§Ô∏è ‚ù§Ô∏è ‚ù§Ô∏è DONE (re)importing Tensorflow hub.Module ')
  print('Tensorflow version is', tf.__version__)

  return elmo


# AZ:-INIT EMBEDDER-----------------------------------------------------------------------------------

def _init_embedder():
  if 'elmo_embedder' in GLOBALS__:
    print('üëå Embedder is already created! ')
    return

  from embedding_tools import ElmoEmbedder
  GLOBALS__['elmo_embedder'] = ElmoEmbedder(_import_elmo(), tf, 'elmo', _import_elmo)

  print('‚ù§Ô∏è DONE creating words embedding model')
  return GLOBALS__['elmo_embedder']


# AZ:-Init chartes context-----------------------------------------------------------------------------------
def _init_charters():
  if 'CharterAnlysingContext' in GLOBALS__:
    print('üëå Charters-related tools are already inited ')
    return

  _init_embedder()  # PRECONDITION
  from charter_patterns import CharterPatternFactory
  from charter_parser import CharterDocumentParser
  CPF = CharterPatternFactory(GLOBALS__['elmo_embedder'])
  GLOBALS__['CharterAnlysingContext'] = CharterDocumentParser(CPF)
  print('‚ù§Ô∏è DONE initing Charters-related tools and models ')


def _init_contracts():
  if 'ContractAnlysingContext' in GLOBALS__:
    print('üëå Contracts-related tools are already inited ')
    return

  from contract_parser import ContractAnlysingContext
  GLOBALS__['ContractAnlysingContext'] = ContractAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['renderer'])
  print('‚ù§Ô∏è DONE initing Contracts-related tools and models ')


# AZ:- THE CODE----------------------------------------------------------------------------------
from typing import List


def _init_the_code(reset=False):
  if '_init_the_code' in GLOBALS__ and not reset:
    print('üëå Code is alredy imported!')
    return

  from transaction_values import ValueConstraint

  import matplotlib as mpl
  from IPython.core.display import display, HTML
  import matplotlib.pyplot as plt
  from renderer import AbstractRenderer, head_types_colors
  from renderer import to_multicolor_text, as_headline_3, as_offset
  from renderer import as_msg, as_quote
  from renderer import as_error_html
  from transaction_values import ValueConstraint
  from parsing import head_types_dict, head_types

  def _as_smaller(txt):
    return f'<div font-size:12px">{txt}</div>'

  def as_c_quote(txt):
    return f'<div style="margin-top:0.2em; margin-left:2em; font-size:14px">"...{txt} ..."</div>'

  v_color_map = {
    'deal_value_attention_vector': (1, 0.0, 0.5),
    'soft$.$at_sum__': (0.9, 0.5, 0.0),
      
    '$at_sum__': (0.9, 0, 0.1),
    'soft$.$at_d_order_': (0.0, 0.3, 0.9),
    
      '$at_x_charity_': (0.0, 0.9, 0.3),
    'soft$.$at_x_charity_': (0.0, 1.0, 0.0),

    'soft$.$at_x_lawsuit_': (0.8, 0, 0.7),
    '$at_x_lawsuit_': (0.9, 0, 0.9),
      
     'soft$.$at_x_realestate_': (0.2, 0.2, 1),
     '$at_x_realestate_': (0.2, 0.2, 1),
  }

  import numpy as np
  class DemoRenderer(AbstractRenderer):

    def render_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):
      print('render_color_text')
      html = self.to_color_text(tokens, weights, colormap, print_debug, _range)
      display(HTML(html))

    def to_color_text(self, tokens, weights, colormap='coolwarm', print_debug=False, _range=None):
      if len(tokens) == 0:
        return " - empty -"
      if len(weights) != len(tokens):
        raise ValueError("number of weights differs weights={} tokens={}".format(len(weights), len(tokens)))

      #   if()
      vmin = weights.min()
      vmax = weights.max()

      if _range is not None:
        vmin = _range[0]
        vmax = _range[1]

      if print_debug:
        print(vmin, vmax)

      norm = mpl.colors.Normalize(vmin=vmin - 0.5, vmax=vmax)
      html = ""
      cmap = mpl.cm.get_cmap(colormap)

      for d in range(0, len(weights)):
        word = tokens[d]
        if word == ' ':
          word = '&nbsp;_ '

        html += '<span title="{} {:.4f}" style="background-color:{}">{} </span>'.format(
          d,
          weights[d],
          mpl.colors.to_hex(cmap(norm(weights[d]))),
          word)

        #     html+='<span style="background-color:' +mpl.colors.to_hex(cmap(norm(weights[d]) ))+ '">' + str(tokens[d]) + " </span>"
        if tokens[d] == '\n':
          html += "<br>"

      return html

    ''' AZ:-Rendering CHARITYüî•-----üí∏------üí∏-------üí∏------------------------------'''
    def render_multicolor_text(self, tokens, vectors, colormap, min_color=None, _slice=None):
      display(HTML(to_multicolor_text(tokens, vectors, colormap, min_color=min_color, _slice=_slice)))

    

    ''' AZ:------üí∏------üí∏-------üí∏----------------------END--Rendering CHARITYüî•------'''

    def render_subj(self, doc):
      from demo import subject_types_dict
      subj = doc.subject
      s_name = subject_types_dict[subj[0]].upper()

      display(
        HTML(f'–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:<h3 style="margin:0">{s_name}<sup> {subj[0]}</sup> </h3> confidence:{subj[1]:20,.2f}'))

    def sign_to_text(self, sign: int):
      if sign < 0: return " &lt; "
      if sign > 0: return " &gt; "
      return ' = '

    def probable_value_to_html(self, pv):
      vc = pv.value
      color = '#333333'
      if vc.sign > 0:
        color = '#993300'
      elif vc.sign < 0:
        color = '#009933'

      return f'<b style="color:{color}">{self.sign_to_text(vc.sign)} {vc.currency} {vc.value:20,.2f} confidence={pv.confidence:20,.2f}</b> '

    def render_contents(self, doc):
      html = as_headline_3('–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞')
      html += "<ul>"
      for i in doc.structure.headline_indexes:
        line = doc.structure.structure[i].to_string(doc.tokens_cc)
        html += f'<li> {line} <sup>line {i}</sup></li>'
      html += "</ul>"

      display(HTML(html))

    def render_sections(self, sections):
      from legal_docs import HeadlineMeta
      html = as_headline_3('–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞')
      html += "<ul>"
      for section_type in sections:
        section: HeadlineMeta = sections[section_type]
        body = section.body.untokenize_cc()[:1000]
        headline = section.subdoc.untokenize_cc()[:500]
        #     line = doc.structure.structure[i].to_string(doc.tokens_cc)
        html += f'<li><h3> {headline} <sup>type: {section_type}</sup> </h3> <p>{body}</p> </li>'
      html += "</ul>"

      display(HTML(html))

    def render_values(self, values):
      if len(values) > 0:
        for pv in values:
          h = self.probable_value_to_html(pv)
          display(HTML(h))
      else:
        display(HTML('—Å—É–º–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'))

    def render_value_section_details(self, value_section_info):
      value_section = value_section_info.body
      headline_doc = value_section_info.subdoc

      headline = headline_doc.untokenize_cc()

      v_names = {
        'value_attention_vector',
        'novalue_attention_vector',

        'novalue_attention_vector_local_contrast',
        'value_attention_vector_tuned'}

      fig = plt.figure(figsize=(20, 6))
      ax = plt.axes()
      for vector_name in v_names:
        ax.plot(value_section.distances_per_pattern_dict[vector_name], label=vector_name, alpha=0.4)

      ax.plot(value_section.distances_per_pattern_dict['value_attention_vector_tuned'], label='value_attention result',
              alpha=0.9, color='black')
      plt.legend(loc='upper right')

      text = self.to_color_text(value_section.tokens_cc,
                                value_section.distances_per_pattern_dict['value_attention_vector_tuned'], _range=(0, 1))
      html = f'{ as_headline_3(headline)} <div style="margin-left:4em; font-size=90%">{text}</div>'
      display(HTML(html))

    

    def render_charter_parsing_results(self, doc, org, rz, charity_constraints):

      txt_html = self.to_color_text(org['tokens'], org['attention_vector'], _range=[0, 1])

      html = '<div style="background:#eeeeff; padding:0.5em"> recognized NE(s): <br><br> org type:<h3 style="margin:0">  {} </h3>org full name:<h2 style="margin:0">  {} </h2> <br>quote: <div style="font-size:90%; background:white">{}</div> </div>'.format(
        org['type_name'], org['name'], txt_html)
      # html+=txt_html
      html += self.render_constraint_values(doc, rz, charity_constraints)

      display(HTML(html))

    def _render_sentence(self, sentence: ConstraintsSearchResult):
      html = ""
      constraints: List[ValueConstraint] = sentence.constraints

      html += "<br>"
      for probable_v in constraints:
        html += self.value_to_html(probable_v.value)

      if len(constraints) > 0:
        html += '<div style="border-bottom:1px solid #ccc; margin-top:1em"></div>'
        search_result: PatternSearchResult = sentence.subdoc

        v = {
          search_result.attention_vector_name: search_result.get_attention(),

          '$at_sum__': search_result.get_attention('$at_sum__'),
          '$at_x_lawsuit_': search_result.get_attention('$at_x_lawsuit_'),
          '$at_x_charity_': search_result.get_attention('soft$.$at_x_charity_')
        }
        min_color = (0.3, 0.3, 0.33)
        html += as_c_quote(to_multicolor_text(search_result.tokens, v,
                                              v_color_map,
                                              min_color=min_color,
                                              _slice=None))

      return html

    

    def render_constraint_values(self, doc, rz, charity_constraints):
      from charter_parser import ConstraintsSearchResult

      html = ''
      for head_type in rz.keys():

        constraint_search_results: List[ConstraintsSearchResult] = rz[head_type]

        html += '<hr style="margin-top: 45px">'

        html += f'<h2 style="color:{head_types_colors[head_type]}; padding:0; margin:0">{head_types_dict[head_type]}</h2>'

        # html += as_quote(r_by_head_type.)

        charity_constraints_by_head = charity_constraints[head_type]

        html_i = ''
        html_i += self.html_charity_constraints_by_head(charity_constraints_by_head)

        if True:
          html_i += as_headline_3('—Ä–µ—à–µ–Ω–∏—è –æ –ø–æ—Ä–æ–≥–æ–≤—ã—Ö —Å—É–º–º–∞—Ö:')

          if len(constraint_search_results) > 0:
            for constraint_search_result in constraint_search_results:
              html_i += self._render_sentence(constraint_search_result)

          else:
            html_i += as_error_html('–ü–æ—Ä–æ–≥–æ–≤—ã–µ —Å—É–º–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω—ã')

        html += as_offset(html_i)

      return html

    ''' AZ:-Rendering CHARITYüî•-----üí∏------üí∏-------üí∏------------------------------'''

    def html_charity_constraints_by_head(self, charity_constraints_by_head: PatternSearchResults) -> str:
      html = ''

      html += as_headline_3('–æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:')

      if len(charity_constraints_by_head) > 0:

        for r in charity_constraints_by_head:
          html += '<BR>'

          v = {
            'soft$.' + r.attention_vector_name: r.parent.distances_per_pattern_dict['soft$.' + r.attention_vector_name],
            r.attention_vector_name: r.parent.distances_per_pattern_dict[r.attention_vector_name],
            #             'soft$.$at_d_order_': r.parent.distances_per_pattern_dict['soft$.$at_d_order_'],
            #             'd_order_consent': r.parent.distances_per_pattern_dict['d_order_consent']
          }

          min_color = (0.3, 0.3, 0.33)
          q_html = ''
          q_html += to_multicolor_text(r.parent.tokens_cc, v,
                                       v_color_map, min_color=min_color, _slice=r.region)
          html += as_c_quote(q_html)
      else:
        html += as_msg('–Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ')

      return html

  GLOBALS__['renderer'] = DemoRenderer()

  # AZ:----------PROTOCOLS RENDERER-------------------------

  from legal_docs import LegalDocument

  import matplotlib as mpl
  from IPython.core.display import display, HTML
  from renderer import as_headline_3, as_headline_4
  
  class ProtocolRenderer(DemoRenderer):

    def winning_patterns_to_html(self, _tokens, ranges, winning_patterns, _range,
                                 colormaps=['Reds', 'Purples', 'Blues', 'Greens', 'Greys']):
      vmin = -ranges[1]
      vmax = -ranges[0]

      #     print("winning_patterns_to_html _range", _range, "min max=", ranges)

      norm = mpl.colors.Normalize(vmax=vmax, vmin=vmin)

      cmaps = []

      #     print (colormaps)
      for n in colormaps:
        cmap = mpl.cm.get_cmap(n)
        cmaps.append(cmap)

      html = ""

      for d in _range:
        winning_pattern_i = winning_patterns[d][0]
        colormap = cmaps[winning_pattern_i % len(colormaps)]
        normed = norm(-winning_patterns[d][1])
        color = mpl.colors.to_hex(colormap(normed))
        html += '<span title="' + '{} {:.2f}'.format(d, winning_patterns[d][
          1]) + '" style="background-color:' + color + '">' + str(
          _tokens[d]) + " </span>"
        if _tokens[d] == '\n':
          html += "<br>"

      return html

    def _render_doc_subject_fragments(self, doc):
      #     print(doc.per_subject_distances)

      _html = ""
      if doc.per_subject_distances is not None:

        type = "–î–æ–≥–æ–≤–æ—Ä  –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è"
        if doc.per_subject_distances[0] > doc.per_subject_distances[1]:
          type = "–î–æ–≥–æ–≤–æ—Ä –≤–æ–∑–º–µ–∑–¥–Ω–æ–≥–æ –æ–∫–∞–∑–∞–Ω–∏—è —É—Å–ª—É–≥"

        _html += "<h3>" + type + "</h3>"

        colormaps = ['PuRd'] * 5 + ['Blues'] * 7 + ['Greys']

        _html += as_headline_4('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞')

        for region in [doc.subj_range]:
          _html += self.winning_patterns_to_html(_tokens=doc.tokens, ranges=doc.subj_ranges,
                                                 winning_patterns=doc.winning_subj_patterns, _range=region,
                                                 colormaps=colormaps)

      return _html

    def render_subject(self, counter):
      html = as_headline_3('–ü—Ä–µ–¥–º–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ (X):') + self.subject_type_weights_to_html(counter)
      display(HTML(html))

    def print_results(self, _doc: LegalDocument, results=None):

      if results is None:
        results = _doc.found_sum

      result, (start, end), sentence, meta = results

      html = "<hr>"

      html += self._render_doc_subject_fragments(_doc)

      if result is None:
        html += '<h2 style="color:red">–°–£–ú–ú–ê –ù–ï –ù–ê–ô–î–ï–ù–ê</h2>'
      else:
        html += '<h2>' + str(result[0]) + ' ' + str(result[1]) + '</h2>'

      for key in meta.keys():
        html += '<div style="font-size:9px">' + str(key) + " = " + str(meta[key]) + "</div>"

      display(HTML(html))
      self.render_color_text(_doc.tokens[start:end], _doc.sums[start:end])

    def subject_type_weights_to_html(self, counter):
      dict = {
        't_dea': '–°–¥–µ–ª–∫–∞',
        't_cha': '–ë–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å',
        't_org': '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è'
      }

      maxkey = "None"
      for key in dict:
        if counter[key] > counter[maxkey]:
          maxkey = key

      html = ""
      for key in dict:
        templ = "<div>{}: {}</div>"
        if key == maxkey:
          templ = '<b style="font-size:135%; color:maroon">{}: {}</b>'
        html += templ.format(counter[key], dict[key])

      return html

  GLOBALS__['ProtocolRenderer'] = ProtocolRenderer()

  from demo_protocols import ProtocolAnlysingContext
  GLOBALS__['ProtocolAnlysingContext'] = ProtocolAnlysingContext(GLOBALS__['elmo_embedder'], GLOBALS__['ProtocolRenderer'])
  GLOBALS__['_init_the_code'] = True

  # AZ:-------------------------------------------------Init Protocols context===

  # AZ:-------------------------------------------------Init Charters context====

  def read_doc(fn):
    import docx2txt, sys, os
    text = ''
    try:
      text = docx2txt.process(fn)
    except:
      print("Unexpected error:", sys.exc_info())
      os.system('antiword -w 0 "' + fn + '" > "' + fn + '.txt"')
      with open(fn + '.txt') as f:
        text = f.read()

    return text

  GLOBALS__['read_doc'] = read_doc

  print("‚ù§Ô∏è DONE initializing the code")


# AZ:-FINDING_VIOLATIONS--------------------------------------------------------
def find_and_show_violations():
  from IPython.core.display import display, HTML

  from contract_parser import ContractAnlysingContext
  from renderer import as_headline_2, as_error_html

  print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')

  charterAnlysingContext: CharterAnlysingContext = GLOBALS__['CharterAnlysingContext']
  contractAnlysingContext: ContractAnlysingContext = GLOBALS__['ContractAnlysingContext']

  contract = contractAnlysingContext.contract
  charter = charterAnlysingContext.doc
  charter_constraints = charterAnlysingContext.constraints  # XXX: move to doc

  renderer = GLOBALS__['renderer']
  renderer.render_subj(contract)

  import copy

  def convert(v):
    v_converted = copy.copy(v)
    if v.currency in currency_converter:
      v_converted.value = currency_converter[v.currency] * v.value
      v_converted.currency = 'RUB'
      return v_converted
    else:
      display(HTML(as_error_html(
        f"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?")))
      return v

  best_value = contractAnlysingContext.find_contract_best_value(convert)

  # rendering:----------------------------

  def _render_violations(ranges_by_group, best_value):
    for group_key in ranges_by_group:
      group = ranges_by_group[group_key]
      display(HTML(as_headline_2(group['name'])))

      for rk in group['ranges']:
        r = group['ranges'][rk]
        display(HTML(r.check_contract_value(best_value, convert, renderer)))

  print("–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:")
  renderer.render_values([best_value])
  renderer.render_color_text(best_value.value.context.tokens, best_value.value.context.attention, _range=[0, 1])

  _render_violations(
    charterAnlysingContext.find_ranges_by_group(charter_constraints, convert, verbose=False),
    best_value)

#   display(HTML(renderer.render_constraint_values(charter_constraints)))


# AZ:--------------------------------------------------------FINDING_VIOLATIONS-

# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX
# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX
# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXXX
# AZ:- ENDO OF THE THE CODE------------------------------------------------XXXX

"""# step 0. –ò–Ω–∏—Ç –≤—Å–µ–≥–∞"""

## do preparation here

# 1.
_init_import_code_from_gh()
# 2.
_init_embedder()
# 3.
_init_the_code()
4.
_init_charters()
# 5.
_init_contracts()

"""# step 1. –£—Å—Ç–∞—Ñ—Ñ"""

uploaded = interactive_upload('–£—Å—Ç–∞—Ñ—Ñ, –æ–Ω –ª—ë—Ö—Ö—Ö, –Ω–æ –ø–æ–¥—É–º–∞—Ñ—Ñ –æ–Ω –æ—Å–æ–∑–Ω–∞–ª, —á—Ç–æ –æ–Ω –Ω–µ —Ç–∞–∫–æ–π —É–∂ –∏ –õ—ë—Ö—Ö')

_CTX = GLOBALS__['CharterAnlysingContext']
_CTX.verbosity_level=2
_CTX.analyze_charter(uploaded[0], True)


GLOBALS__['renderer'].render_charter_parsing_results(_CTX.doc, _CTX.org, _CTX.constraints, _CTX.charity_constraints)
GLOBALS__['renderer'].render_contents(_CTX.doc)

# GLOBALS__['renderer'].render_charter_parsing_results(_CTX.doc, _CTX.org, _CTX.constraints, _CTX.charity_constraints)
_CTX.charity_constraints

# del(GLOBALS__['_init_the_code'] )
_init_the_code(True)
GLOBALS__['renderer'].render_charter_parsing_results(_CTX.doc, _CTX.org, _CTX.constraints, _CTX.charity_constraints)
GLOBALS__['renderer'].render_contents(_CTX.doc)

GLOBALS__['CharterAnlysingContext'].constraints['head.directors'][0].__dict__

"""### tests, experiments"""

if False:
  GLOBALS__['CharterAnlysingContext'].verbosity_level=2
  org, rz = GLOBALS__['CharterAnlysingContext'].analyze_charter(text, True)
  doc = GLOBALS__['CharterAnlysingContext'].doc
  charity_constraints = GLOBALS__['CharterAnlysingContext'].charity_constraints
  org = GLOBALS__['CharterAnlysingContext'].org


  GLOBALS__['renderer'].render_contents(doc)
  GLOBALS__['renderer'].render_charter_parsing_results(doc, org, rz)



"""## üëû Constraint type detection"""



def build_realestate_patterns(factory):
  def cp(name, tuples):
    return factory.create_pattern(name, tuples)

  cp('x_realestate_1', ('–æ—Ç—á—É–∂–¥–µ–Ω–∏—é –∞–∫—Ç–∏–≤–æ–≤ –æ–±—â–µ—Å—Ç–≤–∞ ( –≤–∫–ª—é—á–∞—è', '–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å', '',))

  cp('x_realestate_2', ('—Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤, —Ü–µ–Ω–∞ ',
                       '–∏—Å–∫–∞',
                       '–ø–æ –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–µ–≤—ã—à–∞–µ—Ç'))
 
  
  
build_realestate_patterns(GLOBALS__['CharterAnlysingContext'].pattern_factory)
GLOBALS__['CharterAnlysingContext'].pattern_factory.embedd()

def build_lawsuit_patterns(factory):
  def cp(name, tuples):
    return factory.create_pattern(name, tuples)

#   cp('x_lawsuit_4', ('–Ω–∞—á–∞–ª–æ/—É—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ª—é–±—ã—Ö', '—Å—É–¥–µ–±–Ω—ã—Ö', 
#                 '—Å–ø–æ—Ä–æ–≤, –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –º–∏—Ä–æ–≤–æ–≥–æ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è, –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ –∏—Å–∫–∞, –æ—Ç–∫–∞–∑ –æ—Ç –∏—Å–∫–∞, –∞ —Ç–∞–∫–∂–µ –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ  ',
#                       ))

#   cp('x_lawsuit_3', ('—Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤, —Ü–µ–Ω–∞ ',
#                        '–∏—Å–∫–∞',
#                        '–ø–æ –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–µ–≤—ã—à–∞–µ—Ç'))
  cp('x_lawsuit_6', ( '–ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ–± –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π –∏ —Ä–µ—à–µ–Ω–∏–π , —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–æ', '—Å–ø–æ—Ä–∞–º–∏', '–û–±—â–µ—Å—Ç–≤–∞ —Å –û—Ä–≥–∞–Ω–∞–º–∏ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω–æ–π –≤–ª–∞—Å—Ç–∏ , –Ω–∞ —Å—É–º–º—ã '  ))
  
  
 
  
  
build_lawsuit_patterns(GLOBALS__['CharterAnlysingContext'].pattern_factory)
GLOBALS__['CharterAnlysingContext'].pattern_factory.embedd()

def build_incl_patterns(factory):
  def cp(name, tuples):
    return factory.create_pattern(name, tuples)

  cp('x_exclusive_1', ('', '–∏—Å–∫–ª—é—á–∞—è', '—Å–¥–µ–ª–∫–∏'))

  cp('x_inclusive_1', ('', '–≤–∫–ª—é—á–∞—è', '—Å–¥–µ–ª–∫–∏'))
  
build_incl_patterns(GLOBALS__['CharterAnlysingContext'].pattern_factory)
GLOBALS__['CharterAnlysingContext'].pattern_factory.embedd()

_init_the_code(True)

from IPython.core.display import display, HTML

CH_CTX=GLOBALS__['CharterAnlysingContext']

from charter_patterns import find_sentences_by_pattern_prefix

a:dict = find_sentences_by_pattern_prefix(  CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'x_charity_')
b:dict = find_sentences_by_pattern_prefix(  CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'sum__')
lawsuits = find_sentences_by_pattern_prefix(  CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'x_lawsuit_')
  
def merge_quotes_by_head_type (a, b):
  res={}
  for head in a:
    res[head] = a[head]+b[head]
  return res
  
merged=merge_quotes_by_head_type(a, b)
merged=merge_quotes_by_head_type(merged, lawsuits)
# soft$.$at_sum__
for head in merged:
  print(CH_CTX.doc.sections[head].body.distances_per_pattern_dict.keys())
  html = GLOBALS__['renderer'].html_charity_constraints_by_head(merged[head] )
  display(HTML(html))

from IPython.core.display import display, HTML
_init_the_code(True)
CH_CTX=GLOBALS__['CharterAnlysingContext']

from charter_patterns import find_sentences_by_pattern_prefix
realestates = find_sentences_by_pattern_prefix( CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'sum__')
  

for head in lawsuits:
  html = GLOBALS__['renderer'].html_charity_constraints_by_head(realestates[head] )
  display(HTML(html))

from IPython.core.display import display, HTML

CH_CTX=GLOBALS__['CharterAnlysingContext']

from charter_patterns import find_sentences_by_pattern_prefix
lawsuits = find_sentences_by_pattern_prefix( CH_CTX.pattern_factory, CH_CTX._get_head_sections(), 'x_lawsuit_')
  
 
  
# soft$.$at_sum__
for head in lawsuits:
  print(CH_CTX.doc.sections[head].body.distances_per_pattern_dict.keys())
  html = GLOBALS__['renderer'].html_charity_constraints_by_head(lawsuits[head] )
  display(HTML(html))

from legal_docs import PatternSearchResults, PatternSearchResult
def substract_search_results(a:PatternSearchResults, b:PatternSearchResults):
  b_indexes = [ x.region.start for x in b]
  result=[]
  for x in a:
    if x.region.start not in b_indexes:
      result.append(x)
  return result
  
# for head in lawsuits:
#   rest = substract_search_results(merged, lawsuits)

from transaction_values import complete_re
from text_tools import untokenize, tokenize_text
from legal_docs import extract_sum_and_sign_3
import re

def tokens_before_index(string, index):
  return len(string[:index].split(' '))
  
for head in lawsuits:

  rest = substract_search_results(merged[head], lawsuits[head])
  
  html = GLOBALS__['renderer'].html_charity_constraints_by_head(rest)
  
#   def tokens_before_index(sting, index):
  for sr in rest:
    
    
    sentence = ' '.join(sr.tokens)
    all = [slice(m.start(0), m.end(0)) for m in re.finditer(complete_re, sentence)]
    for a in all:
      print (tokens_before_index(sentence, a.start),'from',sentence[a])
      
      
      
      token_index_s = tokens_before_index(sentence, a.start) - 1
      token_index_e = tokens_before_index(sentence, a.stop)  
      
      slice_=slice(token_index_s, token_index_e)
      print("token:", slice_)
      
      vc = extract_sum_and_sign_3(sr, slice_)
      print(vc.value)
#       finds = complete_re.search(sentence)
#       if finds is not None:
#         print(   )
# #         print(len(finds) )
# #         for find in finds:


#         print('--')
  
  
  
#   complete_re.search(sentence)

  display(HTML(html))

from charter_parser import ConstraintsSearchResult
from IPython.core.display import display, HTML
from renderer import as_quote, to_multicolor_text

# v_color_map = {
#     'deal_value_attention_vector': (1, 0.0, 0.5),
#     'soft$.$at_sum__': (0.9, 0.5, 0.0),
#     '$at_sum__': (0.9, 0, 0.1),
#     'soft$.$at_d_order_':   (0.0, 0.3, 0.9),
#     '$at_x_charity_': (0.0, 0.9, 0.3),
#     'soft$.$at_x_charity_': (0.0, 1.0, 0.0),
      
#     'soft$.$at_x_lawsuit_': (0.8, 0, 0.7),
#     '$at_x_lawsuit_': (0.9, 0, 0.9),
#   }

# def _render_sentence(self, sentence: ConstraintsSearchResult):
#   html = ""
#   constraints: List[ValueConstraint] = sentence.constraints

#   html += "<br>"
#   for probable_v in constraints:
#     html += self.value_to_html(probable_v.value)

#   if len(constraints) > 0:
#     html += '<div style="border-bottom:1px solid #ccc; margin-top:1em"></div>'
#     search_result:PatternSearchResult = sentence.subdoc

#     v = {
#       search_result.attention_vector_name:search_result.get_attention (),

#       '$at_sum__': search_result.get_attention ('$at_sum__'),
#       '$at_x_lawsuit_': search_result.get_attention('soft$.$at_x_lawsuit_'),
#       '$at_x_charity_': search_result.get_attention('soft$.$at_x_charity_')
#     }
#     min_color = (0.3, 0.3, 0.33)
#     html += as_quote(to_multicolor_text(search_result.tokens, v,
#                                           v_color_map,
#                                           min_color=min_color,
#                                           _slice=None))

#   return html




CH_CTX=GLOBALS__['CharterAnlysingContext']


for constraints in CH_CTX.constraints['head.gen']:
  html =GLOBALS__['renderer']._render_sentence(constraints)
  display(HTML(html))
  print(constraints.subdoc.__dict__)
  
# for sentence in CH_CTX.constraints['head.all']:
#   html =GLOBALS__['renderer']._render_sentence(sentence)
#   display(HTML(html))



from legal_docs import calculate_distances_per_pattern
from ml_tools import *
from patterns import *

#XXX: renamed from find_charity_sentences


  
 

###-----test
CH_CTX=GLOBALS__['CharterAnlysingContext']
renderer = GLOBALS__['renderer']
charter = CH_CTX.doc
section = charter.sections['head.directors'].body


slices1, attention_v_name_consent = find_sentences_by_pattern_prefix (section, CH_CTX.pattern_factory, pattern_prefix='d_order_consent')
slices2, attention_v_name_charity = find_sentences_by_pattern_prefix (section, CH_CTX.pattern_factory, pattern_prefix='x_charity')
slices3, attention_v_name_law = find_sentences_by_pattern_prefix (section, CH_CTX.pattern_factory, pattern_prefix='x_lawsuit_')
slices4, attention_v_currency = find_sentences_by_pattern_prefix (section, CH_CTX.pattern_factory, pattern_prefix='currency')


attention_incl,_ = make_attention_vector(section, CH_CTX.pattern_factory, 'x_inclusive')
attention_excl,_ = make_attention_vector(section, CH_CTX.pattern_factory, 'x_exclusive')

attention_excl=momentum(attention_excl, 0.9)

colormap = {
    'red':(1,0,0),
    'red1':(1,0.4,0),
    'green':(0,1,0),
    'blue':(0,0,1),
    'cyan':(0,0.7,1),
    'yellow':(0.9,0.8,0)
}

alltogether={}
def merge_slices(slices1):
  for _slice in slices1:
    alltogether[_slice [0].start] = _slice
    ss=section.subdoc_slice( _slice [0] )

merge_slices(slices1)
merge_slices(slices3)
merge_slices(slices2)
merge_slices(slices4)

ssss=[]
for k in alltogether:
  _slice=alltogether[k]
#   print(_slice)
  ss=section.subdoc_slice( _slice [0] )
  vectors = {
    'red':ss.distances_per_pattern_dict['soft$.'+attention_v_name_law],
    'cyan':ss.distances_per_pattern_dict['soft$.'+attention_v_name_charity],
#     'green':ss.distances_per_pattern_dict['soft$.'+attention_v_name_consent],
    'red1':ss.distances_per_pattern_dict['soft$.'+attention_v_currency],
      
    'yellow':attention_incl[_slice [0] ],
    'green':attention_excl[_slice [0] ],
  }
  ssss.append(ss)
#   print (ss.tokens_cc)
  renderer.render_multicolor_text(ss.tokens_cc, vectors, colormap=colormap)
#   renderer.render_color_text(ss.tokens, vectors['red'])
del ssss
# print (slices)
# print(section.distances_per_pattern_dict)
# vectors['red']
from IPython.core.display import display, HTML
display(HTML('ddd'))
GLOBALS__['renderer'].__dict__

# contract value: 5
  
# directors:{
    
#     [4, 6]: True
#     [6, 20]: False
#     [2, inf]: True
#     [-inf, 4]: False
    
# } ==> True | False | True | False ===> True
  
  
  
# all:{    
#     [6, inf]: False
#     [6, 20]: False
#     [2, inf]: True
#     [-inf, 4]: False
    
# } ==> True | False | True | False ===> True
  
  
# for level in OrgLevel:
#   for constraint in OrgLevel.constraints:
#     if contract.value in range(constraint.min, constraint.max) 
#       if constraint.subj == contract.subj
#         raise RedFlag('–∞ —á–æ –ø—Ä–æ—Ç–æ–∫–æ–ª-—Ç–æ –µ—Å—Ç—å?')

# if contract.value > max ( every constraint.max)
#    raise RedFlag('—á—Ç–æ-—Ç–æ –Ω–µ —Ç–∞–∫')

"""#### Charitiy finder"""

def build_charity_patterns(factory):
  def cp(name, tuples):
    return factory.create_pattern(name, tuples)

  cp('x_charity_1', ('–¥–æ–≥–æ–≤–æ—Ä',
                     '–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ',
                     '–ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏—è'))

  cp('x_charity_1.1', ('–æ–¥–æ–±—Ä–µ–Ω–∏–µ –≤–Ω–µ—Å–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∫–∞–∫–∏—Ö-–ª–∏–±–æ –≤–∫–ª–∞–¥–æ–≤ –∏–ª–∏ –ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–π –Ω–∞ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–ª–∏',
                       '–±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ',
                       '—Ü–µ–ª–∏'))

  cp('x_charity_1.2', ('–æ–¥–æ–±—Ä–µ–Ω–∏–µ –≤–Ω–µ—Å–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∫–∞–∫–∏—Ö-–ª–∏–±–æ –≤–∫–ª–∞–¥–æ–≤ –∏–ª–∏',
                       '–ø–æ–∂–µ—Ä—Ç–≤–æ–≤–∞–Ω–∏–π',
                       '–Ω–∞ –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏–ª–∏ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ü–µ–ª–∏ '))

  cp('x_charity_2', ('–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ',
                     '–±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–π',
                     '–ø–æ–º–æ—â–∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π')),

  cp('x_charity_3', ('—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ —Å–¥–µ–ª–æ–∫',
                     ' –¥–∞—Ä–µ–Ω–∏—è ',
                     ' '))


from typing import List

import numpy as np

from legal_docs import calculate_distances_per_pattern
from ml_tools import filter_values_by_key_prefix, max_exclusive_pattern, relu
from patterns import improve_attention_vector, PatternSearchResult, ConstraintsSearchResult, PatternSearchResults
from text_tools import get_sentence_bounds_at_index


def find_charity_constraints(doc, factory, head_sections:dict ) -> dict:
  charity_quotes_by_head_type = {}
  for section_name in head_sections:

    # section_name = section_prefix + head
    # print(head, '->', section_name)
    if section_name in doc.sections:
      subdoc = doc.sections[section_name].body
      # subdoc.calculate_distances_per_pattern(TFAA)

      print(section_name)
      bounds = find_charity_sentences(subdoc, factory)
      charity_quotes_by_head_type[section_name] = bounds

      # print('ok')
  return charity_quotes_by_head_type


def find_charity_sentences(subdoc, factory) -> List:
  """
    returns list of tuples (slice, confidence, summa-of-attention-)
  """

  calculate_distances_per_pattern(subdoc, factory, merge=True, pattern_prefix='x_charity_')

  slices = []
  vectors = filter_values_by_key_prefix(subdoc.distances_per_pattern_dict, 'x_charity_')
  vectors_i = []
  for v in vectors:
    if max(v) > 0.6:
      vector_i, _ = improve_attention_vector(subdoc.embeddings, v, relu_th=0.6, mix=0.9)
      vectors_i.append(vector_i)
    else:
      vectors_i.append(v)

  x = max_exclusive_pattern(vectors_i)
  x = relu(x, 0.8)
  subdoc.distances_per_pattern_dict['$at_x_charity_'] = x

  dups = {}
  for i in np.nonzero(x)[0]:
    bounds = get_sentence_bounds_at_index(i, subdoc.tokens)

    if bounds[0] not in dups:
      sl = slice(bounds[0], bounds[1])
      sum_ = sum(x[sl])
      confidence = 'x'
      #       confidence = np.mean( np.nonzero(x[sl]) )
      nonzeros_count = len(np.nonzero(x[sl])[0])
      print('nonzeros_count=', nonzeros_count)
      confidence = 0

      if nonzeros_count > 0:
        confidence = sum_ / nonzeros_count
      print('confidence=', confidence)
      if confidence > 0.8:
        # GLOBALS__['renderer'].render_color_text(subdoc.tokens_cc[sl],
        #                                         subdoc.distances_per_pattern_dict['$at_x_charity_'][sl], _range=(0, 1))
        print(i, sum_)

        slices.append((sl, confidence, sum_))

      dups[bounds[0]] = True

  return slices




##---test

# find_charity_constraints(self.doc, GLOBALS__['CharterAnlysingContext'].pattern_factory, self._get_head_sections())
# GLOBALS__['CharterAnlysingContext'].

charity_constraints = find_charity_constraints(doc, 
                                               GLOBALS__['CharterAnlysingContext'].pattern_factory, 
                                               GLOBALS__['CharterAnlysingContext']._get_head_sections())

"""#### Render charity constraints"""

#---CharterRenderer
_CTX = GLOBALS__['CharterAnlysingContext']
_cr = CharterRenderer()
_cr.render_charter_parsing_results(_CTX.doc, _CTX.org, _CTX.constraints, _CTX.charity_constraints)
# _cr.render_contents(_CTX.doc)

# # GLOBALS__['renderer'].render_color_text(subdoc.tokens_cc, subdoc.distances_per_pattern_dict['x_charity_1.2'], _range=(0,1))
# # x = max_exclusive_pattern_by_prefix(subdoc.distances_per_pattern_dict, 'x_charity_')
# import numpy as np
# from text_tools import get_sentence_bounds_at_index
# from ml_tools import filter_values_by_key_prefix,max_exclusive_pattern, momentum, smooth_safe, smooth, relu
# from patterns import improve_attention_vector
# vectors = filter_values_by_key_prefix(subdoc.distances_per_pattern_dict, 'x_charity_')
# vectors_i=[]
# for v in vectors:
#   if max(v)>0.6:
#     vector_i, _ = improve_attention_vector(subdoc.embeddings, v, relu_th=0.6, mix=0.9)
#     vectors_i.append(vector_i)
#   else:
#     vectors_i.append(v)
    
# x = max_exclusive_pattern(vectors_i)
# x=relu(x, 0.8)
# i = np.argmax(x)
# sl = slice( i-150, i+150)



# dups={}
# for i in np.nonzero(x)[0]:
#   bounds = get_sentence_bounds_at_index( i, subdoc.tokens)
  
#   if bounds[0] not in dups:
#     sl=slice(bounds[0], bounds[1])
#     sum_ = sum(x[sl])

#     if sum_ >2:
#       GLOBALS__['renderer'].render_color_text(subdoc.tokens_cc[sl], x[sl], _range=(0,1))
#       print(i, sum_)
# #       yeld (bounds)

#     dups[bounds[0]]=True

"""### Miscl"""

if False:
  doc.embedd(GLOBALS__['ContractAnlysingContext'].hadlines_factory)

if False:
  # GLOBALS__['ContractAnlysingContext'].hadlines_factory.

  doc.calculate_distances_per_pattern(GLOBALS__['CharterAnlysingContext'].hadlines_factory)

# print(doc.distances_per_pattern_dict.keys())
from legal_docs import rectifyed_sum_by_pattern_prefix

from ml_tools import max_exclusive_pattern_by_prefix




vv = max_exclusive_pattern_by_prefix(doc.distances_per_pattern_dict, 'headline.name.1')
print(vv[0:10])



# GLOBALS__['renderer'].render_color_text(doc.tokens_cc, vv)

for s in doc.sections:
  print (s)
  
if 'head.directors' in doc.sections:
  subdoc = doc.sections['head.directors'].body
  for ky in subdoc.distances_per_pattern_dict:
    print(ky)
  GLOBALS__['renderer'].render_color_text(subdoc.tokens_cc, subdoc.distances_per_pattern_dict['deal_attention_vector'])

level_by_line = [ max ( i._possible_levels) for i in doc.structure.structure ]
 


headlines_attention_vector=[]
for i in doc.structure.structure:
  l = i.span[1]-i.span[0]
  headlines_attention_vector+=[level_by_line[ i.line_number ]]*l
  
# print (pv[0:100])
headlines_attention_vector = normalize(headlines_attention_vector)
headlines_attention_vector = relu(headlines_attention_vector, 0.4)

# headlines_attention_vector = smooth(headlines_attention_vector, 20)

av= relu(headlines_attention_vector/2 + vv, 0.6)
av = momentum(av, 0.99)

GLOBALS__['renderer'].render_color_text(doc.tokens_cc, av)

"""## Meta-pattern! (Cool!!(!))
—Ç–∏–ø–∞ —Å–∞–º–æ–æ–±—É—á–µ–Ω–∏–µ
"""

# ---------
from patterns import FuzzyPattern
best_id=np.argmax(av)
best_embedding_v = doc.embeddings[best_id]

meta_pattern=FuzzyPattern('s-meta-na')
meta_pattern.embeddings =  np.array([ best_embedding_v ])

meta_pattern_attention = 1.0 - meta_pattern._eval_distances(doc.embeddings)
meta_pattern_attention = relu(meta_pattern_attention,  0.7)


GLOBALS__['renderer'].render_color_text(doc.tokens_cc, meta_pattern_attention, _range=(0,1))

import matplotlib as mpl
import matplotlib.pyplot as plt
fig = plt.figure(figsize=(20, 6))
ax = plt.axes()
span=1400
ax.plot(meta_pattern_attention[best_id-span:best_id+span], alpha=0.5, color='green', label='meta_pattern_attention');
ax.plot(normalize(av[best_id-span:best_id+span]), alpha=0.5, color='red', label='av');

"""# step 2. –î–æ–≥–æ–≤–æ—Ä"""

uploaded = interactive_upload('–î–æ–≥–æ–≤–æ—Ä –≤ –∑–∞–∫–æ–Ω–µ')

GLOBALS__['ContractAnlysingContext'].analyze_contract(uploaded[0])
doc = GLOBALS__['ContractAnlysingContext'].contract

GLOBALS__['renderer'].render_subj(doc)
GLOBALS__['renderer'].render_contents(doc)

"""# step 3. –ü–æ–∏—Å–∫ –≤—Ä–µ–¥–∞"""

find_and_show_violations()

"""### subj correlations"""

print(GLOBALS__['ContractAnlysingContext'].contract.sections['subj'].body.untokenize_cc())
print("-"*20)
print(GLOBALS__['CharterAnlysingContext'].constraints['head.directors']['sentences'][1]['subdoc'].untokenize_cc())


docA=GLOBALS__['ContractAnlysingContext'].contract.sections['subj'].body
docB=GLOBALS__['CharterAnlysingContext'].constraints['head.directors']['sentences'][1]['subdoc']


GLOBALS__['CharterAnlysingContext'].constraints['head.directors']['sentences'][1]

# GLOBALS__['CharterAnlysingContext'].doc.constraints
_init_the_code(reset=True)

from patterns import dist_mean_cosine as DF
from text_tools import untokenize

#
# docA.embedd( GLOBALS__['CharterAnlysingContext'].pattern_factory )
# docB.embeddings[0:10]
# docA.embeddings = None
import numpy as np


def match_contract_to_charter_constraints(contract, charter, charter_constraints, charity_constraints):
  """
  find best constraint to apply to Contract
  """

  r_quotes = []
  r_vector = []

  quote_slice = slice(0, 17)

  if 'subj' not in contract.sections:
    raise ValueError("contract has no subject section")

  subj = contract.sections['subj'].body
  print(subj.untokenize_cc())
  print('------')
  if subj.embeddings is None:
    print("Subj embeddings are gone, restoring...")
    subj.embeddings = contract.embeddings[subj.start:subj.end]
    #     subj.tokens = doc.tokens[subj.start:subj.end]
    #     subj.tokens_cc = doc.tokens_cc[subj.start:subj.end]
    #     subj.embedd( GLOBALS__['CharterAnlysingContext'].pattern_factory )
    print('\t\t sample:', subj.embeddings[0][1:10])

  for head_type in charter_constraints:

    ##charity:
    if head_type in charity_constraints:
      print(f'{head_type} has charity constrinats')
      
      charity_constraints_by_head = charity_constraints[head_type]
      charity_constraints_by_head_new = []
      
      charity_constraints['new.'+head_type] = charity_constraints_by_head_new
      
      for i in range(len(charity_constraints_by_head)):
        _tuple = charity_constraints_by_head[i] 
#       for cc in charity_constraints[head_type]:
        _slice = _tuple[0]
        emb_charter = charter.sections[head_type].body.embeddings[_slice]
        
        distance = 1 - DF(emb_charter,  subj.embeddings[5:])
        
#         cc.add['subj_correlation'] = distance
        
#         detupling
        charity_constraints_by_head_new.append ( {
            'slice':_slice,
            'subj_correlation': distance,
            'confidence': _tuple[1],
            'sum': _tuple[2]
        })
  
        print('\t'*4, 'cc=', charity_constraints_by_head_new[i])
        
        #         print('\t\t---CC', cc[0])
        

    #       GLOBALS__['CharterAnlysingContext'].doc.sections['head.directors'].body.embeddings[_slice]

    ##------------------------charity end
    print(f'measuring {head_type} constraints...'.upper())
    cc = charter_constraints[head_type]
    quotes = cc['sentences']
    for quote in quotes:
      print()
      _q = untokenize(quote['subdoc'].tokens_cc[quote_slice])
      print(_q)

      distance = 1 - DF(quote['subdoc'].embeddings[quote_slice],
                        subj.embeddings[5:])

      quote['subj_correlation'] = distance

      print(f'distance = {distance:.4f}')

      r_quotes.append(_q)
      r_vector.append(distance)
      r_quotes.append('\n')
      r_vector.append(distance)

  GLOBALS__['renderer'].render_color_text(r_quotes, r_vector)
  print(r_vector)
  print(r_quotes)
  
  
match_contract_to_charter_constraints(GLOBALS__['ContractAnlysingContext'].contract,
                                      GLOBALS__['CharterAnlysingContext'].doc,
                                      GLOBALS__['CharterAnlysingContext'].constraints,
                                      GLOBALS__['CharterAnlysingContext'].charity_constraints
                                     )

from ml_tools import ProbableValue, np, TokensWithAttention
from renderer import as_warning, as_offset, as_error_html, as_msg, as_quote, as_currency
from text_tools import untokenize
from transaction_values import ValueConstraint

# //copy
class ViolationsFinder:

  def find_ranges_by_group(self, charter_constraints, m_convert, verbose=False):
    ranges_by_group = {}
    for head_group in charter_constraints:
      #     print('-' * 20)
      group_c = charter_constraints[head_group]
      data = self._combine_constraints_in_group(group_c, m_convert, verbose)
      ranges_by_group[head_group] = data
    return ranges_by_group

  @staticmethod
  def _combine_constraints_in_group(group_c, m_convert, verbose=False):
    # print(group_c)
    # print(group_c['section'])

    data = {
      'name': group_c['section'],
      'ranges': {}
    }

    sentences = group_c['sentences']
    #   print (charter_constraints[head_group]['sentences'])
    sentence_id = 0
    for sentence in sentences:
      constraint_low = None
      constraint_up = None

      sentence_id += 1
      #     print (sentence['constraints'])

      s_constraints = sentence['constraints']
      # –±–æ–ª—å—à–∏–µ –∏—â–µ–º
      maximals = [x for x in s_constraints if x.value.sign > 0]

      if len(maximals) > 0:
        constraint_low = min(maximals, key=lambda item: m_convert(item.value).value)
        # if verbose:
        #   print("all maximals:")
        #   self.renderer.render_values(maximals)
        #   print('\t\t\t constraint_low', constraint_low.value.value)
        #   self.renderer.render_values([constraint_low])

      minimals = [x for x in s_constraints if x.value.sign <= 0]
      if len(minimals) > 0:
        constraint_up = min(minimals, key=lambda item: m_convert(item.value).value)
        # if verbose:
        #   print("all: minimals")
        #   self.renderer.render_values(minimals)
        #   print('\t\t\t constraint_upper', constraint_up.value.value)
        #   self.renderer.render_values([constraint_up])
        #   print("----X")

      if constraint_low is not None or constraint_up is not None:
        data['ranges'][sentence_id] = VConstraint(constraint_low, constraint_up, group_c)

    return data
    # ==================================================================VIOLATIONS


class VConstraint:
  def __init__(self, lower, upper, head_group):
    _emp = TokensWithAttention([''], [0])
    self.lower = ProbableValue(ValueConstraint(0, 'RUB', +1, context=_emp), 0)
    self.upper = ProbableValue(ValueConstraint(np.inf, 'RUB', -1, context=_emp), 0)

    if lower is not None:
      self.lower = lower

    if upper is not None:
      self.upper = upper

    self.head_group = head_group

  @staticmethod
  def maybe_convert(v: ValueConstraint, convet_m):
    html = ""
    v_converted = v
    if v.currency != 'RUB':
      v_converted = convet_m(v)
      html += as_warning(f"–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∞–ª—é—Ç {as_currency(v)} --> RUB ")
      html += as_offset(as_warning(f"–ø—Ä–∏–º–µ—Ä–Ω–æ: {as_currency(v)} ~~  {as_currency(v_converted)}  "))
    return v, v_converted, html

  def check_contract_value(self, _v: ProbableValue, convet_m, renderer):
    greather_lower = False
    greather_upper = False

    if _v is None:
      return as_error_html("—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞")
    v: ValueConstraint = _v.value

    if v is None:
      return as_error_html("—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –≤–µ—Ä–Ω–∞")

    if v.value is None:
      return as_error_html(f"—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –≤–µ—Ä–Ω–∞ {v.currency}")
    ###----

    lower_v = None
    upper_v = None
    if self.lower is not None:
      lower_v: ValueConstraint = self.lower.value
    if self.upper is not None:
      upper_v: ValueConstraint = self.upper.value

    html = as_msg(f"–î–∏–∞–ø–∞–∑–æ–Ω: {as_currency(lower_v)} < ..... < {as_currency(upper_v)}")

    v, v_converted, h = self.maybe_convert(v, convet_m)
    html += h

    if self.lower is not None:
      lower_v: ValueConstraint = self.lower.value
      lower_v, lower_converted, h = self.maybe_convert(lower_v, convet_m)
      html += h

      if v_converted.value >= lower_converted.value:
        greather_lower = True
        html += as_warning("—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ...".upper())
        html += as_warning(
          f"—Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞  {as_currency(v_converted)}  –ë–û–õ–¨–®–ï –Ω–∏–∂–Ω–µ–π –ø–æ—Ä–æ–≥–æ–≤–æ–π {as_currency(lower_converted)} ")
        html += as_quote(untokenize(lower_v.context.tokens))

    if self.upper is not None:

      upper_v: ValueConstraint = self.upper.value
      upper_v, upper_converted, h = self.maybe_convert(upper_v, convet_m)
      html += h

      if v_converted.value >= upper_converted.value:

        html += as_error_html(
          f"—Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞  {as_currency(v_converted)} –ë–û–õ–¨–®–ï –≤–µ—Ä—Ö–Ω–µ–π –ø–æ—Ä–æ–≥–æ–≤–æ–π {as_currency(upper_converted)} ")

      elif greather_lower:
        head_name = self.head_group['section']
        html += as_error_html(f'—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã "{head_name.upper()}"')

        if lower_v.context is not None:
          html += as_quote(renderer.to_color_text(lower_v.context.tokens, lower_v.context.attention, _range=[0, 1]))

        if upper_v.context is not None:
          html += '<br>'
          html += as_quote(renderer.to_color_text(upper_v.context.tokens, upper_v.context.attention, _range=[0, 1]))

    return html 
  
  
  
  # AZ:-FINDING_VIOLATIONS--------------------------------------------------------
def find_and_show_violations():
  from IPython.core.display import display, HTML

  from contract_parser import ContractAnlysingContext
  from renderer import as_headline_2, as_error_html

  charterAnlysingContext: CharterAnlysingContext = GLOBALS__['CharterAnlysingContext']
  contractAnlysingContext: ContractAnlysingContext = GLOBALS__['ContractAnlysingContext']

  contract = contractAnlysingContext.contract
  charter = charterAnlysingContext.doc
  
  charter_constraints = charterAnlysingContext.constraints  # XXX: move to doc
  charity_constraints = charterAnlysingContext.charity_constraints  # XXX: move to doc

  

  import copy

  def convert(v):
    v_converted = copy.copy(v)
    if v.currency in currency_converter:
      v_converted.value = currency_converter[v.currency] * v.value
      v_converted.currency = 'RUB'
      return v_converted
    else:
      display(HTML(as_error_html(
        f"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?")))
      return v

  best_value = contractAnlysingContext.find_contract_best_value(convert)

  # rendering:----------------------------

  def _render_violations(ranges_by_group, best_value):
    
    for group_key in ranges_by_group:
      group = ranges_by_group[group_key]
      display(HTML(as_headline_2(group['name'])))

      for rk in group['ranges']:
        r = group['ranges'][rk]
        display(HTML(r.check_contract_value(best_value, convert, renderer)))

        
  renderer = GLOBALS__['renderer']
  renderer.render_subj(contract)
  
  print('---')
  print("–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:")
  renderer.render_values([best_value])
  renderer.render_color_text(best_value.value.context.tokens, best_value.value.context.attention, _range=[0, 1])

  violations_finder = ViolationsFinder()####//XXXX: remplaced
  
  
  _render_violations(    
    violations_finder.find_ranges_by_group(charter_constraints, convert, verbose=False),
    best_value)
  
  
  
  
  
  
find_and_show_violations()

contract= GLOBALS__['ContractAnlysingContext'].contract
charter = GLOBALS__['CharterAnlysingContext'].doc
# if( GLOBALS__['ContractAnlysingContext'].contract.subject[0] == 'charity'):
#   print('charity')

charity_constraints =  GLOBALS__['CharterAnlysingContext'].charity_constraints
for cc in charity_constraints:
  if cc[:4]=='new.':
    print(cc[4:].upper() )
    constraints = charity_constraints[cc]
    for constraint in constraints:
#       print(constraint)
      if constraint['subj_correlation'] > 0.5:
        GLOBALS__['ContractAnlysingContext'].renderer.render_subj(contract)
        print(contract.sections['subj'].body.untokenize_cc())
#         GLOBALS__['ContractAnlysingContext'].renderer.render_color_text(contract.sections['subj'].tokens, contract.sections['subj'].)

        print (f"\n–ö–æ—Ä–µ–ª—è—Ü–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —É—Å—Ç–∞–≤–∞: {constraint['subj_correlation']:.4f}\n\n"  )
        print(constraint['slice'])

# contract.sections

DIST_FUNC(docA.embeddings,  docB.embeddings)

"""# step 4. –ü—Ä–æ—Ç–æ–∫–æ–ª"""

uploaded = interactive_upload('–ü—Ä–æ—Ç–æ–∫–æ–ª, –ø—Ä–æ—Ç–æ–∫—É—é –∏ –±—É–¥—É –ø—Ä–æ—Ç–æ–∫–æ–≤–∞—Ç—å')
GLOBALS__['ProtocolAnlysingContext'].process(uploaded[0])

## do preparation here   

#1.
_init_import_code_from_gh()
#2.
_init_embedder()
#3.
_init_the_code()
#4. 
_init_charters()
#5. 
# _init_contracts()

"""# Sample Charter"""



SAMPLE="""
 

–û–±—â–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è





 


–£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª


xxvii –£—Å—Ç–∞–≤–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª –û–±—â–µ—Å—Ç–≤–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –∏–∑ –Ω–æ–º–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –¥–æ–ª–µ–π –µ–≥–æ –£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç  6 734 244 615 (–®–µ—Å—Ç—å –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ —Å–µ–º—å—Å–æ—Ç —Ç—Ä–∏–¥—Ü–∞—Ç—å —á–µ—Ç—ã—Ä–µ –º–∏–ª–ª–∏–æ–Ω–∞ –¥–≤–µ—Å—Ç–∏ —Å–æ—Ä–æ–∫ —á–µ—Ç—ã—Ä–µ —Ç—ã—Å—è—á–∏ —à–µ—Å—Ç—å—Å–æ—Ç –ø—è—Ç–Ω–∞–¥—Ü–∞—Ç—å) —Ä—É–±–ª–µ–π.



xxxv –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–µ –≤–ø—Ä–∞–≤–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø—Ä–∏–±—ã–ª–∏ –û–±—â–µ—Å—Ç–≤–∞ –º–µ–∂–¥—É –£—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ –û–±—â–µ—Å—Ç–≤–∞:

       ‚Ä¢ –¥–æ –ø–æ–ª–Ω–æ–π –æ–ø–ª–∞—Ç—ã –≤—Å–µ–≥–æ —É—Å—Ç–∞–≤–Ω–æ–≥–æ –∫–∞–ø–∏—Ç–∞–ª–∞ –û–±—â–µ—Å—Ç–≤–∞;

     

–û—Ä–≥–∞–Ω—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è


lxxxiv –û—Ä–≥–∞–Ω–∞–º–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è—é—Ç—Å—è:


       ‚Ä¢ –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞;


       ‚Ä¢ –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ ‚Äì –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è;


       ‚Ä¢ –ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ - –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω;


       ‚Ä¢ –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä - –ï–¥–∏–Ω–æ–ª–∏—á–Ω—ã–π –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ä–≥–∞–Ω.


–û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞


lxxxvi –í—ã—Å—à–∏–º –æ—Ä–≥–∞–Ω–æ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è–µ—Ç—Å—è –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞. –û—á–µ—Ä–µ–¥–Ω–æ–µ –û–±—â–µ–µ —Å–æ–±—Ä–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞  —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –∏ —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –û–±—â–µ—Å—Ç–≤–∞ –∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –≥–æ–¥ –∏ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –≤ –ø–µ—Ä–∏–æ–¥ —Å 1 –º–∞—Ä—Ç–∞ –ø–æ 30 –∞–ø—Ä–µ–ª—è. –ü—Ä–æ–≤–æ–¥–∏–º—ã–µ –ø–æ–º–∏–º–æ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ –û–±—â–∏–µ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ —è–≤–ª—è—é—Ç—Å—è –≤–Ω–µ–æ—á–µ—Ä–µ–¥–Ω—ã–º–∏. –í–Ω–µ–æ—á–µ—Ä–µ–¥–Ω—ã–µ –û–±—â–∏–µ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –ø—Ä–æ–≤–æ–¥—è—Ç—Å—è –≤ —Å–ª—É—á–∞—è—Ö, –∫–æ–≥–¥–∞ —ç—Ç–æ–≥–æ —Ç—Ä–µ–±—É—é—Ç –∏–Ω—Ç–µ—Ä–µ—Å—ã –û–±—â–µ—Å—Ç–≤–∞.


lxxxvii –ö –∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ–π –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –æ—Ç–Ω–æ—Å—è—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã:

    

       12) —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞, —Å–æ—Å—Ç–∞–≤–∞, —Ñ–æ—Ä–º—ã –∏ –ø–æ—Ä—è–¥–∫–∞ –≤–Ω–µ—Å–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ç–∞–∫–∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤, –∞ —Ç–∞–∫–∂–µ –∏–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π –≤–Ω–µ—Å–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–∫–ª–∞–¥–æ–≤ –£—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ –û–±—â–µ—Å—Ç–≤–∞;
       13) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ –∫—Ä—É–ø–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –ø—Ä—è–º–æ –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ –∏–º—É—â–µ—Å—Ç–≤–∞, —Ü–µ–Ω–∞ –∏–ª–∏ –±–∞–ª–∞–Ω—Å–æ–≤–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ—Ç–æ—Ä–æ–≥–æ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 25 (–î–≤–∞–¥—Ü–∞—Ç—å –ø—è—Ç—å) –∏ –±–æ–ª–µ–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ø–æ –¥–∞–Ω–Ω—ã–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –æ—Ç—á–µ—Ç–Ω—É—é –¥–∞—Ç—É;
       14) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, –≤ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –∏–º–µ–µ—Ç—Å—è –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ —Ü–µ–Ω–∞ –∏–ª–∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –∏–º—É—â–µ—Å—Ç–≤–∞, —è–≤–ª—è—é—â–µ–≥–æ—Å—è –ø—Ä–µ–¥–º–µ—Ç–æ–º —Å–¥–µ–ª–∫–∏,  –ø—Ä–µ–≤—ã—à–∞–µ—Ç 10 (–¥–µ—Å—è—Ç—å) –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤ –±–∞–ª–∞–Ω—Å–æ–≤–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤  –±–∞–ª–∞–Ω—Å–æ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ø–æ –¥–∞–Ω–Ω—ã–º –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –æ—Ç—á–µ—Ç–Ω—É—é –¥–∞—Ç—É.
       15) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∏–ª–∏ –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏ –û–±—â–µ—Å—Ç–≤–∞;
       26) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫ –º–µ–Ω—ã, –¥–∞—Ä–µ–Ω–∏—è, –∏–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞—é—â–∏—Ö –±–µ–∑–≤–æ–∑–º–µ–∑–¥–Ω–æ–µ –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ –∏–º—É—â–µ—Å—Ç–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –ª–∏–±–æ –æ–ø–ª–∞—Ç—É (–≤—Å—Ç—Ä–µ—á–Ω–æ–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ) –≤ –Ω–µ–¥–µ–Ω–µ–∂–Ω–æ–π —Ñ–æ—Ä–º–µ,  –æ–¥–æ–±—Ä–µ–Ω–∏–µ –¥–æ–≥–æ–≤–æ—Ä–æ–≤ —Å–ø–æ–Ω—Å–æ—Ä—Å–∫–æ–≥–æ –∏ –±–ª–∞–≥–æ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∞, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Å—É–º–º—ã —Å–¥–µ–ª–∫–∏, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ –∫–∞–∫ –∫—Ä—É–ø–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –∏ —Å–¥–µ–ª–∫–∏ —Å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å—é;
       27) —Ä–µ—à–µ–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–æ–≤, –æ—Ç–Ω–µ—Å–µ–Ω–Ω—ã—Ö –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤, –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –Ω–µ –∏–∑–±—Ä–∞–Ω;
       28) —Ä–µ—à–µ–Ω–∏–µ –∏–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, –æ—Ç–Ω–µ—Å–µ–Ω–Ω—ã—Ö –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞.



–°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –û–±—â–µ—Å—Ç–≤–∞


      1. –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç –æ–±—â–µ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞, –∞ —Ç–∞–∫–∂–µ –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏–π –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –∏ –∏–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –µ–≥–æ –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ—Ä–≥–∞–Ω–∞.

      2. –°–æ–≤–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 4 (–ß–µ—Ç—ã—Ä–µ—Ö) —á–µ–ª–æ–≤–µ–∫.

      3. –ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è:


      14) —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ-—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞, –≤ —Ç–æ–º —á–∏—Å–ª–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è –æ –≤–Ω—É—Ç—Ä–∏—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç—Ä–æ–ª–µ, –¥–æ–∫—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–∫–∞—Ö –∏ —Ä–µ–≤–∏–∑–∏—è—Ö;

      15) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–µ–º –¥–µ–Ω–µ–∂–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –∏ (–∏–ª–∏) –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è, –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∏–º—É—â–µ—Å—Ç–≤–∞, –≤ —Ä–∞–º–∫–∞—Ö –∫–æ—Ç–æ—Ä—ã—Ö —Ü–µ–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–ª–∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å –æ—Ç—á—É–∂–¥–∞–µ–º–æ–≥–æ –∏–º—É—â–µ—Å—Ç–≤–∞, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è —Å–¥–µ–ª–∫–∏, –ø—Ä–µ–≤—ã—à–∞–µ—Ç –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π —Å–¥–µ–ª–∫–∏ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫, –∑–∞–∫–ª—é—á–µ–Ω–Ω—ã—Ö –≤ —Ç–µ—á–µ–Ω–∏–µ 6 (—à–µ—Å—Ç–∏) –º–µ—Å—è—Ü–µ–≤, –≤ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π –∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –¥–∞–Ω–Ω–æ–π —Å—É–º–º—ã –≤ –∏–Ω–æ–π –≤–∞–ª—é—Ç–µ, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞  –∫–∞–∫ –∫—Ä—É–ø–Ω—ã–µ —Å–¥–µ–ª–∫–∏ –∏ —Å–¥–µ–ª–∫–∏ —Å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å—é, –∞ —Ç–∞–∫–∂–µ –¥–ª—è —Å–¥–µ–ª–æ–∫, –æ–¥–æ–±—Ä—è–µ–º—ã—Ö –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ 22)-26) –ø—É–Ω–∫—Ç–∞ 11.2 –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞, –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ 17) ‚Äì22), 30) –ø—É–Ω–∫—Ç–∞ 12.3 –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞;

      16) –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ –Ω–∞—á–∞–ª–µ/—É—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–∏ –ª—é–±—ã—Ö —Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤ –∏ —Ä–∞–∑–±–∏—Ä–∞—Ç–µ–ª—å—Å—Ç–≤, —Ü–µ–Ω–∞ –∏—Å–∫–∞ –ø–æ –∫–æ—Ç–æ—Ä—ã–º –ø—Ä–µ–≤—ã—à–∞–µ—Ç 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π (–∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –≤ –¥—Ä—É–≥–æ–π –≤–∞–ª—é—Ç–µ) –≤ —Ç–æ–º —á–∏—Å–ª–µ, –ø–æ–¥–ø–∏—Å–∞–Ω–∏–µ –º–∏—Ä–æ–≤–æ–≥–æ —Å–æ–≥–ª–∞—à–µ–Ω–∏—è, –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ –∏—Å–∫–∞, –æ—Ç–∫–∞–∑ –æ—Ç –∏—Å–∫–∞, –∞ —Ç–∞–∫–∂–µ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –ª—é–±—ã—Ö –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, –∫—Ä–æ–º–µ —Å—É–¥–µ–±–Ω—ã—Ö —Å–ø–æ—Ä–æ–≤, –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è, –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç–Ω–µ—Å–µ–Ω–æ –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞;


–ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞


 1. –ü—Ä–∞–≤–ª–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –ö–æ–ª–ª–µ–≥–∏–∞–ª—å–Ω—ã–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –æ—Ä–≥–∞–Ω–æ–º –û–±—â–µ—Å—Ç–≤–∞. –ü—Ä–∞–≤–ª–µ–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –∏–∑–±–∏—Ä–∞–µ—Ç—Å—è –û–±—â–∏–º —Å–æ–±—Ä–∞–Ω–∏–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ  2 (–î–≤—É—Ö) —á–µ–ª–æ–≤–µ–∫ ‚Äì —á–ª–µ–Ω–æ–≤ –ü—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞.


12. –í —Å–ª—É—á–∞–µ –Ω–µ–ø—Ä–∏–Ω—è—Ç–∏—è –ü—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Ä–µ—à–µ–Ω–∏—è –ø–æ –æ–¥–Ω–æ–º—É –∏ —Ç–æ–º—É –∂–µ –≤–æ–ø—Ä–æ—Å—É –≤ —Ö–æ–¥–µ 2 (–î–≤—É—Ö) –Ω–∞–¥–ª–µ–∂–∞—â–µ —Å–æ–∑–≤–∞–Ω–Ω—ã—Ö –∑–∞—Å–µ–¥–∞–Ω–∏–π –ü—Ä–∞–≤–ª–µ–Ω–∏—è –ø–æ –ª—é–±—ã–º –ø—Ä–∏—á–∏–Ω–∞–º, –≤–∫–ª—é—á–∞—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–≤–æ—Ä—É–º–∞ –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≥–æ–ª–æ—Å–æ–≤ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è, –≤–æ–ø—Ä–æ—Å, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –Ω–µ –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ —Ä–µ—à–µ–Ω–∏–µ, –≤—ã–Ω–æ—Å–∏—Ç—Å—è –Ω–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ (–≤–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –ø–æ–≤–µ—Å—Ç–∫—É –¥–Ω—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–∑—ã–≤–∞–µ–º–æ–≥–æ –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤). –í–æ –∏–∑–±–µ–∂–∞–Ω–∏–µ —Å–æ–º–Ω–µ–Ω–∏–π, —Ä–µ—à–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å—Å—è –∫–∞–∫ –Ω–µ–ø—Ä–∏–Ω—è—Ç–æ–µ –¥–ª—è —Ü–µ–ª–µ–π –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –ø—É–Ω–∫—Ç–∞, –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ —Ä–µ—à–µ–Ω–∏–µ –Ω–µ –ø—Ä–∏–Ω—è—Ç–æ –≤—Å–ª–µ–¥—Å—Ç–≤–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –ø—Ä–æ—Ç–∏–≤ –Ω–µ–≥–æ –ø—Ä–æ–≥–æ–ª–æ—Å–æ–≤–∞–ª–∏ –∏–ª–∏ –≤–æ–∑–¥–µ—Ä–∂–∞–ª–∏—Å—å –æ—Ç –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏—è –≤—Å–µ —á–ª–µ–Ω—ã –ü—Ä–∞–≤–ª–µ–Ω–∏—è.

13. –ö –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –ü—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞ –æ—Ç–Ω–æ—Å—è—Ç—Å—è:



         ‚Ä¢ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—É—Ä –Ω–∞ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–π (–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Ñ–∏–ª–∏–∞–ª–æ–≤ –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤) –û–±—â–µ—Å—Ç–≤–∞, –∞ —Ç–∞–∫–∂–µ —É—Å–ª–æ–≤–∏–π —Ç—Ä—É–¥–æ–≤—ã—Ö –¥–æ–≥–æ–≤–æ—Ä–æ–≤ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –ª–∏—Ü–∞–º–∏, —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –æ—Ç –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ª–∏—Ü;


         ‚Ä¢ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Å–æ–≥–ª–∞—Å–∏–∏ –Ω–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–µ –∏–ª–∏ –æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–º –æ–¥–æ–±—Ä–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–µ–º –¥–µ–Ω–µ–∂–Ω—ã—Ö –≤—ã–ø–ª–∞—Ç –∏ (–∏–ª–∏) –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ–º, –æ—Ç—á—É–∂–¥–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç—á—É–∂–¥–µ–Ω–∏—è, –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–µ–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–æ–º –∏–º—É—â–µ—Å—Ç–≤–∞, —Å—Ç–æ–∏–º–æ—Å—Ç—å –∫–æ—Ç–æ—Ä–æ–≥–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–π —Å–¥–µ–ª–∫–∏ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ –≤ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ—Ç 1 000 000 (–û–¥–Ω–æ–≥–æ) –º–∏–ª–ª–∏–æ–Ω–∞ —Ä—É–±–ª–µ–π –¥–æ 50 000 000 (–ü—è—Ç—å–¥–µ—Å—è—Ç –º–∏–ª–ª–∏–æ–Ω–æ–≤) —Ä—É–±–ª–µ–π –∏–ª–∏ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç –¥–∞–Ω–Ω–æ–π —Å—É–º–º—ã –≤ –∏–Ω–æ–π –≤–∞–ª—é—Ç–µ, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞  —Ç–∞–∫–∏–µ —Å–¥–µ–ª–∫–∏ —Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–∏—è –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞  –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ó–∞–∫–æ–Ω–æ–º –∏ –£—Å—Ç–∞–≤–æ–º;


         ‚Ä¢ –ø—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –ø–æ –ø—Ä–∏–µ–º–∫–µ –∏ –æ–ø–ª–∞—Ç–µ –û–±—â–µ—Å—Ç–≤–æ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç –ø–æ –ê–≥–µ–Ω—Ç—Å–∫–æ–º—É –¥–æ–≥–æ–≤–æ—Ä—É –Ω–∞ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–∞ ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –≥–∞–∑–æ–ø–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∏–π –∑–∞–≤–æ–¥ (–Æ–ü –ì–ü–ó). –ì–∞–∑–æ–∫–æ–º–ø—Ä–µ—Å—Å–æ—Ä–Ω–∞—è —Å—Ç–∞–Ω—Ü–∏—è –Æ–õ–¢ –ü—Ä–∏–æ–±—Å–∫–æ–≥–æ –º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏—è¬ª ‚Ññ10-875 –æ—Ç 29.09.2010 –≥., –∑–∞–∫–ª—é—á–µ–Ω–Ω–æ–º—É –º–µ–∂–¥—É –û–±—â–µ—Å—Ç–≤–æ–º –∏ –û–û–û ¬´–ì–∞–∑–ø—Ä–æ–º–Ω–µ—Ñ—Ç—å-–•–∞–Ω—Ç–æ—Å¬ª.


–ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –û–±—â–µ—Å—Ç–≤–∞


cvi –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ —Ç–µ–∫—É—â–µ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –û–±—â–µ—Å—Ç–≤–∞ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –µ–¥–∏–Ω–æ–ª–∏—á–Ω—ã–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –æ—Ä–≥–∞–Ω–æ–º –û–±—â–µ—Å—Ç–≤–∞ - –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–º. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –∏–∑–±–∏—Ä–∞–µ—Ç—Å—è –û–±—â–∏–º —Å–æ–±—Ä–∞–Ω–∏–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ —Å—Ä–æ–∫–æ–º –Ω–∞ 3 (–¢—Ä–∏) –≥–æ–¥–∞, –µ—Å–ª–∏ —Ä–µ—à–µ–Ω–∏–µ–º –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–µ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω –∏–Ω–æ–π —Å—Ä–æ–∫. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–∏–∑–±—Ä–∞–Ω —Ä–µ—à–µ–Ω–∏–µ–º –û–±—â–µ–≥–æ —Å–æ–±—Ä–∞–Ω–∏—è —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞ –Ω–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä –¥–µ–π—Å—Ç–≤—É–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –£—Å—Ç–∞–≤–∞ –û–±—â–µ—Å—Ç–≤–∞ –∏ —Ç—Ä—É–¥–æ–≤–æ–≥–æ –¥–æ–≥–æ–≤–æ—Ä–∞, –∑–∞–∫–ª—é—á–∞–µ–º–æ–≥–æ —Å –Ω–∏–º –û–±—â–µ—Å—Ç–≤–æ–º.


       ‚Ä¢ —É—Ç–≤–µ—Ä–∂–¥–∞—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã, —Ä–µ–≥—É–ª–∏—Ä—É—é—â–∏–µ —Ç–µ–∫—É—â—É—é (–æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—É—é) –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å –û–±—â–µ—Å—Ç–≤–∞, –∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∞–∫—Ç—ã (–∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –ª–æ–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—â–∏—Ö —Å–∏—Å—Ç–µ–º—ã –æ–ø–ª–∞—Ç—ã —Ç—Ä—É–¥–∞ –∏ –¥—Ä—É–≥–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç–Ω–µ—Å–µ–Ω–æ –∫ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏ –∏–Ω—ã—Ö –æ—Ä–≥–∞–Ω–æ–≤ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –û–±—â–µ—Å—Ç–≤–∞);

       ‚Ä¢ –≤–Ω–æ—Å–∏—Ç—å –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏–µ –û–±—â–∏—Ö —Å–æ–±—Ä–∞–Ω–∏–π —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –û–±—â–µ—Å—Ç–≤–∞, –∑–∞—Å–µ–¥–∞–Ω–∏—è –°–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤;

       ‚Ä¢ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ—à–µ–Ω–∏—è –ø–æ –¥—Ä—É–≥–∏–º –≤–æ–ø—Ä–æ—Å–∞–º, –æ—Ç–Ω–æ—Å—è—â–∏–º—Å—è –∫ –µ–≥–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏.



cxlv –ù–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ª—é–±–æ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞ –Ω–µ –≤–ª–µ—á–µ—Ç –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –µ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏–π. –í —Å–ª—É—á–∞–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ —Å–∏–ª—É –Ω–æ–≤—ã—Ö –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö –∞–∫—Ç–æ–≤, –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –∫–æ—Ç–æ—Ä—ã–º–∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –£—Å—Ç–∞–≤–∞ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –Ω–µ–¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º–∏, –∏ –∫–æ—Ç–æ—Ä—ã–µ —Ç—Ä–µ–±—É—é—Ç –≤–Ω–µ—Å—Ç–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –£—Å—Ç–∞–≤, –£—á–∞—Å—Ç–Ω–∏–∫–∏ –æ–±—è–∑–∞–Ω—ã –ø—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏—è –æ –≤–Ω–µ—Å–µ–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –Ω–∞—Å—Ç–æ—è—â–∏–π –£—Å—Ç–∞–≤.

v –ü–æ–ª–Ω–æ–µ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:

      –û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –≥–∞–∑–æ–ø–µ—Ä–µ—Ä–∞–±–∞—Ç—ã–≤–∞—é—â–∏–π –∑–∞–≤–æ–¥¬ª.

      –°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:

      –û–û–û ¬´–Æ–∂–Ω–æ-–ü—Ä–∏–æ–±—Å–∫–∏–π –ì–ü–ó¬ª.


      –ü–æ–ª–Ω–æ–µ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –û–±—â–µ—Å—Ç–≤–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ: Yuzhno-Priobsky Gaz Processing Plant Limited Liability Company.


      –°–æ–∫—Ä–∞—â–µ–Ω–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ:  Yuzhno-Priobsky GPP LLC.


"""

GLOBALS__['CharterAnlysingContext'].analyze_charter(SAMPLE)

from IPython.core.display import display, HTML
doc = GLOBALS__['CharterAnlysingContext'].doc
GLOBALS__['renderer'].render_contents(doc)

 
GLOBALS__['renderer'].render_charter_parsing_results(GLOBALS__['CharterAnlysingContext'].org,GLOBALS__['CharterAnlysingContext'].constraints)


def render_sections(sections):
  html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ —Å–µ–∫—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'
  html += "<ul>"
  for section_type in sections:
    section:HeadlineMeta = sections[section_type]
    body = section.body.untokenize_cc()[:1000]
    headline = section.subdoc.untokenize_cc()[:500]
    #     line = doc.structure.structure[i].to_string(doc.tokens_cc)
    html += f'<li><h3> {headline} <sup>type: {section_type}</sup> </h3> <p>{body}</p> </li>'
  html += "</ul>"

  display(HTML(html))
  
def render_contents(doc):
  html = '<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'
  html += "<ul>"
  for i in doc.structure.headline_indexes:
    line = doc.structure.structure[i].to_string(doc.tokens_cc)
    html += f'<li> {line} <sup>line {i}</sup></li>'
  html += "</ul>"

  display(HTML(html))
  
render_sections(doc.sections)



"""#Upload charter"""

if False:
  uploaded = interactive_upload('Charter')  
  org, rz = GLOBALS__['CharterAnlysingContext'] .analyze_charter(uploaded[0])

_init_contracts()

GLOBALS__

"""#Upload contract"""

uploaded = interactive_upload('–î–æ–≥–æ–≤–æ—Ä')

GLOBALS__['ContractAnlysingContext'].verbosity_level=4
GLOBALS__['ContractAnlysingContext'].analyze_contract(uploaded[0])

"""# Violations"""

#@title –ù–∞—Å—Ç—Ä–æ–π–∫–∏ { run: "auto", display-mode: "form" }
USD_to_RUB = 64.02 #@param {type:"number"}
RUB_to_USD = 1.0/USD_to_RUB

# print('USD_to_RUB=',USD_to_RUB)
# print('RUB_to_USD=',RUB_to_USD)



currency_converter = {
  'USD': USD_to_RUB,
  'RUB': 1.0
}

print(currency_converter)

find_and_show_violations()

doc=GLOBALS__['ContractAnlysingContext'].contract
GLOBALS__['renderer'].render_contents(doc)

h = GLOBALS__['renderer'].render_constraint_values(GLOBALS__['CharterAnlysingContext'].constraints)
display(HTML(h))

"""#violations (move and erase)"""

from transaction_values import ValueConstraint

print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')
from IPython.core.display import display, HTML

contract = GLOBALS__['ContractAnlysingContext'].contract
charter = GLOBALS__['CharterAnlysingContext'].doc
charter_constraints = GLOBALS__['CharterAnlysingContext'].constraints  # XXX: move to doc

#       h = GLOBALS__['renderer'].render_constraint_values(GLOBALS__['CharterAnlysingContext'].constraints)
#       display(HTML(h))


# def max_constraint_val(constraints):
renderer = GLOBALS__['renderer']
renderer.render_subj(contract)
print()
# GLOBALS__['renderer'].render_values(contract.contract_values)

print("----------")

# GLOBALS__['renderer'].render_values([most_confident_value])
# GLOBALS__['renderer'].render_color_text (most_confident_value.value.context[0], most_confident_value.value.context[1], _range=[0,1])

# for c in contract.contract_values:
#   print(c.confidence)
#   print(c.value.value)
# #   if c.value.value > best_c.value.value:


# #   print(c.value.context)
#   GLOBALS__['renderer'].render_color_text (c.value.context[0], c.value.context[1], _range=[0,1])

# GLOBALS__['renderer'].render_contents(contract)


# -------------------charter

charter_constraints = GLOBALS__['CharterAnlysingContext'].constraints  # XXX: move to doc


from ml_tools import ProbableValue

currency_converter = {
  'USD': USD_to_RUB,
  'RUB': 1.0

}
import copy


def convert(v, currency_converter=currency_converter):
  v_converted = copy.copy(v)
  if v.currency in currency_converter:
    v_converted.value = currency_converter[v.currency] * v.value
    v_converted.currency = 'RUB'
    return v_converted
  else:
    display(HTML(as_error_html(
      f"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?")))
    return v


from text_tools import untokenize
import numpy as np

class VConstraint:
  def __init__(self, lower, upper, head_group):
    self.lower = ProbableValue( ValueConstraint(0, 'RUB', +1), 0 )
    self.upper = ProbableValue( ValueConstraint(np.inf, 'RUB', -1), 0 )
    
    if lower is not None:
      self.lower = lower
     

    if upper is not None:
      self.upper = upper
     
      
    self.head_group = head_group

  def maybe_convert(self, v: ValueConstraint, currency_converter):
    html = ""
    v_converted = v
    if v.currency != 'RUB':
      v_converted = convert(v, currency_converter)
      html += as_warning(f"–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤–∞–ª—é—Ç {as_currency(v)} --> RUB ")
      html += as_offset(as_warning(f"–ø—Ä–∏–º–µ—Ä–Ω–æ: {as_currency(v)} ~~  {as_currency(v_converted)}  "))
    return v, v_converted, html

  def check_contract_value(self, _v: ProbableValue, currency_converter):
    greather_lower = False
    greather_upper = False

    if _v is None:
      return as_error_html("—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –∏–∑–≤–µ—Å—Ç–Ω–∞")
    v: ValueConstraint = _v.value

    if v is None:
      return as_error_html("—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –≤–µ—Ä–Ω–∞")

    if v.value is None:
      return as_error_html(f"—Å—É–º–º–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –Ω–µ –≤–µ—Ä–Ω–∞ {v.currency}")
    ###----

    lower_v = None
    upper_v = None
    if self.lower is not None:
      lower_v: ValueConstraint = self.lower.value
    if self.upper is not None:
      upper_v: ValueConstraint = self.upper.value

    html = as_msg(f"–¥–∏–∞–ø–∞–∑–æ–Ω: {as_currency(lower_v)} < ..... < {as_currency(upper_v)}")

    v, v_converted, h = self.maybe_convert(v, currency_converter)
    html += h

    if self.lower is not None:
      lower_v: ValueConstraint = self.lower.value
      lower_v, lower_converted, h = self.maybe_convert(lower_v, currency_converter)
      html += h

      if v_converted.value >= lower_converted.value:
        greather_lower = True
        html += as_warning("—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ...".upper())
        html += as_warning(
          f"—Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞  {as_currency(v_converted)}  –ë–û–õ–¨–®–ï –Ω–∏–∂–Ω–µ–π –ø–æ—Ä–æ–≥–æ–≤–æ–π {as_currency(lower_converted)} ")
        html += as_quote(untokenize(lower_v.context[0]))

    if self.upper is not None:

      upper_v: ValueConstraint = self.upper.value
      upper_v, upper_converted, h = self.maybe_convert(upper_v, currency_converter)
      html += h

      if v_converted.value >= upper_converted.value:

        html += as_error_html(
          f"—Å—É–º–º–∞ –¥–æ–≥–æ–≤–æ—Ä–∞  {as_currency(v_converted)} –ë–û–õ–¨–®–ï –≤–µ—Ä—Ö–Ω–µ–π –ø–æ—Ä–æ–≥–æ–≤–æ–π {as_currency(upper_converted)} ")

      elif greather_lower:
        head_name = self.head_group['section']
        html += as_error_html(f'—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–¥–æ–±—Ä–µ–Ω–∏–µ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã "{head_name.upper()}"')

        if lower_v.context is not None:
          html += as_quote(renderer.to_color_text(lower_v.context[0], lower_v.context[1], _range=[0, 1]))
        if upper_v.context is not None:
          html += '<br>'
          html += as_quote(renderer.to_color_text(upper_v.context[0], upper_v.context[1], _range=[0, 1]))

    return html


# -----------


def _combine_constraints_in_group(group_c, verbose=False):
  # print(group_c)
  # print(group_c['section'])

  data = {
    'name': group_c['section'],
    'ranges': {}
  }

  sentences = group_c['sentences']
  #   print (charter_constraints[head_group]['sentences'])
  sentence_id = 0
  for sentence in sentences:
    constraint_low = None
    constraint_up = None

    sentence_id += 1
    #     print (sentence['constraints'])

    s_constraints = sentence['constraints']
    # –±–æ–ª—å—à–∏–µ –∏—â–µ–º
    maximals = [x for x in s_constraints if x.value.sign > 0]

    if len(maximals) > 0:
      constraint_low = min(maximals, key=lambda item: convert(item.value, currency_converter).value)
      if verbose:
        print("all maximals:")
        renderer.render_values(maximals)
        print('\t\t\t constraint_low', constraint_low.value.value)
        renderer.render_values([constraint_low])

    minimals = [x for x in s_constraints if x.value.sign <= 0]
    if len(minimals) > 0:
      constraint_up = min(minimals, key=lambda item: convert(item.value, currency_converter).value)
      if verbose:
        print("all: minimals")
        renderer.render_values(minimals)
        print('\t\t\t constraint_upper', constraint_up.value.value)
        renderer.render_values([constraint_up])
        print("----X")

    if constraint_low is not None or constraint_up is not None:
      data['ranges'][sentence_id] = VConstraint(constraint_low, constraint_up, group_c)

  return data


def find_ranges_by_group(charter_constraints):
  ranges_by_group = {}
  for head_group in charter_constraints:
    #     print('-' * 20)
    group_c = charter_constraints[head_group]
    data = _combine_constraints_in_group(group_c)
    ranges_by_group[head_group] = data
  return ranges_by_group


def select_most_confident_if_almost_equal(a: ProbableValue, alternative: ProbableValue, equality_range=0):
  if abs(convert(a.value).value - convert(alternative.value).value) < equality_range:
    if a.confidence > alternative.confidence:
      return a
    else:
      return alternative
  return a


def find_contract_best_value(contract):
  best_value: ProbableValue = max(contract.contract_values,
                                  key=lambda item: convert(item.value, currency_converter).value)

  most_confident_value = max(contract.contract_values, key=lambda item: item.confidence)
  best_value = select_most_confident_if_almost_equal(best_value, most_confident_value, 20)

  return best_value


best_value = find_contract_best_value(contract)


# rendering:----------------------------


def _render_violations(ranges_by_group, best_value):
  for group_key in ranges_by_group:
    group = ranges_by_group[group_key]
    #   print(group['name'])
    display(HTML(as_headline_2(group['name'])))

    for rk in group['ranges']:
      r = group['ranges'][rk]
      display(HTML(r.check_contract_value(best_value, currency_converter)))


print("–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:")
renderer.render_values([best_value])
renderer.render_color_text(best_value.value.context[0], best_value.value.context[1], _range=[0, 1])

_render_violations(
  find_ranges_by_group(charter_constraints),
  best_value)

display(HTML(renderer.render_constraint_values(charter_constraints)))

"""## —á–∏—Å—Ç–æ–≤–∏–∫"""

from transaction_values import ValueConstraint

print('–ü–æ–∏—Å–∫ –Ω–∞—Ä—É—à–µ–Ω–∏–π')
from IPython.core.display import display, HTML

contract = GLOBALS__['ContractAnlysingContext'].contract
charter = GLOBALS__['CharterAnlysingContext'].doc
charter_constraints = GLOBALS__['CharterAnlysingContext'].constraints  # XXX: move to doc

 
renderer = GLOBALS__['renderer']
renderer.render_subj(contract)
  

charter_constraints = GLOBALS__['CharterAnlysingContext'].constraints  # XXX: move to doc


from ml_tools import ProbableValue
from text_tools import untokenize
import numpy as np


def convert(v):
  
  v_converted = copy.copy(v)
  if v.currency in currency_converter:
    v_converted.value = currency_converter[v.currency] * v.value
    v_converted.currency = 'RUB'
    return v_converted
  else:
    display(HTML(as_error_html(
      f"–º—ã –Ω–µ –≤ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏ (–ø–æ–∫–∞) –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å {v.currency} --> RUB. –≠—Ç–æ –≤–æ–æ–±—â–µ –≤–∞–ª—é—Ç–∞ –∫–∞–∫–æ–π —Å—Ç—Ä–∞–Ω—ã? –†—É–º—ã–Ω–∏–∏?")))
    return v


 


def _combine_constraints_in_group(group_c, verbose=False):
  # print(group_c)
  # print(group_c['section'])

  data = {
    'name': group_c['section'],
    'ranges': {}
  }

  sentences = group_c['sentences']
  #   print (charter_constraints[head_group]['sentences'])
  sentence_id = 0
  for sentence in sentences:
    constraint_low = None
    constraint_up = None

    sentence_id += 1
    #     print (sentence['constraints'])

    s_constraints = sentence['constraints']
    # –±–æ–ª—å—à–∏–µ –∏—â–µ–º
    maximals = [x for x in s_constraints if x.value.sign > 0]

    if len(maximals) > 0:
      constraint_low = min(maximals, key=lambda item: convert(item.value, currency_converter).value)
      if verbose:
        print("all maximals:")
        renderer.render_values(maximals)
        print('\t\t\t constraint_low', constraint_low.value.value)
        renderer.render_values([constraint_low])

    minimals = [x for x in s_constraints if x.value.sign <= 0]
    if len(minimals) > 0:
      constraint_up = min(minimals, key=lambda item: convert(item.value, currency_converter).value)
      if verbose:
        print("all: minimals")
        renderer.render_values(minimals)
        print('\t\t\t constraint_upper', constraint_up.value.value)
        renderer.render_values([constraint_up])
        print("----X")

    if constraint_low is not None or constraint_up is not None:
      data['ranges'][sentence_id] = VConstraint(constraint_low, constraint_up, group_c)

  return data


def find_ranges_by_group(charter_constraints):
  ranges_by_group = {}
  for head_group in charter_constraints:
    #     print('-' * 20)
    group_c = charter_constraints[head_group]
    data = _combine_constraints_in_group(group_c)
    ranges_by_group[head_group] = data
  return ranges_by_group


def select_most_confident_if_almost_equal(a: ProbableValue, alternative: ProbableValue, equality_range=0):
  if abs(convert(a.value).value - convert(alternative.value).value) < equality_range:
    if a.confidence > alternative.confidence:
      return a
    else:
      return alternative
  return a


def find_contract_best_value(contract):
  best_value: ProbableValue = max(contract.contract_values,
                                  key=lambda item: convert(item.value, currency_converter).value)

  most_confident_value = max(contract.contract_values, key=lambda item: item.confidence)
  best_value = select_most_confident_if_almost_equal(best_value, most_confident_value, 20)

  return best_value


best_value = find_contract_best_value(contract)


# rendering:----------------------------


def _render_violations(ranges_by_group, best_value):
  for group_key in ranges_by_group:
    group = ranges_by_group[group_key]
    #   print(group['name'])
    display(HTML(as_headline_2(group['name'])))

    for rk in group['ranges']:
      r = group['ranges'][rk]
      display(HTML(r.check_contract_value(best_value, currency_converter, renderer)))


print("–°—É–º–º–∞ –î–æ–≥–æ–≤–æ—Ä–∞:")
renderer.render_values([best_value])
renderer.render_color_text(best_value.value.context[0], best_value.value.context[1], _range=[0, 1])

_render_violations(
  find_ranges_by_group(charter_constraints),
  best_value)

display(HTML(renderer.render_constraint_values(charter_constraints)))

"""#~~~~ Garbage, to be removed"""





# violations

from IPython.core.display import display, HTML
def render_subj(self, doc):
      from demo import subject_types_dict
      subj=doc.subject
      s_name=subject_types_dict[ subj[0]].upper()
      
      display(HTML(f'–ü—Ä–µ–¥–º–µ—Ç –¥–æ–≥–æ–≤–æ—Ä–∞:<h3 style="margin:0">{s_name}<sup> {subj[0]}</sup> </h3> confidence:{subj[1]:20,.2f}'))

r=GLOBALS__['renderer']
# GLOBALS__['renderer'].render_subj = render_subj 

import types
r.render_subj = types.MethodType( render_subj, r )

contract = GLOBALS__['ContractAnlysingContext'].contract
GLOBALS__['renderer'].render_subj(contract)

doc = GLOBALS__['CharterAnlysingContext'].doc
from IPython.core.display import display, HTML


def render_contents(doc):
  html='<h3>–í—ã—è–≤–ª–µ–Ω–Ω–æ–µ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞</h4>'
  html+="<ul>"
  for i in doc.structure.headline_indexes:
    line = doc.structure.structure[i].to_string(doc.tokens_cc)
    html+=f'<li> {line} <sup>line {i}</sup></li>'
  html+="</ul>"
 
  
  display(HTML(html))
    
render_contents(doc)

print(GLOBALS__['ContractAnlysingContext'].contract)

# constraints = GLOBALS__['CharterAnlysingContext'].constraints

# GLOBALS__['renderer'].render_values(GLOBALS__['ContractAnlysingContext'].contract_values)
# GLOBALS__['renderer'].render_charter_parsing_results(GLOBALS__['CharterAnlysingContext'].org, GLOBALS__['CharterAnlysingContext'].constraints)


# # for i in 

# for headkey in constraints:
#   cc = constraints[headkey]
#   print (cc)
#   print (cc['section'])
#   print (cc['caption'])
  
#   for s in cc['sentences']:
#     print ('\t\t',s['constraints'])
#     c = s['constraints']
#     for vc in c:
#       print(f'\t\t\t {vc.value} \t {vc.sign} \t {vc.currency}')