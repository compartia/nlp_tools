# -*- coding: utf-8 -*-
"""DEMO II Sum & Subj Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AVNUCzbNAh1ghQr0tYQnNdtTP2tEpnWF

# Init
"""

import tensorflow as tf
import tensorflow_hub as hub

print(tf.__version__)
elmo = hub.Module('https://storage.googleapis.com/az-nlp/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz', trainable=False) #twitter

hyperparameters={}
hyperparameters['embeddings.layer']='elmo'

!wget https://raw.githubusercontent.com/compartia/nlp_tools/structured_2/text_tools.py
!wget https://raw.githubusercontent.com/compartia/nlp_tools/structured_2/embedding_tools.py
!rm ml_tools.py  
!wget https://raw.githubusercontent.com/compartia/nlp_tools/structured_2/ml_tools.py
!wget https://raw.githubusercontent.com/compartia/nlp_tools/structured_2/text_normalize.py  
!wget https://raw.githubusercontent.com/compartia/nlp_tools/structured_2/patterns.py 
!wget https://raw.githubusercontent.com/compartia/nlp_tools/structured_2/transaction_values.py  

!rm doc_structure.py  
!wget https://raw.githubusercontent.com/compartia/nlp_tools/structured_2/doc_structure.py 
!rm legal_docs.py  
!wget https://raw.githubusercontent.com/compartia/nlp_tools/structured_2/legal_docs.py  
  
from transaction_values import *
from patterns import *
from text_tools import *
from text_normalize import *
from embedding_tools import *
from ml_tools import *


from legal_docs import *
from doc_structure import *

import legal_docs as ld

"""# Code"""

REPORTED_MOVED={}

def at_github(fn):
  @wraps(fn)
  @wraps(fn)
  def with_reporting(*args, **kwargs):
    if fn.__name__ not in REPORTED_MOVED:
      REPORTED_MOVED[fn.__name__] = 1
      print("----WARNING!: function {} must be imported from github".format(fn.__name__) )
 
    ret = fn(*args, **kwargs)
    return ret

  return with_reporting

"""### rendering"""

import matplotlib as mpl
from IPython.core.display import display, HTML


def to_color_text(tokens, weights, colormap='coolwarm', print_debug=False, _range=None):
  #   weights = _weights *-1
  if len(tokens)==0:
#     raise ValueError("don't know how to render emptiness")
    return " - empty -"
  if len(weights) != len(tokens):
    raise ValueError("number of weights differs weights={} tokens={}".format(len(weights), len(tokens)))

  #   if()
  vmin = weights.min()
  vmax = weights.max()

  if _range is not None:
    vmin = _range[0]
    vmax = _range[1]

  if print_debug:
    print(vmin, vmax)

  norm = mpl.colors.Normalize(vmin=vmin - 0.5, vmax=vmax)
  html = ""
  cmap = mpl.cm.get_cmap(colormap)

  for d in range(0, len(weights)):
    word = tokens[d]
    if word == ' ':
      word = '&nbsp;_ '
    
    html += '<span title="{} {:.4f}" style="background-color:{}">{} </span>'.format(
      d,
      weights[d],
      mpl.colors.to_hex(cmap(norm(weights[d]))),
      word)

    #     html+='<span style="background-color:' +mpl.colors.to_hex(cmap(norm(weights[d]) ))+ '">' + str(tokens[d]) + " </span>"
    if tokens[d] == '\n':
      html += "<br>"

  return html


def render_color_text(tokens, weights, colormap='coolwarm', print_debug=False, _range=None):
  html = to_color_text(tokens, weights, colormap, print_debug, _range)
  display(HTML(html))
  
  
  
  
def winning_patterns_to_html(_tokens, ranges, winning_patterns, _range,
                             colormaps=['Reds', 'Purples', 'Blues', 'Greens', 'Greys']):
  
    vmin = -ranges[1]
    vmax = -ranges[0]

#     print("winning_patterns_to_html _range", _range, "min max=", ranges)

    norm = mpl.colors.Normalize(vmax=vmax, vmin=vmin)

    cmaps = []

#     print (colormaps)
    for n in colormaps:
        cmap = mpl.cm.get_cmap(n)
        cmaps.append(cmap)

    html = ""

    for d in _range:
        winning_pattern_i = winning_patterns[d][0]
        colormap = cmaps[winning_pattern_i % len(colormaps)]
        normed = norm(-winning_patterns[d][1])
        color = mpl.colors.to_hex(colormap(normed))
        html += '<span title="' + '{} {:.2f}'.format(d, winning_patterns[d][1]) + '" style="background-color:' + color + '">' + str(
            _tokens[d]) + " </span>"
        if _tokens[d] == '\n':
            html += "<br>"

    return html

  
  
  
def _render_doc_subject_fragments(doc):
#     print(doc.per_subject_distances)
    type = "Договор  благотворительного пожертвования"
    if doc.per_subject_distances[0] > doc.per_subject_distances[1]:
        type = "Договор возмездного оказания услуг"

    _html = "<h3>" + type + "</h3>"

    colormaps = ['PuRd'] * 5 + ['Blues'] * 7 + ['Greys']

    _html += "<h4> Предмет договора:</h4>"

    for region in [doc.subj_range]:
        _html += winning_patterns_to_html(_tokens=doc.tokens, ranges=doc.subj_ranges,
                                          winning_patterns=doc.winning_subj_patterns, _range=region,
                                          colormaps=colormaps)

    return _html


def print_results(doc, results):
    result, (start, end), sentence, meta = results

    html = "<hr>"

    html += _render_doc_subject_fragments(doc)

    if result is None:
        html += '<h2 style="color:red">СУММА НЕ НАЙДЕНА</h2>'
    else:
        html += '<h2>' + str(result[0]) + ' ' + str(result[1]) + '</h2>'

    for key in meta.keys():
        html += '<div style="font-size:9px">' + str(key) + " = " + str(meta[key]) + "</div>"

    display(HTML(html))
    render_color_text(doc.tokens[start:end], doc.sums[start:end])

"""### Embedding"""

class ElmoEmbedder(AbstractEmbedder):

  def __init__(self, elmo):
    self.elmo = elmo
    self.config = tf.ConfigProto()
    self.config.gpu_options.allow_growth=True

  def embedd_tokenized_text(self, words, lens):
    with tf.Session(config=self.config) as sess:
      embeddings = self.elmo(
        inputs={
          "tokens": words,
          "sequence_len": lens
        },
        signature="tokens",
        as_dict=True)[ hyperparameters['embeddings.layer'] ]

      sess.run(tf.global_variables_initializer())
      out = sess.run(embeddings)
#       sess.close()


    return out, words

  def get_embedding_tensor(self, str, type=hyperparameters['embeddings.layer'], signature="default"):
    embedding_tensor = self.elmo(str, signature=signature, as_dict=True)[type]

    with tf.Session(config=self.config) as sess:
      sess.run(tf.global_variables_initializer())
      embedding = sess.run(embedding_tensor)
#       sess.close()

    return embedding


embedder = ElmoEmbedder(elmo)

"""### Define Patterns"""

class PatternFactory(AbstractPatternFactory):
  
  
  def create_pattern(self, pattern_name, ppp):
    _ppp = (ppp[0].lower(), ppp[1].lower(), ppp[2].lower())
    fp = FuzzyPattern(_ppp, pattern_name)
    self.patterns.append(fp)
    return fp
      
    
  def _build_subject_patterns(self):
        
    
    ep = ExclusivePattern()
    
    ep.add_pattern(self.create_pattern ('t_charity_1',('договор','благотворительного', 'пожертвования'))) #at index 0
    ep.add_pattern(self.create_pattern ('t_charity_2',('договор  о предоставлении','безвозмездной  помощи', 'финансовой')))
    ep.add_pattern(self.create_pattern ('t_charity_3',('проведение','благотворительных', '')))
#     ep.add_pattern(self.create_pattern ('t_charity_4',('"Благотворитель" оплачивает следующий счет, выставленный на','Благополучателя', '')))
    ep.add_pattern(self.create_pattern ('t_charity_4',('"принимает в качестве','Пожертвования', '')))
    p1 = self.create_pattern ('t_charity_5',('','Жертвователь', 'безвозмездно передает в собственность, а Благополучатель принимает'))
    
    """
    
    
    Получатель принимает в качестве Пожертвования

    """
#     p1.soft_sliding_window_borders=True
    ep.add_pattern(p1)
    
    ep.add_pattern(self.create_pattern ('t_comm_1',('ПРОДАВЕЦ обязуется передать в собственность ПОКУПАТЕЛЯ, а','ПОКУПАТЕЛЬ', 'обязуется принять и оплатить')))
    p2 = self.create_pattern ('t_comm_2',('Арендодатель обязуется предоставить','Арендатору', 'за плату во временное владение и пользование недвижимое имущество '))
    p2.soft_sliding_window_borders=True
    ep.add_pattern(p2)
    ep.add_pattern(self.create_pattern ('t_comm_3',('Исполнитель обязуется своими силами','выполнить работы', 'по разработке')))
    
    ep.add_pattern(self.create_pattern ('t_comm_4',('Исполнитель обязуется','оказать услуги', '')))
    ep.add_pattern(self.create_pattern ('t_comm_5',('Заказчик поручает и оплачивает, а Исполнитель предоставляет ','услуги', 'в виде')))
    ep.add_pattern(self.create_pattern ('t_comm_6',('договор на оказание','платных', 'услуг')))  
    ep.add_pattern(self.create_pattern ('t_comm_7',('договор','возмездного', 'оказания услуг')))  
    
    
    ep.add_pattern(self.create_pattern ('t_unk',('<UNK>','unk', '<UNK>'))) 

    
    
    self.subject_patterns = ep

    
  
 
    
  
  
  
  def __init__(self, embedder):

    AbstractPatternFactory.__init__(self, embedder)
    
    

    self._build_subject_patterns()
#     self.subject_pattern = 
#     //--------------
    
  
    sum_1 = self.create_pattern ('sum_1',('Стоимость Работ составляет','0 рублей','(миллионов тысяч) рублей 0 копеек, включая НДС'))
    sum_2 = self.create_pattern ('sum_2', ('Расчеты по договору. Стоимость оказываемых услуг составляет ','0',' рублей 0 копеек. Оплата работ производится '))
    sum_max = self.create_pattern ('sum_max',('Стоимость расчетов по договору не может превышать','0','рублей'))
    
    phone_num = self.create_pattern ('phone_num',('телефон','00-00-00',''))
                     

    sum_pay_neg = self.create_pattern ( 'sum_pay_neg' , ('после выставления счета оплачивает сумму в размере','0','рублей'))
    sum_fine_neg = self.create_pattern ( 'sum_fine_neg', ('уплачивается','штраф 0 рублей а также возмещаются понесенные','убытки'))        
    sum_fine_neg2 = self.create_pattern ('sum_fine_neg2', ('В случае нарушения  сроков выполнения Работ по соответствующему Приложению , Заказчик имеет право взыскать пени в размере','0%','от стоимости не выполненного вовремя этапа Работ по соответствующему Приложению за каждый день просрочки'))
    sum_term_neg = self.create_pattern ( 'sum_term_neg', ('в срок не позднее, чем за','3','банковских календарных дней'))
   
  
    sum_1.soft_sliding_window_borders=True
    sum_2.soft_sliding_window_borders=True
    sum_max.soft_sliding_window_borders=True
    sum_fine_neg.soft_sliding_window_borders=True
    
    self.embedd()
    
    
    
    sp = CoumpoundFuzzyPattern()

    sp.add_pattern( sum_1 )    
    sp.add_pattern( sum_2 )    
    sp.add_pattern( sum_max )
    
#     sp.add_pattern( sum_pay_neg , -0.5)
    sp.add_pattern( sum_fine_neg , -0.8)
    sp.add_pattern( sum_fine_neg2 , -0.51)
#     sp.add_pattern( sum_term_neg , -0.6)
    
    self.sum_pattern = sp
    
    
    
    ep = ExclusivePattern()
    
    sp_a = CoumpoundFuzzyPattern()

    sp_a.add_pattern( sum_1 )    
#     sp_a.add_pattern( sum_2 )    
    sp_a.add_pattern( sum_max )
    
    
    ep.add_pattern(sp_a)  
    
#     ep.add_pattern( sum_1 )    
#     ep.add_pattern( sum_2 )    
#     ep.add_pattern( sum_max )
    
    ep.add_pattern( sum_pay_neg   )
    ep.add_pattern( sum_fine_neg  )
#     ep.add_pattern( sum_fine_neg2  )
    ep.add_pattern( sum_term_neg )
    ep.add_pattern (phone_num)
    
    self.sum_pattern_exclusive = ep
    
    
    

    
 
    
    
    
embedder = ElmoEmbedder(elmo)
PF = PatternFactory(embedder)

"""#### HeadlinesPatternFactory"""

class HeadlinesPatternFactory(AbstractPatternFactory):
  
  
  def create_pattern(self, pattern_name, ppp):
    _ppp = (ppp[0].lower(), ppp[1].lower(), ppp[2].lower())
    fp = FuzzyPattern(_ppp, pattern_name)
    self.patterns.append(fp)
    self.patterns_dict[pattern_name] = fp
    return fp

  def __init__(self, embedder):
    AbstractPatternFactory.__init__(self, embedder)
    self.patterns_dict = {}
    self._build_head_patterns()
    self.embedd()
    
    self.headlines = ['subj','contract', 'def', 'price', 'pricecond', 'terms', 'dates', 'break', 'rights', 'obl', 'resp', 'forcemajor', 'confidence', 'special', 'appl', 'addresses', 'conficts']

  def _build_head_patterns(self):
    def cp(name, tuples):
      return self.create_pattern(name, tuples)
    
    
    """
    
    ПРЕДМЕТ ДОГОВОРА.
СТОИМОСТЬ РАБОТ
ПОРЯДОК И УСЛОВИЯ ПЛАТЕЖЕЙ.
СРОКИ ВЫПОЛНЕНИЯ РАБОТ.
ПРАВА И ОБЯЗАННОСТИ СТОРОН.
ГАРАНТИЙНЫЕ ОБЯЗАТЕЛЬСТВА.
ОТВЕТСТВЕННОСТЬ СТОРОН.
СРОК ДЕЙСТВИЯ, ПОРЯДОК ИЗМЕНЕНИЯ И РАСТОРЖЕНИЯ ДОГОВОРА.
НЕПРЕОДОЛИМАЯ СИЛА( ФОРС-МАЖОРНЫЕ ОБСТОЯТЕЛЬСТВА).
КОНФИДЕНЦИАЛЬНОСТЬ ПОЛУЧЕННОЙ СТОРОНАМИ ИНФОРМАЦИИ.
РАЗРЕШЕНИЕ СПОРОВ.
ОСОБЫЕ УСЛОВИЯ.
ЗАКЛЮЧИТЕЛЬНЫЕ ПОЛОЖЕНИЯ.
ПРИЛОЖЕНИЯ.
ЮРИДИЧЕСКИЕ АДРЕСА, РЕКВИЗИТЫ И ПОДПИСИ СТОРОН.

"""
       
    
    PRFX = ''
    
        
    cp ('headline.contract',(PRFX,'ДОГОВОР','\n город, месяц, год \n общество с ограниченной ответственностью, в лице, действующего на основании, именуемое далее, заключили настоящий договор о нижеследующем'))
    cp ('headline.def',(PRFX,'Термины и определения','толкования'))

    cp ('headline.subj.1',('заключили настоящий Договор нижеследующем:\n' +PRFX ,'Предмет договора.\n','Исполнитель обязуется, заказчик поручает'))
    cp ('headline.subj.2',(PRFX ,'ПРЕДМЕТ ДОГОВОРА',''))
    
    
    cp ('headline.price.1',(PRFX,'цена договора',''))
    cp ('headline.price.2',(PRFX,'СТОИМОСТЬ РАБОТ',''))
    cp ('headline.price.3',(PRFX,'УСЛОВИЯ ПЛАТЕЖЕЙ',''))
    cp ('headline.price.4',(PRFX,'Оплата услуг',''))
   
    cp ('headline.pricecond.1',(PRFX,'Условия и порядок расчетов.',''))

    
    
    
    cp ('headline.terms',(PRFX,'СРОКИ ВЫПОЛНЕНИЯ РАБОТ.','Порядок выполнения работ.'))  
  
    cp ('headline.dates',(PRFX,'СРОК ДЕЙСТВИЯ ДОГОВОРА.\n','настоящий договор вступает в силу с момента подписания сторонами, изменения и дополнения к договору оформляются письменным соглашением сторон, продленным на каждый последующий год'))
    cp ('headline.break',(PRFX,'Расторжение договора','досрочное расторжение договора, предупреждением о прекращении, расторгается в случаях, предусмотренных действующим законодательством, в одностороннем порядке'))
    
    
    cp ('headline.rights.1',(PRFX,'права и обязанности','сторон.\n'))
    cp ('headline.obl.1',(PRFX,'ОБЯЗАТЕЛЬСТВА','сторон.\n'))
    cp ('headline.obl.2',(PRFX,'ГАРАНТИЙНЫЕ','ОБЯЗАТЕЛЬСТВА.'))
    
    cp ('headline.resp',(PRFX,'Ответственность сторон.\n','невыполнения или ненадлежащего выполнения своих обязательств, несут ответственность в соответствии с действующим законодательством'))
   

    cp ('headline.forcemajor',(PRFX,'НЕПРЕОДОЛИМАЯ СИЛА.','ФОРС-МАЖОРНЫЕ ОБСТОЯТЕЛЬСТВА'))
    cp ('headline.confidence',(PRFX,'КОНФИДЕНЦИАЛЬНОСТЬ ИНФОРМАЦИИ.',''))
    
    
    cp ('headline.special.1',(PRFX+'ОСОБЫЕ, дополнительные',' УСЛОВИЯ.',''))
    cp ('headline.special.2',(PRFX,'ЗАКЛЮЧИТЕЛЬНЫЕ ПОЛОЖЕНИЯ.',''))
                    
     
    
    cp ('headline.appl',(PRFX,'ПРИЛОЖЕНИЯ.',''))
    cp ('headline.addresses',(PRFX,'РЕКВИЗИТЫ СТОРОН','ЮРИДИЧЕСКИЕ АДРЕСА'))

    
         
    cp ('headline.conficts',(PRFX,'Споры и разногласия.',''))         
    
      
#     // -----------------------
     
HPF = HeadlinesPatternFactory(embedder)

"""#### PricePF"""

# see also https://colab.research.google.com/drive/1w5KNrKn6O4GFM5dFEspeIVEF-mUwHGm_#scrollTo=1uz5CtBdETys&uniqifier=6
from patterns import AbstractPatternFactory, FuzzyPattern


class PriceFactory(AbstractPatternFactory):

  def create_pattern(self, pattern_name, ppp):
    _ppp = (ppp[0].lower(), ppp[1].lower(), ppp[2].lower())
    fp = FuzzyPattern(_ppp, pattern_name)
    self.patterns.append(fp)
    self.patterns_dict[pattern_name] = fp
    return fp

  def __init__(self, embedder):
    AbstractPatternFactory.__init__(self, embedder)

    self.patterns_dict = {}
 
 
 
    self._build_sum_patterns()
    self.embedd()


    
  def _build_sum_patterns(self):
    def cp(name, tuples):
      return self.create_pattern(name, tuples)
    
    suffix = 'млн. тыс. миллионов тысяч рублей долларов копеек евро'
    prefix = 'решений о совершении сделок '


    cp ('_sum.work.1',('Стоимость Работ составляет','0 рублей',suffix))
    cp ('_sum.work.2', ('Расчеты по договору. Стоимость оказываемых услуг составляет ','0',suffix))
    cp ('_sum.work.3',('Стоимость расчетов по договору не может превышать','0',suffix))
    cp ( '_sum.work.4' , ('после выставления счета оплачивает сумму в размере','0',suffix))
    
    cp ('sum_neg.phone',('телефон','00-00-00',''))
                     

    
    cp ( 'sum_neg.penalty', ('уплачивается','штраф','0 рублей а также возмещаются понесенные убытки'))        
    cp ( 'sum_neg.3', ('В случае нарушения  сроков выполнения Работ по соответствующему Приложению , Заказчик имеет право взыскать пени в размере','0%','от стоимости не выполненного вовремя этапа Работ по соответствующему Приложению за каждый день просрочки'))
    cp ( 'sum_neg.date.1', ('в срок не позднее, чем за 0 банковских','календарных',' дней'))
    cp ( 'sum_neg.vat', ('в том числе','НДС','0 '+suffix))
    cp ( 'sum_neg.date.2', ('в течение','0','рабочих дней '))

  
    
    
PricePF = PriceFactory(embedder)

"""### Contract class"""



"""### Upload file code"""

!sudo apt-get install antiword
!pip install docx2txt
import docx2txt, sys, os

from google.colab import files

 

def interactive_upload():
  print('select .docx files:')
  uploaded = files.upload()
  docs=[]
  for fn in uploaded.keys():
    print('User uploaded file "{name}" with length {length} bytes'.format(
        name=fn, length=len(uploaded[fn])))

    with open(fn, "wb") as df:
      df.write(uploaded[fn])
      df.close()

    # extract text
  
    text = ''
    try:
      text = docx2txt.process(fn)
    except:
      print("Unexpected error:", sys.exc_info())
      os.system('antiword "' + fn + '" > "' + fn + '.txt"')
      with open(fn + '.txt') as f:
        text = f.read()
      #os.remove(fn+'.txt') #fn.txt was just to read, so deleting  
  
    print(text)
    docs.append(text)
    return docs
  
  

  
  
# print_results(doc.tokens, (result, (start, end), sentence, {'a':'aaaa','b':'bbb'}))

"""# Upload file"""

docs = interactive_upload()



"""### - NEW -"""

# ------------------------------
def subdoc_between_lines(line_a: int, line_b: int, doc):
  _str = doc.structure.structure
  start = _str[line_a].span[1]
  if line_b is not None:
    end = _str[line_b].span[0]
  else:
    end = len(doc.tokens)
  return doc.subdoc(start, end)

# ------------------------------
def _doc_section_under_headline(_doc, hl_struct, headline_indices, render=False):
  if render:
    print('_doc_section_under_headline:searching for section:', hl_struct['headline.type'])

  bi = hl_struct['headline.index']

  bi_next = bi + 1
  best_headline = headline_indices[bi]

  if bi_next < len(headline_indices):
    best_headline_next = headline_indices[bi_next]
  else:
    best_headline_next = None

  if render:
    print(
      '_doc_section_under_headline: best_headline:{} best_headline_next:{} bi:{}'.format(best_headline,
                                                                                         best_headline_next, bi),
      '_' * 40)

  subdoc = subdoc_between_lines(best_headline, best_headline_next, _doc)
  if len(subdoc.tokens) < 2:
    raise ValueError(
      'Empty "{}" section between headlines #{} and #{}'.format(hl_struct['headline.type'], best_headline, best_headline_next))

  # May be embedd
  if render:
    print('_doc_section_under_headline: embedding segment:', untokenize(subdoc.tokens_cc))

  

  return subdoc

# ------------------------------
def find_sections_by_headlines(best_indexes, _doc, headline_indexes, render=False):
  sections = {}

  for bi in best_indexes:

    """
    bi = {
        'headline.index': bi,
        'headline.type': head_type,
        'headline.confidence': distance_by_headline[bi],
        'headline.subdoc': embedded_headlines[bi],
        'headline.attention_v': attention_v}
    """
    hl = best_indexes[bi]
    
    if render:
      print('=' * 100)
      print(untokenize(hl['headline.subdoc'].tokens_cc))
      print('-' * 100)

    head_type = hl['headline.type']

    try:      
      hl['body.subdoc'] = _doc_section_under_headline(_doc, hl, headline_indexes, render=render)
      sections[head_type] = hl
      
    except ValueError as error:
      print(error)

  return sections



def _find_best_headline_by_pattern_prefix(headline_indices, embedded_headlines, pat_refix, threshold, render=False):
  distance_by_headline = []

  attention_vs = []
  for headline_index, subdoc in zip(headline_indices, embedded_headlines):
    names, _c = rectifyed_sum_by_pattern_prefix(subdoc.distances_per_pattern_dict, pat_refix, relu_th=0.6)
    names = smooth_safe(names, 4)
    _max_id = np.argmax(names)
    _max = np.max(names)
    _sum = math.log(1 + np.sum(names[_max_id - 1:_max_id + 2]))
    distance_by_headline.append(_max + _sum)
    attention_vs.append(names)

  bi = np.argmax(distance_by_headline)
  if distance_by_headline[bi] < threshold:
    raise ValueError('Cannot find headline matching pattern "{}"'.format(pat_refix))

  return bi, distance_by_headline, attention_vs[bi]


def match_headline_types(head_types_list, headline_indexes, embedded_headlines: List[LegalDocument], pattern_prefix,
                         threshold):
  best_indexes = {}
  for head_type in head_types_list:
    try:
      bi, distance_by_headline, attention_v = \
        _find_best_headline_by_pattern_prefix(headline_indexes, embedded_headlines, pattern_prefix + head_type,
                                              threshold,
                                              render=False)

      obj = {'headline.index': bi,
             'headline.type': head_type,
             'headline.confidence': distance_by_headline[bi],
             'headline.subdoc': embedded_headlines[bi],
             'headline.attention_v': attention_v}

      if bi in best_indexes:
        e_obj = best_indexes[bi]
        if e_obj['headline.confidence'] < obj['headline.confidence']:
          best_indexes[bi] = obj
      else:
        best_indexes[bi] = obj

    except Exception as e:
      print(e)
      pass

  return best_indexes



class ContractDocument2(LegalDocument):
  def __init__(self, original_text):
    LegalDocument.__init__(self, original_text)
    self.right_padding = 0

  def tokenize(self, _txt):
    return tokenize_text(_txt)

doc = ContractDocument2(docs[0])
doc.parse()


## 1. detect structure ----------------------------------------------------------------------------------------------------
headline_indexes = doc.structure.headline_indexes

  
#--(test)
print('headline_indexes', headline_indexes)
for i in headline_indexes:
  li = doc.structure.structure[i] 
  _str = li.to_string(doc.tokens_cc) 
  print(f'\t{li.level}\t#{li.number}\t->{li._possible_levels} \t {_str} ')

## 2. map headlines semantics-------------------------------------------------------------------------------------------------

embedded_headlines = embedd_headlines(headline_indexes, doc, HPF)
 
#--(test)
for eh in embedded_headlines:
  print( untokenize(eh.tokens_cc))

import math
best_indexes = match_headline_types(HPF.headlines, headline_indexes, embedded_headlines, 'headline.', 0.9)
  
  
#--(test)
for bi in best_indexes:
  hl = best_indexes[bi]
  t=hl['headline.subdoc']
  print(bi)
  render_color_text(t.tokens_cc, hl['headline.attention_v'], _range=[0, 2])

print()
for bi in best_indexes:
  hl = best_indexes[bi]
  t=hl['headline.subdoc']
  print( '#{} \t {} \t {:.4f} \t {}'.format(hl['headline.index'], hl['headline.type'] + ('.' * (14-len(hl['headline.type']))), hl['headline.confidence'], untokenize(t.tokens_cc)))

sections = find_sections_by_headlines(best_indexes,
                                        doc,
                                        headline_indexes,
                                        render=True)

section_price_1 = sections['price']['body.subdoc']
# section_price_2 = sections['price.cond']['body.subdoc']
section_subj = sections['subj']['body.subdoc']

# _sum.work
#     sum_neg

section_price_1.embedd(PricePF)
section_price_1.calculate_distances_per_pattern(PricePF)




print('*'*100)

# for name in sections:
#   print(name)
#   section  = sections[name]['body.subdoc']
  
#   section.embedd(PricePF)
#   section.calculate_distances_per_pattern(PricePF)
#   render_color_text(section.tokens_cc, r['value_attention_vector'], _range=(0,1))

def make_contract_value_attention_vectors(subdoc):
  value_attention_vector, _c1 = rectifyed_sum_by_pattern_prefix(subdoc.distances_per_pattern_dict, '_sum.work', relu_th=0.4)
  value_attention_vector = cut_above(value_attention_vector, 1)
  value_attention_vector = relu(value_attention_vector, 0.6)
  value_attention_vector = momentum(value_attention_vector, 0.8)

   
  novalue_attention_vector, _c1 = rectifyed_sum_by_pattern_prefix(subdoc.distances_per_pattern_dict, 'sum_neg', relu_th=0.4)
  novalue_attention_vector = cut_above(novalue_attention_vector, 1)
#   novalue_attention_vector = relu(novalue_attention_vector, 0.6)
#   novalue_attention_vector = momentum(novalue_attention_vector, 0.8)
  
#   novalue_attention_vector = normalize(novalue_attention_vector)
  
#   _novalue_attention_vector_blur = smooth_safe(novalue_attention_vector, 20)
#   novalue_attention_vector_local_contrast = normalize(novalue_attention_vector - _novalue_attention_vector_blur*0.99)
#   novalue_attention_vector_local_contrast = relu(novalue_attention_vector_local_contrast, 0.7)

  novalue_attention_vector_local_contrast = relu(novalue_attention_vector, 0.6)
  novalue_attention_vector_local_contrast = momentum(novalue_attention_vector_local_contrast, 0.9)
  
  value_attention_vector_tuned = (value_attention_vector - novalue_attention_vector*0.7)
#   value_attention_vector_tuned = smooth_safe(value_attention_vector_tuned, 8)
  value_attention_vector_tuned=relu(value_attention_vector_tuned,0.3)
  value_attention_vector_tuned=normalize(value_attention_vector_tuned)
  

  return {
    'value_attention_vector': value_attention_vector,
    'novalue_attention_vector': novalue_attention_vector,
#     '_novalue_attention_vector_blur':_novalue_attention_vector_blur,
    'novalue_attention_vector_local_contrast':novalue_attention_vector_local_contrast,
    'value_attention_vector_tuned':value_attention_vector_tuned
#     'deal_value_attention_vector': deal_value_attention_vector,
#     'margin_attention_vector': margin_attention_vector,
#     'margin_value_attention_vector': margin_value_attention_vector
  }





r = make_contract_value_attention_vectors(section_price_1) 


#--------------- test
import matplotlib as mpl
import matplotlib.pyplot as plt
fig = plt.figure(figsize=(20, 6))
ax = plt.axes()
for vector_name in r:                 
  print(vector_name.upper())
  render_color_text(section_price_1.tokens_cc, r[vector_name], _range=(0,1))
  
  ax.plot(r[vector_name], label=vector_name, alpha=0.4);
ax.plot(r['value_attention_vector_tuned'], label=vector_name.upper(), alpha=0.9, color='black');

 

plt.title('margin_numbers "{}"'.format(i))
plt.legend(loc='upper right')

@at_github
def split_by_token(tokens: List[str], token):
  res = []
  sentence = []
  for i in tokens:
    if i == token:
      res.append(sentence)
      sentence = []
    else:
      sentence.append(i)
  
  res.append(sentence)
  return res
##---------------------------------------

@at_github
def embedd_generic_tokenized_sentences(strings: List[str], factory: AbstractPatternFactory) -> \
        List[LegalDocument]:
  

  embedded_docs = []
  if strings is None or len(strings)==0:
    return []

  tokenized_sentences_list = []
  for i in range(len(strings)):
    s = strings[i]

    words = nltk.word_tokenize(s)

    subdoc = LegalDocument()

    subdoc.tokens = words
    subdoc.tokens_cc = words

    tokenized_sentences_list.append(subdoc.tokens)
    embedded_docs.append(subdoc)

  sentences_emb, wrds, lens = embedd_tokenized_sentences_list(factory.embedder, tokenized_sentences_list)

  for i in range(len(embedded_docs)):
    l = lens[i]
    tokens = wrds[i][:l]

    line_emb = sentences_emb[i][:l]

    embedded_docs[i].tokens = tokens
    embedded_docs[i].tokens_cc = tokens
    embedded_docs[i].embeddings = line_emb
    embedded_docs[i].calculate_distances_per_pattern(factory)

  return embedded_docs


 


# --------------------- test

attentoin_vector_name = 'value_attention_vector_tuned'
section_price_1 = sections['price']['body.subdoc']
section_price_1.distances_per_pattern_dict = {**section_price_1.distances_per_pattern_dict, **r}
for k in section_price_1.distances_per_pattern_dict:
  print (k)

# extract_constraint_values_from_section(sections['price'], 'value_attention_vector_tuned')


def sign_to_text(sign: int):
  if sign < 0: return " &lt; "
  if sign > 0: return " &gt; "
  return ' = '

def value_to_html(vc: ValueConstraint):
  color = '#333333'
  if vc.sign > 0:
    color = '#993300'
  elif vc.sign < 0:
    color = '#009933'

  return f'<b style="color:{color}">{sign_to_text(vc.sign)} {vc.currency} {vc.value:20,.2f}</b> '


prices = extract_all_contraints_from_sentence(section_price_1, section_price_1.distances_per_pattern_dict[attentoin_vector_name])
for p in prices:
  h=value_to_html(p)
  display(HTML(h))

"""# Analyze"""

doc = None
for d in docs:
  doc = ContractDocument()
  doc.parse(d)
#   print(doc.normal_text)
  doc.analyze(PF)
  
#   render_color_text(doc.tokens[:-TEXT_PADDING], doc.sums[:-TEXT_PADDING])
  print_results(doc, doc.found_sum)
  print()

print(doc.normal_text)